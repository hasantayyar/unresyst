%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% iso8859-2

%%%                                    %%%
%%% ©ablona bakaláøské práce na MFF UK %%%
%%%                                    %%%
%%% (c) Franti¹ek ©trupl, 2005         %%%
%%%                                    %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% POZOR: Úprava bakaláøské práce je závislá rovnì¾ na volbì jednostranného resp. oboustranného tisku.
%%%        Bli¾¹i informace naleznete v dokumentu Úprava bakaláøské práce, který se nalézá na adrese:
%%%        http://www.mff.cuni.cz/studium/obecne/bplayout/pok12mo4.pdf

\documentclass[12pt,notitlepage]{report}
%\pagestyle{headings}
\pagestyle{plain}

% \frenchspacing aktivuje pou¾ití nìkterých èeských typografických pravidel

\usepackage[latin2]{inputenc} % nastavuje pou¾ité kódování, u¾ivatelé Windows zamìní latin2 za cp1250
%\usepackage[czech]{babel}
\usepackage{a4wide} % nastavuje standardní evropský formát stránek A4
%\usepackage{index} % nutno pou¾ít v pøípadì tvorby rejstøíku balíèkem makeindex
%\usepackage{fancybox} % umo¾òuje pokroèilé rámeèkování :-)
\usepackage{graphicx} % nezbytné pro standardní vkládání obrázkù do dokumentu
\usepackage{amsfonts}
\usepackage{amsmath}

\usepackage[left=2.5cm]{geometry} % nastavení dané velikosti okrajù

%\newindex{default}{idx}{ind}{Rejstøík} % zavádí rejstøík v pøípadì pou¾ití balíku index

% promenne:
\newcommand{\vedouci}{prof. RNDr. Peter Vojtá¹, DrSc.}
\newcommand{\ja}{Petr Cvengro¹}
\newcommand{\katedra}{Katedra softwarového in¾enýrství}
\newcommand{\nazev}{Univerzální doporuèovací systém}
\newcommand{\datum}{DATUM}
\newcommand{\vedoucimail}{Peter.Vojtas@mff.cuni.cz}

% prikazy s parametry

% obrazek
\newcommand{\fig}[4][13]{
    \begin{figure}[!ht]
        \vspace{3mm}
        \begin{center}
            \includegraphics[width=#1cm]{#2}
            \caption{#3}
            \label{#4}
        \end{center}
    \end{figure}
}
% parameters: [width in cm], filename, caption, label


\title{Název práce}   % tyto dvì polo¾ky jsou zde v podstatì formálnì, ve skuteènosti nejsou nikde 
\author{Petr Cvengro¹} % dále v dokumentu pou¾ity

%\date{}

\begin{document}

%\csprimeson % zapne jednoduché psaní èeských uvozovek pomocí klasických znakù, ale potom pozor 
             % na originální apostrofy, které budou chybnì interpretovány!!!

%%% Následuje první, úvodní, strana bakaláøské práce. Jednotlivé polo¾ky nahraïte dle vlastních
%%% údajù. Zmìnit podle konkrétní délky jednotlivých polo¾ek mù¾ete i zalomení øádkù.
\begin{titlepage}
\begin{center}
\ \\

\vspace{15mm}

\large
Univerzita Karlova v Praze\\
Matematicko-fyzikální fakulta\\

\vspace{5mm}

{\Large\bf DIPLOMOVÁ PRÁCE}

\vspace{10mm}

%%% Aby vlo¾ní loga v¹e správnì fungovalo, je tøeba mít soubor logo.eps nahraný v pracovním adresáøi,
%%% tj. v adresáøi, kde se nachází pøekládaný zdrojový soubor. Soubor logo.eps je mo¾né získat napø.
%%% na adrese: http://www.mff.cuni.cz/fakulta/symboly/logo.eps
\includegraphics[scale=0.3]{pics/logo.jpg} 

\vspace{15mm}

%\normalsize
{\Large \ja}\\ % doplòte va¹e jméno
\vspace{5mm}
{\Large\bf \nazev}\\ % doplòte název práce
\vspace{5mm}
\katedra\\ % doplòte název katedry èi ústavu
\end{center}
\vspace{15mm}

\large
\noindent Vedoucí diplomové práce: \vedouci % doplòte odpovídající údaje
%%% dal¹í øádek mù¾ete ve vìt¹inì pøípadù (tj. pokud údaje uvedené vý¹e nejsou pøíli¹ dlouhé) zru¹it
\hskip20mm 
\vspace{1mm} 

\noindent Studijní program: Informatika, Softwarové systémy, Softwarové in¾enýrství % doplòte odpovídající údaje
%%% dal¹í øádek mù¾ete ve vìt¹inì pøípadù (tj. pokud údaje uvedené vý¹e nejsou pøíli¹ dlouhé) zru¹it
%\hskip20mm 

\vspace{20mm}

\begin{center}
2010-2011 % doplòte rok vzniku va¹í bakaláøské práce
\end{center}

\end{titlepage} % zde konèí úvodní strana

\normalsize % nastavení normální velikosti fontu
\setcounter{page}{2} % nastavení èíslování stránek
\ \vspace{10mm} 

\noindent Na tomto místì mohou být napsána pøípadná podìkování (vedoucímu práce, konzultantovi, tomu, kdo pùjèil software, literaturu, poskytl data apod.). % doplòte vlastní text

\vspace{\fill} % nastavuje dynamické umístìní následujícího textu do spodní èásti stránky
\noindent Prohla¹uji, ¾e jsem svou diplomovou práci napsal samostatnì a výhradnì s pou¾itím citovaných pramenù. Souhlasím se zapùjèováním práce.

\bigskip
\noindent V Praze dne \datum \hspace{\fill}\ja\\ % doplòte patøièné datum, jméno a pøíjmení

%%%   Výtisk pak na tomto míste nezapomeòte PODEPSAT!
%%%                                         *********

\tableofcontents % vkládá automaticky generovaný obsah dokumentu

\newpage % pøechod na novou stránku

%%% Následuje strana s abstrakty. Doplòte vlastní údaje.
\noindent
Název práce: \nazev\\
Autor: \ja\\
Katedra (ústav): \katedra\\
Vedoucí diplomové práce: \vedouci\\
e-mail vedoucího: \vedoucimail\\

\noindent Abstrakt:  V pøedlo¾ené práci studujeme ... Uvede se abstrakt v rozsahu 80 a¾ 200 slov. %Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Ut sit amet sem. Mauris nec turpis ac sem mollis pretium. Suspendisse neque massa, suscipit id, dictum in, porta at, quam. Nunc suscipit, pede vel elementum pretium, nisl urna sodales velit, sit amet auctor elit quam id tellus. Nullam sollicitudin. Donec hendrerit. Aliquam ac nibh. Vivamus mi. Sed felis. Proin pretium elit in neque. Pellentesque at turpis. Maecenas convallis. Vestibulum id lectus. Fusce dictum augue ut nibh. Etiam non urna nec mi mattis volutpat. Curabitur in tortor at magna nonummy gravida.\\

\noindent Klíèová slova: klíèová slova (3 a¾ 5)

\vspace{10mm}

\noindent
Title: Universal Recommender System\\
Author: \ja\\
Department: Department of Software Engineering\\
Supervisor: \vedouci\\
Supervisor's e-mail address: \vedoucimail\\

\noindent Abstract: In the present work we study ... Uvede se anglický abstrakt v rozsahu 80 a¾ 200 slov. %Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Ut sit amet sem. Mauris nec turpis ac sem mollis pretium. Suspendisse neque massa, suscipit id, dictum in, porta at, quam. Nunc suscipit, pede vel elementum pretium, nisl urna sodales velit, sit amet auctor elit quam id tellus. Nullam sollicitudin. Donec hendrerit. Aliquam ac nibh. Vivamus mi. Sed felis. Proin pretium elit in neque. Pellentesque at turpis. Maecenas convallis. Vestibulum id lectus. Fusce dictum augue ut nibh. Etiam non urna nec mi mattis volutpat. Curabitur in tortor at magna nonummy gravida.\\

\noindent Keywords: klíèová slova (3 a¾ 5) v angliètinì

\newpage

%%% Následuje text bakaláøské práce èlenìný do kapitol, které se èíslují, oznaèí názvy a graficky oddìlí.
%%% Nedoporuèuje se pou¾ívat víc ne¾ dvì úrovnì èíslování kapitol, viz pøíklad ní¾e.

\chapter{Introduction}
    \label{introduction}

    A present-day internet user is facing a plentitude of options. E-shops are offering a wide choice of various products, internet newspapers publish thousands of articles every day, loads of videos are published or uploaded by users every second. When a user is deciding what to buy, read or see, there are by far too many options to browse and choose the optimal one. Search engines don't help much, because a query like ``find something I would like'' is too vague. That's where recommender systems emerge. They help users to deal with the information overload, retailers to offer the most appropriate product for each client which resutls in increased custumer satisfaction and loyalty. 
    
    The key feature of recommender systems is \emph{personalization}. Unlike search engines, recommenders take into account the personality and past behaviour of each user. A typical recommender wouldn't present the same set of items to two different users.
    
    Recommender systems are programs operating on large amount of data in software systems. Recommender systems try to present items such as books, music, news, etc. that are likely to be interesting for a given user. These systems may be helpful for users that are choosing between a large number of items and aren't willing to browse information about all available items.
    
    Traditional recommender systems are specific to a particular domain of recommended items. Our view is more general and involves domain independence and utilzation of any relationships among the entities in the domain. The thesis aims to create a prototype of a \emph{Universal Recommender} system, a system applicable to various domains, prediciting relationships of the given type using already known relationships. Our recommender adds a new layer above algorithms implemented in recommender frameworks, making the recommender easily applicable to any domain and system.
    
    %TODO tohle opravit
    In the introductory chapter we describe the basic structure of the thesis. Then we give a formal definition of a recommender system. Finally we review projects and papers that have been created on the universal recommender topic.
    
    \section{Thesis Structure}
        \label{thesis_structure}
        In the \emph{\ref{introduction} Introduction} chapter we describe some basic ideas of the thesis, give a formal definition of a recommender system and explore the works that have been made on the topic.
        
        TODO doplnit
    \section{Thesis Concepts}
        The section describes the main concepts of the thesis. We list the most important features and describe the purpose of the thesis.
        \subsection{Motivation}
            \label{motivation}
            Modern web applications like e-shops or social networks tend to have much information about items in the system, they collect much data about users and their behaviour. When implementing a recommender in the system, it would be natural to use all the available knowledge for generating recommendations. However, current algorithms used for recommending usually employ only a single source of knowledge: a user-item rating. Using all available knowledge for recommending would lead to better recommendation accuracy and better reasoning for the provided recommendations.
            
            Using multiple sources of data for recommending is also a current trend in the recommender research field, as illustrated by the current recommender system competition, organized by members of the Netflix prize winning team \cite{yahoo_cup}.
            
            We would like our Universal recommender system (\emph{Unresyst}) to take advantage of all available relationships. Let's show our idea on an example. Suppose, we have to generate recommendations in a system like Last.fm \cite{last_fm}. Registered users can let the system know what music they are playing on their computers through a media player plugin. Moreover, users can fill in some basic personal information, like gender and age. Songs and artists can be marked by tags\footnote{Tag is a short textual notice, provided by a user to describe the song or an artist. For example, music can be tagged as ``Rock'', ``Jazz'', ``Pop`` or ``Slow'', ``Indie''.}. In a recommender, we would like to be able to provide user-artist recommendations as illustrated on the figure \ref{pic_similarity}. The links between a user and an artist he/she has listened is displayed as solid line. The similarity derived from user attributes and artist tags is displayed as dotted line. The user-item recommendations, we would like to generate, are displayed as dashed lines. 
            
            \fig[11]{pics/intro_similarity.png}{Using domain-specific similarity for recommending}{pic_similarity}

            Then there are some domain-specific rules we would like to incorporate to the recommendation process. Some music is usually disliked by listeners with given demographic information. For example girls are seldom fans of ``Heavy Metal'' music, so we would like to decrease the chance of ``Heavy Metal'' music being recommended to girls. The situation is illustrated on the figure \ref{pic_rule}, the expected negative preference is displayed as a zig-zag line.
            
            \fig[10]{pics/intro_rule.png}{Applying domain specific rules for deprecating recommendations}{pic_rule}
            
            Moreover, some artists are more likely to be played in a given period, e.g. because they have released a new album recently or they are on a tour. Such artists should be recommended more often to listeners. This aritst property doesn't depend on the particular listener, it should just ``help'' the artist to get to recommendations for more users.
            
            \fig[10]{pics/intro_bias.png}{Using item property for recommendations}{pic_bias}
            
            The obtained \emph{compiled predictions} can be used directly for recommending or they can serve as an input for an ordinary recommender algorithm. More about recommending in the Last.fm dataset can be found in chapter \ref{veryfying_last_fm}. 
            
        \subsection{Main Features}
            \label{main_features}
            The main concepts of the thesis are:
            \begin{description}
                    \item[Problem analysis and design of a solution.] The main goal of the work is to analyze the problem of a universal recommender, to create an architecture of the recommender system, design its interfaces and provide an implementation draft. The intefaces should be usable in real-world applications.
                    \item[Domain independence.] The recommender should work on any domain it's addapted to. It can't rely on any domain-specific assumptions. 
                    \item[Using various relationships.] For the recommendation, the recommender should be able to use any number of relationships available in the domain.
                    \item[Recommending given relationship.] The recommender should be able to predict any given relationship, not just the ``rating'' relationship as most recommenders do.
                    \item[A recommender, not a framework.] The adaptation to the given domain should be simple and should require minumum changes in the parent system. As opposed to recommendation frameworks that give resources to implement a recommender, our system should be a complete recommender ready to be addapted and used on an arbitrary domain.
                    \item[Pluggable user interface.] The recommender should contain a web-based user interface for presenting the recommendations. The interface should be pluggable to an existing web application, so that it can look like a part of the system and the user doesn't have to leave system web pages to see his/her recommendations. 
                    \item[Verification on various domains.] The recommender should be addapted to at least three domains to verify its universality and usability of the recommender interfaces. 
            \end{description}
        \subsection{Thesis Classification}
            \label{classification}
                
                The recommender system research field can be divided into the following the following areas, as stated in \cite{probabilistic_analysis}:
                
                \begin{enumerate}
                    \item Gathering user preference
                    \item Algorithms transforming past user actions and other data to recommendations \label{algo}
                    \item Privacy, legacy and other aspects
                    \item Measuring recommender accuracy \label{measure}
                    \item Recommender system implementation
                \end{enumerate}
                
                The thesis primarily concentrates on \ref{algo}: generating recommendations from known data. The area \ref{measure} is also partly covered in the thesis, as the results of the recommender on various domains had to be compared to other known approaches. The resting areas are undoubtedly as important as the selected ones, however the selected fit the best to the demonstration of our universal recommender idea. 

                Finally we list the topics that are out of the scope of our work:
                \begin{description}
                    \item[Scalable implementation] The provided recommender aplication is meant as a prototype and isn't intended to be scalable for large datasets. 
                    \item[Central server for multiple systems.] A single Unresyst instance isn't intended to be used as a central server for multiple domains - a Unresyst instance always refers to a single domain. Unresyst doesn't deal with matching the same subjects and objects appearing in multiple systems. 
                    \item[Collecting user preference] Unresyst doesn't help the system collecting any user actions for recommending. Implicit and explicit user feedback can be used for generating recommendations in Unresyst, but it has to be handled by the outer system and passed to Unresyst in the form of business rules and relationships.
                \end{description}

\chapter{Analysis}
    \label{analysis}
    In the chapter we discuss the circumstances under which recommender systems are a preferrable option both for users and system holders. Later we describe the reasons for using our universal recommender (\emph{Unresyst}), we compare our recommender to existing solutions. We propose draft of a process model for activities related to running Unresyst. Finally we formally define the problem of recommending.
    
    Recommender system is a part of a web-based application, that uses data about users and their behaviour to provide them with items which are the most relevant to them. The recommended items are typically things that are liable to user taste, like books, music, news, etc.
    
    \section{Recommender System Applicability}
        \label{recommender_system_applicability}
        For a successful implementation of a recommender system, several conditions have to be fulfilled. A summary of applicability conditions for a collaborative filtering recommender can be found in \cite{collaborative_filtering}. We list some of them that are valid for any recommender, independently of the recommender algorithm.
        
        \begin{description}
            \item[Many items:] In the domain there are many items that might be interesting for a user. It is not possible for the user to browse all of them.
            \item[Choice based on taste:] The choice of the items depends on the taste of each user. If there were some objective criteria for recommending items to users the recommender system wouldn't be much helpful.
            \item[Taste data:] In the system there have to be some data about the users interacting with items that can be interpreted as expressing taste. It doesn't matter if these are explicit rating data or implicit capture of user behaviour, but there have to be some.
            \item[Homogeneous items:] The items in the domain have some common attributes, they can all be covered by taste data, e.g. they can all be viewed or rated.
        \end{description}
    
    \section{Recommender System Benefits}
        \label{recommender_system_benefits}
        The section summarizes reasons why recommender systems are useful for both users and system holders.
        
        \fig[8]{pics/use_case_recommender.png}{Use cases for a recommender system.}{pic_use_case_recommender}
        
        \subsection{Benefits for System Users}
            \label{benefits_for_users}
            In a web-system like an e-shop or an internet radio a user is overloaded with items. The system database typically contains thousands of items divided into several categories. The recommender provides user with items that are likely to be interesting without requiring him/her to search for them. This saves user's time and helps him/her spend more time exploring the interesting items than messing around uninteresting items. The provided recommendations are personalized, they reflect the past user's behaviour and available data, so the recommendations are likely to be much accurate. 
            
            In comparison to advanced multi-criteria search, recommender systems are better at reflecting users' preference in criteria that aren't easy to express and depend on the taste of the user. The advantage of recommender system is their user-friendliness - they don't require any explicit search terms, they just use the facts they already know about the user. This can be a significant advantage for inexperienced internet users. 
            
            Opposed to search engines, recommender systems present items ordered by the expected preference, which can be more accurate when taste is important. However, multi-criteria search can act as a supplement to a recommender system, for performing well defined search queries. E.g. if the user is absolutely certain he/she wants a red lap-top with the given display size at the lowest price, the multi-criteria search is the best option to find such a product.
            
            Recommender systems help users find novel items. When a user only browses and searches the system items, he/she usually gets stuck to a relatively small group of items. The recommendations usually contain items chosen by various criteria, so that they contain both items the user is familiar with and items that are likely to be interesting for the user, but the user wouldn't otherwise discover them.
            
            Apart from that, a recommender system can predict user's interest for a particular item. E.g. the last.fm festival recommender can predict user's interest in a particular festival based on the user's taste and the festival lineup \cite{lastfm_festivals}. This also saves user's time, he/she doesn't have to examine details of the items that aren't likely to be interesting for him/her.
        
        \subsection{Benefits for a System Holder}
            \label{benefits_for_holders}
            A satisfied user is a key for the success of a web-system business. If the user easily finds interesting items in the system, he/she tends to return to the system regularly, which results in a high visit rate. 
            
            In an e-shop, if a user easily finds items that are appropriate for him/her, he/she is more likely to buy them. In a non-retail system like an internet radio, the system holder can also profit from a user finding appropriate items quickly. The user spends more time on pages that provide interesting information for him/her, which leads to more appropriate context advertisements with higher earnings.
            
            Another interesting feature recommender systems provide to e-shop holders is the ability to include promoted items to recommendations. E-shop holders can artificially increase the recommendation rates of the promoted goods so that they apeear in recommendations for more users. However, this feature should be used moderately because it distorts the results of the recommender algorithm. A massive propagation of items that are promoted by the system holder but are not very interesting for particular users may lead to a loss of user's trust for the recommender.
            
            And last but not least, a recommender system provides a competitive advantage. Web business leaders like Google \cite{google_news}, Amazon \cite{amazon} or Yahoo! \cite{yahoo} have already implemented recommenders in their systems, for smaller companies a recommender system may be a key advantage over their rivals.
    
    \section{Universal Recommender Analysis}
        \label{universal_recommender_analysis}
        In the section we describe the position of the proposed recommender system (\emph{Unresyst}) on the market. We depict advantages and disadvantages of the Unresyst recommender, we compare Unresyst to existing sollutions. Finally we propose processes for incorporating Unresyst to a web-based system and for running a system with Unresyst.
        
        The proposed Unresyst recommender is a domain-independent recommender system that is able to use various relationships between the domain entities. Unresyst is an independent software component that logically stands outside the web-based parent system. It comminicates with the parent system through a defined API\footnote{API stands for Application Programming Interface.}. Detailed information on the system architecture can be found in the section \ref{architecture}. 
        
        Unresyst itself doesn't contain any domain-specific data or methods. In order to work correctly on the given domain, it has to be addapted to it. Addaptation data make Unresyst use domain knowledge for making recommendations. Addaptation is designed so that it's as easy as possible. Adaptation data are stored in the parent system and are used during the communication with Unresyst. Detailed description on the adaptation can be found in the section \ref{adaptation_data}. 
        
        In order to provide high quality recommendations, Unresyst can take use of any \emph{relationships} between the entities in the system domain. Additionally, the business knowledge can be transformed to \emph{rules} and used for generating recommendations. Both rules and relationships are stored in the addaptation data. See sections \ref{representing_rules}, \ref{representing_relationships} for details on rule and relationship representation.
        
        \subsection{Universal Recommender Applicability}
            \label{universal_recommender_applicability}
            
            Compaines that run big global web-systems generally have enough resources to develop their own recommender systems that are specifically designed for their needs. Therefore, Unresyst is aimed at small and mid-size web systems. The goal of the Unresyst concept is to provide companies a way to implement a recommender system without having to develop their own recommender solution, which is often both time and money consuming. With a bit of configuration, Unresyst can provide recommending accuracy comparable to a custom-made recommender system. We suppose the web-system application uses a database to store its data. The data are manipulated trough an SQL\footnote{SQL stands for Structured Query Language, a language most commonly used for structred data manipulation.} or ORM\footnote{ORM stands for Object-relational mapping, a technique used for manipulating data directly in the application without using SQL.} layer.
            
            \fig{pics/owner.png}{Choosing the way of recommender system implementation.}{pic_owner}
            
            Unresyst can take use of any attributes and relationships that can be tracked in the parent system. Data that can be used by Unresyst include but are not limited to:
            \begin{description}
                \item[User behaviour:] In recommendations we can use data about user viewing item pages, the time users spent on each page, analysis of user's mouse move and any other implicit feedback provided by users.
                \item[Explicit feedback:] We can also use the explicit user feedback, like rating on a scale, thumb up/thumb down rating, in systems where such mechanisms are available.
                \item[Demographic information:] In systems where demographic data are available, we can use them for making recommendations. For users we can use attributes like age, place of residence, or education. For items we can use the data about their manufacturers like country or size of the company.
                \item[Social relations:] In systems, where users interact between each other, the social data can be used for providing recommendations. We can use relationships between users like friends, sent personal messages or viewing other user's profile.
                \item[Other relationships:] Any other relationships between entities of the system can be used for making recommendations. Such relationships include user-defined tags which can be used for determining similarity of the entities marked with the same tag, or user's preference for items marked with a particular tag.
             \end{description}
             
             Recommendations produced by Unresyst can take into account both objective and subjective criteria. Objective criteria for recommending can be expressed in business rules (e.g. not recommending expensive items to users with low income). Subjective criteria, as the expressed preference for an item are used both for the user and users that are observerd to have similar taste.
             
             The most common operations for a recommender ,providing recommendations and prediciting the preference for a particular item, are performed in time independent of the number of the entities in the system. The exact recommendation and prediction time may vary between the recommender algorithms. However most of the presented current algorithm use some kind of recommendation index which enables them to perform recommendations in constant time.
             
             The Unresyst software component is logically independent of the parent system, it provides an API for all common operations. The API and the domain-specific configuration is made so that the adaptation to the domain and to the parent system is as easy as possible. Unresyst also contains a pluggable user interface for presenting recommendations to the user. The user interface can be incorporated into the parent system user interface so that the user doesn't have to leave the parent system in order to see the recommendations.
             
        \subsection{Comparison to Other Solutions}
            \label{comparison_to_other_solutions}
            In the section we compare Unresyst to other solutions that are available for a small to mid-size company that likes to implement a recommender system at a reasonable time and cost. Unresyst is laying somewhere between the presented options, using the advantages of all and minimizing their drawbacks.
            
            \subsubsection{Filtering Items in Queries}
                \label{filtering_items_in_queries}
                For a system holder, a minimalistic approach to item recommending is to implement item filtering in a query language (e.g. SQL) above the system database. This approach can be very efficient when the holder wishes to implement a small set of well-defined filtering rules, that don't imply user's taste. Such an implementation can be fast and cheap, as it doesn't require any significant changes to the system, nor incorporation of a third party component to the system. 
                
                \fig[4]{pics/options_a_own_circle.png}{Implementing recommendations directly in the application.}{pic_direct}

                However this approach works well only for well-defined and static filtering criteria that aren't costly to evaluate. With an increased size of the rule set, the maintainance of the queries becomes difficult. When the system holder wishes to implement some kind of evaluation of user taste, the situation even complicates. Complex queries combining various data can take a long time to evaluate, which results in slow generating of the system web pages and nervous users.
                
                Simple hard coded filtering queries don't allow exceptions to the expressed rules. E.g. if we set up a hard coded query for not recommending an item to users with the given demographic data, the item won't be recommended even if we have a high preference signs from other sources such as user behaviour.
                
                The Unresyst recommender offers a transparent way of managing the business knowledge that is used for generating recommendations. The rules and relationships aren't written in query language but in a more human-friendly form. The business knowledge is kept in one place and is separated from the recommender algorithm. Changing the significance of the rules and relationships can be done there too. All recommendations are produced using the given business knowledge. The rules and relationships are combined according to their significance.
                
                The recommender algorithm which is one of the Unresyst layers, can use complex techniques to exploit the business knowledge. Therefore the recommendations produced by Unresyst are generally more accurate. At the same time the algorithm uses a recommender index that makes the prediction time independent of the number of entities in the system. 
                
                The main disadvantage of Unresyst compared to the minimalistic option is the required initiatory effort required to start producing recommendations. Firstly, Unresyst has to be configurated for the system, which means specifying the subject and object domain, definition of the predicted relationship  and finally writing down the business knowledge in the form of rules and relationships. Then the recommendations have to be incorporated to the parent system - calling of Unresyst methods has to be added to neccessary places, the recommender user interface has to be incorporated to the system. However the initial effort pays off as the latter changes in recommender configuration can be done easily at one place.
                
                Running a system that uses a recommender involves some additional effort. The index of the recommender algorithm has to be built before the recommender is used. This can be a time-consuming action, depending on the algorithm and number of entities in the system. The recommender index has to be kept up to date by either rebuilding now and then or by continuously calling methods for index update. These methods keep update the index with every change in the system but they require some additional time during save and update of the system entites and they might be inavailable for some recommender algorithms. The issues of the recommender index however occur when running any recommender that takes constant time for recommending items.
                
                To summarize the comparison, Unresyst is a better option than filtering items in queries unless the system holder only whishes to implement a small set of fixed filtering rules, that don't need to be changed over time and he/she isn't interested in exploiting the rules by a recommender algorithm.
                
            \subsubsection{Using a Recommender Framework}
                \label{using_a_recommender_framework}
                The system holder can choose to implement a recommender based on a recommender framework library like Duine \cite{duine} or Mahout \cite{mahout}. These are software libraries providing implementations of common present-day algoritms like collaborative filtering or content-based algorithms. For details on recommender algorithms see the section \ref{algorithms}.
                
                \fig[8]{pics/options_b_library.png}{Implementing recommendations using a recommender framework.}{pic_framework}

                
                Recommender frameworks aren't real rivals to Unresyst as they can be used in the Algorithm layer of Unresyst. In this section we compare the usage of mere recommendation framework directly incorporated  into the system and the usage of Unresyst with a recommender algorithm below, no matter if the in-built recommender algorithm is used, or if the algorithm implementation is overtaken from a third party library.
                
                Most algorithms in recommender frameworks rely on presence of a single explicit preference indicator like rating. If a system holder likes to use more sources of negative or positive preference data, he/she has to care about converting the preference to the rating used in the recommender algorithm. Using multiple sources of preference data, like data about user behaviour, social data or demographic data about users, is necessary for the algorithm to provide good recommendations. Only recommenders that use all available knowledge can produce high quality recommendations.
                
                \fig[8]{pics/options_c_unresyst.png}{Implementing recommendations through Unresyst, optionally using a recommender framework algorithm.}{pic_unresyst}
                
                The API of most of the present-day recommender frameworks isn't very developer-friendly and let the developer deal with converting between the system entities and recommender entities. This requires additional programming. Moreover, the algorithm API often lacks methods for updating the entities. Therefore in order to propagate the changes in the system data to recommender, the system administrator has to rebuild the index of the recommender algorithm. The recommendations can't be made ``on-line'' from the current system data. Unresyst brings up a simple and complete interface for using the recommender in the parent system.
                
                In addition, Unresyst enables system holders to run multiple instances of a recommender in one parent system. E.g. there can be a product recommender and user group recommender in the system, that is working in one Unresyst installation, but is independent of each other and can be using different rules and relationships to produce recommendations. 

                
                To summarize the comparison, incorporating a recommender framework is usually complicated both techically and intellectually. This may be one of the reasons why the present-day recommender frameworks haven't been widely used in real world web-based systems. Unresyst adds a new layer above the algorithms that solves the problems with combining different sources of preference data and enables the system holder to incorporate the business knowledge to recommendations.
            \subsubsection{Using a Recommender Service}
                \label{service_through_api}
                Another option, the system holder can possibly use in future is implementing a recommender using a recommender service. The first attempt to provide a such a service is the Google Prediction API \cite{google_api}. The service is still in development in Google Labs, available for experiments only through a waiting list. Only little data about the way the service internally works is available for public. There's only one obvious disadvantage of the approach: all data that are to be used for recommending have to be passed and regularly updated through the API. This can raise privacy issues system owner's distrust.
                
                \fig[8]{pics/options_d_google.png}{Implementing recommendations using a recommender service}{pic_setup}

        \subsection{Unresyst Process Model Draft}
            \label{unresyst_process_draft}
            In the section we propose a design of processes related to Unresyst setup and maintainance. Note that this is only a brief simplyfied sketch illustrating how real processes could possibly look like. The actual usage of the system would be highly dependent on particular company, its environment and people. A more technical view on Unresyst setup and evaluation can be found in chapters about Unresyst architecture (\ref{architecture}) and evaluation (\ref{evaluating_recommender_results}).

            \subsubsection{Unresyst Setup}
                \label{unresyst_setup}
                After the system holder or the company management agrees on using Unresyst for recommending in their system, the setup activities may begin. One of the main roles in the recommender operation is the \emph{Domain Expert}. He/She is familiar with the business the system is operating in, knows a lot about entites and their relationships both in the real world and in the system. 
                
                \fig{pics/process_setup.png}{Unresyst Setup process, a draft of a process model.}{pic_setup}
                
                Firstly, the \emph{Business Analyst} interviews the \emph{Domain Expert} in order to find out the requirements for the recommender and type and ammount of data that is available for making recommendations.  The output of this activity is a report that thoroughly describes the purpose of the recommender and knowledge that is available for recommending in the parent system. The report should at least include the list of recommender instances that will be incorporated to the system and for each recommender it should describe the subjects and objects of recommendations, the description of the predicted relationship and finally a description of all relationships and business rules that are available for the domain. The report is prepared by the \emph{Business Analyst}, is approved by the \emph{Domain Expert} and is imperative for the later activities. This activity should be done properly, multiple iterations of interviewing and recording will be needed.
                
                The report is delivered to the \emph{Data Specialist}. \emph{Data Specialist} is a person highly familiar with the data model of the system. He/she transforms the report into an Unresyst configuration, which formally defines subjects, objects, rules and relationships for each recommender. After the configuration, the \emph{Data Specialist} performs the recommender build, evaluates the results of the recommender and verifies sample recommendations with the \emph{Domain Expert}. \emph{Data Specialist} tries improving the recommender evaluation by tuning the rule and relationship parameters, until a given accuracy threshold is reached.
                
                The \emph{Developer} is next to come. \emph{Developer} is familiar with the implementation of the parent system. He/she incorporates the Unresyst API calls to the appropriate parts of the system, includes the recommender user interface into the parent system interface.
                
                After enough tests have been performed, the version of the parent system using Unresyst is put into operation. Tests should include user-testing inquiring real users of the system.
                
            \subsubsection{Unresyst Maintainance}
                \label{unresyst_maintainance}
                
                Running a recommender system isn't just a matter of setup. Keeping the recommendation quality high requires a regular maintainance activity. The frequency of the maintainance tasks depend on many factors such as  domain dynamics and internal capacities of the company. It should be done at least a few times a year.
                
                \fig{pics/process_review.png}{Unresyst Review process, a draft of a process model.}{pic_review}
                
                Maintainance activites follow selected setup activities in order to improve accuracy of the recommender. \emph{Business Analyst} interviews the \emph{Domain Expert} to find out what has happened in the domain business since the last maintainance activity. Requests for collecting new types of user-data can be included. The news are delivered to the \emph{Data Specialist}, who incorporates them to the recommender configuration. He/She also revises the changes in the system that could have affected the recommendation sources and adujusts the configuration to use any newly available data. Finally he/she evalutes the recommender with the new configuration and tunes the parameters until the desired evaluation is obtained. The new Unresyst configuration and sample recommendations are consulted with the \emph{Domain Expert}. The new configuration is finally tested and put into operation.
        
    \section{Definitions}
        \label{definitions}
        XXXX TODO zkontrolovat, doplnit.
        In this section we give some basic definitions of terms and problems that appear in the whole thesis.
        
        \subsection{Basic Terms}
        \label{basic_terms}
            The basic terms used both in definitions and throughout the tesis are:
            \begin{description}
                \item[Subject]: Subject of a recommendation is an entity to which the recommender presents its recommendations. A subject can be a user as well as a user group or any other entity.
                \item[Object]: Object of a recommendation is an entity which can be recommended to subjects. Objects can be books, songs, or any other entities.  
                \item[Entity]: Entity is a subject, an object or any other thing that occurs in the domain.
                \item[Predicted relationship]: Predicted relationship is a subject-object relationship that we try to predict for making recommendations. An example of such a relationship is the \emph{likes} relationship between a user and an item. 
                \item[Expectancy of the predicted relationship]: For predicting a relationship we need a rate - a number determining the estimated probability that the \emph{predicted relationship} will ocurr between the subject and object. In other words, Expectancy can be explained as subject-object preference in means of the predicted relationship. In our user-item \emph{like} example, the expectancy would mean how much the user is likely to like the item. 
             \end{description}
        
        \subsection{Recommender System}
        \label{def_recommender_system}
            Informally, a recommender system is a system that presents some chosen \emph{objects} to a given \emph{subject}. The objects are chosen so that they are likely to invoke a positive response of the subject.
            
            Similarly to the recommender problem definition in \cite{survey}, we formally define the recommendation as choosing the object $o_s$ for each subject $s$, so that the object maximizes the subject's utility $u_R$:
            \begin{equation}
            \label{eq_recommender_problem}
            \forall s \in S: o_s = \underset{o \in O}{arg \  max \  u_R(s, o)},
            \end{equation}
            where $S$ is the subject domain, $O$ is the object domain. The usefulness of the object to the subject is measured by the $u_R$ function, $u_R: S \times O \to T$, where $T$ is a totally ordered set. 
            
            There are two differences to the definition in \cite{survey}. Firstly, we define our function on a \emph{Subject domain $S$}, instead of the User domain. In our view an adressee of a recommendation can be anything, not just a user. In some cases $S=O$, e.g. when we are recommending new friends to a user.  Secondly, we parametrize the utility function by the given relationship type $R$. In our system a recommendation can be done in the means of the given relationship type. 
            
        \subsection{Relationship Prediction}
            \label{def_relationship_prediction}
            \emph{Relationship Prediction} $\hat{u}$ is an approximation of the utility function $u$: 
            \begin{equation}
                \label{eq_relationship_prediction}
                \hat{u}: S \times O \to [0, 1]  \times E,
            \end{equation}
            where $E$ is a set of textual explanations.
            
            For a given subject-object pair, $\hat{u}$ gives:
            \begin{description}
                \item[Expectancy:] the predicted probabilitity of occurence of the given relationship type between the subject and the object. It's a number between $0$ and $1$. The value $1$ is reserved for the subject-object pairs, that are already connected by the relationship of the given type. Thus, the objects with relationship expectancy $1$ usually aren't presented. The recommended objects are usually presented ordered by the expectancy. The exact expectancy value doesn't have to be presented.
                \item[Explanation:] a textual explanation why the object has been recommended. For some recommender algorithms explanations aren't available.
                %\item[Relationship metadata values]: coming soon
            \end{description}

            For instance, if the object and subject domains are community server users and the relationship type is friendship, for Alice and Bob the recommender can give a relationship prediction of $0.75$, with an explanation, that they have four friends in common. This means that the predicted probability of friendship between Alice and Bob is $0.75$. 
            
            Our concept is similar to the one used in the Duine framework \cite{duine}. The prediction techniques in Duine give a \emph{Prediction}, \emph{Validity indicators} and an \emph{Explanation} for each subject-object pair. \emph{Prediction} is an estimation of subject's rating of the object. \emph{Validity indicators} determine the \emph{confidence} of the techinque when predicting the rating. Low values mean, that the technique isn't confident about the \emph{Prediction} for the given subject-object pair, e.g. it doesn't have enough information to make a valid prediction. \emph{Explanation} has the same meaning as the one in our recommender. 
             
            In a universal recommender we can't assume there will be a rating relationship between subjects and objects. Moreover, we are supposed to be able to predict any given relationship between subjects and objects, not just the preference expressed by the rating. In a Universal recommender, we only predict a $0/1$ indicator: there is the predicted relationship between the given subject and object, or there isn't. Hence we can shrink the prediction and confidence concepts into one - relationship \emph{expectancy}. 
            
            Let's show the reduction on an example. A recommender predicts, that \emph{Bob} will like the \emph{Five Days In Paris} book with $20\%$ probability. The like expectancy is $0.2$. For us, this is the same as predicting that Bob won't like it with $80\%$ probability. This is because, in our relationship representation, Bob either likes the book, or he doesn't. The events ``Bob likes the book'' and ``Bob doesn't like the book'' are complementary.
            
	    % like s 20% confidence neni to samy jako like s 20% expectancy. Confidence u like musi zacinat na 0.5. Pod 0.5 je to dislike - pomoci confidence se nejde prepnout z like do dislike.
            
            % napr. prediction 0, confidence 0.75 je to samy jako prediction 1, confidence 0.25. Protoze P(0) = 0.75 = 1-0.25 - protoze jevy 0 a 1 se vylucuji. 
            
            The dependency between relationship expectancy and prediction confidence is illustrated on the figure \ref{pic_expectancy_confidence}. Let prediction confidence be a function to $[0,1]$ determining how sure the recommender is about the given relationship prediction. Expectancy values just above zero indicate that the recommender is quite sure that there won't be the given relationship between the given subject-object pair. Expectancy values near $0.5$ mean low confidence for the prediction. Especially $0.5$ means that according to the recommender, the probability of the relationship occurence is the same as for non-occurence. Expectancy values close to $1$ mean that recommender is quite sure, that the given subject-object pair will be connected by the given relationship. 

            \fig[9]{pics/expectancy_confidence.png}{The dependency between relationship expectancy and prediction confidence.}{pic_expectancy_confidence}
	    
	    Expectancy can be useful for ordering the obtained recommended objects. For example, let's suppose we are predicting the ``like`` relationship and the list of recommended objects is ordered by the expectancy. At the beginning of the list there are objects the subject will probably like (the expectancy is close to $1$). Then there are objects the recommender is not sure about (the expectancy is around $0.5$). At the bottom of the list there are objects that will be probably disliked by the subject (the expectancy is close to $0$).
	    
	    On the other hand, expectancy isn't much intuitive for specifying the relationships in a system, so giving positiveness and confidence are used there (see \ref{representing_relationships}, \ref{representing_rules}).
	    
            In our universal recommender we don't support rating prediction directly. But as subject-object rating means a level of subject-object preference, we can estimate rating using our relationship expectancy. We only need to define mapping from relationship expectancy values to rating. Taking the subject and object from the previous example (Bob and Five Days in Paris), we can interpret Bob's $0.2$ like relationship expectation, to the rating 1 star on a 0 to 5 star scale. 

        \subsection{Recommendation}
            \label{recommendation}
            For the given subject, the \emph{Recommender System} or \emph{Recommender} performs a \emph{Recommendation} $\varrho$ -- it chooses at most $N$ subjects with the highest relationship prediction rate:
            \begin{equation}
                \label{eq_recommendation}
                \varrho: S \to \mathcal{P}_{\leq N}(O),
            \end{equation}
            where $\mathcal{P}_{\leq N}(O)$ is a $N$-limited powerset of $O$ (the set of subsets of $O$ of cardinality lower or equal to $N$).
            
            The recommender always chooses exactly $N$ objects, except the case where there are less than $N$ objects available for recommendation. The chosen objects are presented to the subject ordered by the Recommendation Rate.
            
            For instance, using the example in \ref{def_relationship_prediction}, the friendship recommender presents ten other community server users to Alice. The users are sorted by the relationship prediction rate which reflects the number of mutual friends.
        
        \subsection{Adaptation}
    
    \section{Operations in Recommender Systems}
        \label{operations}
        In a recommendation system, some common operations are:
        \begin{description}
            \item[Recommender setup:] After a configuration of the recommender is done, the recommender has to prepare itself for recommending objects. This operation can be pretty time consuming, as this doesn't have to be performed very often. 
            \item[Recommendation (see \ref{recommendation}):] Recommendation is the most common operation for a recommender system. Choosing objects with the highest Recommendation Rate for the given subject among all objects can be a very expensive operation. That's why most recommender systems introduce some kind of index, enabling the recommender to recommend objects real-time. This operation should be performed very fast, ideally in a constant time.
            \item[Prediction:] Prediction is used for estimating the subject's preference in a particular object. It can be used for direct displaying when browsing through the objects or for ordering displayed objects when browsing in an object catalogue. Usually it is not possible to store predictions for all subject-object pair, so the prediction has to be computed on-line. Therefore it has to be pretty fast.
        \end{description}
    
    \section{Related Work}
        \label{related_work}
        XXX TODO doplnit white paper a duine
        The recommender research area has been strongly influenced by the Netflix prize \cite{netflix_wiki}. In the years 2006-2009, the Netflix DVD rental company held a competition on improving their recommender, awarded by the grand prize of US\$1,000,000. To the competition participants, Netflix exposed a data set of over hundred millions of ratings. Over 48,000 teams from 182 different countries participated, the competition had a huge response in both scientific and mainstream media. A paper describing the winning solution was publicly released \cite{netflix_solution}. The competition brought benefits for the Netflix company as well as for the whole recommender research world \cite{netflix_benefit}  Unfortunately, the second Netflix prize was canceled after some user privacy issues \cite{netflix_end}.
        
        \subsection{Domain Independent Recommenders}
            \label{domain_independent_recommenders}
            The idea of a domain-independent recommender isn't completely new. The most notable project in this field is an open-source project called \emph{AURA} (The Advanced Universal Recommendation Architecture) \cite{aura}. The project was supported by Sun and later by Oracle, but since the end of 2009 there's been no activity on the source code repository. The experimental music recommender based on AURA, \emph{The Music Explaura} \cite{music_explaura} seems to be inactive. The project aimed to create a universal hybrid recommender system, combining the two most used approaches: collaborative filtering and content-based recommendation (see \ref{collaborative_filtering}, \ref{content_based_filtering}). The system should have been working above a data store. More on the project can be found in \cite{aura_wiki}.  
            
            Another notable work on universal recommender is a US software pattent application \emph{Universal system and method for representing and predicting human behavior} \cite{patent}. The text contains a mixture of marketing proclamations, ideas on the recommender architecture, description of recommender and machine-learning algorithms and ideas on capturing implicit user ratings. In our opinion, the recommending methods presented in the text could be working well only on very small sets of data, for larger data sets, the ammount of time needed for performing some basic operations wouldn't be acceptable. The final paragraph, trying to claim everything around, from vector object representation to capturing the action of user adjusting the volume on his music player, gives a negative example of where the idea of software patents can lead. As far as we know there's no functional recommender system based on this patent. 
            
            white paper, 
            Duine - trochu moc se tam pracuje s tim user ratingem. mixuju podobne pravidla a relationships jako on recommendation techniques. (minimalne mam podobne prostredky), ale nekaskaduju. 


\chapter{Recommender Algorithms}
    \label{algorithms}
    In the chapter we list and describe algorithms that are commonly used for recommending. For each algorithm we describe its possibility to be implemented as domain-independent, and the its capacity to use multiple data sources as an input.

    \section{Content-based Methods}
        \label{content_based_filtering}
        Content-based filtering methods are one of the oldest and most popular methods for recommending. The principle of these methods is recommending objects that are similar to some objects, the user liked in past. The similarity among the objects is determined from the values of their characteristics. 
        
        
        They are widely used in text-based applications, for recommending documents or web sites \cite{survey}. One of the implementations of a content based based recommender is the Music Genome Project \cite{wiki_genome}. A musician analyzes each song in the system, giving a value for each of the musical characteristics. 
        
        The figure \ref{pic_content_based} shows an example of a content based recommender. The known relationships are marked as full arrows, the calculated or inserted object similarity by the dotted arrow and the predicted relationship by the dashed arrow.
        
        \fig{pics/content-based.png}{Content-based Methods}{pic_content_based}

        \subsection{Definition}
        More formally, according to \cite{survey}, the utility function $u_R(s, o)$ of subject $s$, object $o$ and relationship $R$ is estimated based on the utilities $u_R(s, o_i)$ assigned by subject $s$ to objects $o_i \in O$ that are similar to object $o$. The method can be enhanced by introducing \emph{subject profiles} containing information about subjects' tastes. 
        \subsection{Benefits and Drawbacks}
        The accuracy of the provided recommendations strongly depends on the similarity determination. If the items are characterized properly and the subjects tend to like uniform sets of objects, the recommender can be pretty successful, as \cite{wiki_genome} mentioned above. However there are several drawbacks of the method, as mentioned in \cite{survey}:
        \begin{description}
            \item[Limited content analysis:] The set of characteristics assigned to each object is always limited and is never able to fully characterize the object. Moreover the values of the characteristics have to be determined either manually which is time-consuming or automatically which currently works well only for text documents. 
            \item[Overspecialization:] The method always recommends objects that are similar to some that the subject liked in the past. Therefore the recommender never broadens subjects' horizon by recommending diverse objects.
            \item[New user problem:] When a new subject emerges in the system and has no relationships to objects, the system cannot make any recommendations to the subject.
        \end{description}

        \subsection{Suitability for The Universal Recommender}
        In a domain-independent recommender we cannot assume that there are sufficient object characteristics available. The only way how to get object characteristics and similarities is to obtain them during the addaption to a new domain. As this is usually quite a complicated operation, the universal recommender wouldn't be much helpful for most of the domains. Therefore the content-based methods aren't very suitable for the universal recommender.

    \section{Collaborative Filtering}
        \label{collaborative_filtering}
        Collaborative filtering is currently one of the most widely used technique for recommending. Market leaders as Amazon.com, Last.fm or Digg.com use recommenders based on collaborative filtering \cite{wiki_collaborative}. 
        
        For recommending an object to a subject, the method uses relationships between other subjects and objects. For a given subject $s$, the algorihm finds subjects that have relationships to most of the objects that $s$ has. Recommended objects are then taken from other objects related to found subjects. 
        
        In the figure \ref{pic_collaborative} there is a simplified example of a recommendation made by collaborative filtering. The full arrows represent already known relationships. The two subjects both have a relation to one item and therefore they are treated as similar. The recommendation is marked by the dashed arrow. An object to be recommended is chosen from the similar subject's related objects so that the subject isn't related to the object.
        
        \fig{pics/collaborative.png}{Collaborative Filtering}{pic_collaborative}
        
        The collaborative filtering methods can be divided into several groups. The overview of the groups can be seen in the figure \ref{pic_collaborative_groups}), names of the techniques and algorithms belonging to the given groups are in italics.
        
        \fig{pics/collaborative_groups.png}{Classification of the collaborative filtering algorithms}{pic_collaborative_groups}
        
        By the manner in which the unknown relationships are predicted, collaborative filtering methods can be divided into two groups: \emph{Memory-based} and \emph{Model-based} \cite{survey}.
        
        \subsection{Memory-based Collaborative Filtering}
            Memory based (or heuristic-based) methods are historically the first collaborative filtering methods. In memory-based prediction methods, the predictions of possible relationships are counted as an aggreagate of the known subject-object relationships. The aggregate function can be a simple average or some more sofisticated measure using relative differences to average ratings or inter-subject similarity. 
            
            \emph{Neighbourhood methods} belong to this category. For recommending an object to a subject they use relationships of the neighbouring subject or object (depending on the recommender being subject-based or object-based). The neighbour is defined as the subject/object having the highest similarity to the given subject/object. The similarity can be counted in many ways, including the Pearson correlation coefficient \cite{survey}. 
            
            The memory-based methods can further be devided into two groups by the direction which is used for recommending: \emph{Subject-based} or \emph{Object-based}. 
            
            \subsubsection{Subject-based Collaborative Filtering}
                Subject-based (or user-based) methods are centered to the subjects. In this traditional variation, the similarity of subjects is computed. More formally, according to \cite{survey}, the utility function $u_R(s, o)$ of subject $s$, object $o$ and relationship $R$ is estimated based on the utilities $u_R(s_j, o)$ assigned to object $o$ by the subjects $s_j \in S$  who are similar to subject $s$. Usually the similarity between subjects is determined by comparing their relationships to objects. 
            \subsubsection{Object-based Collaborative Filtering}
                Object-based (or item-based) methods have been popularized by Amazon.com \cite{wiki_collaborative}. The principle of the algorithm remains the same, but the algorithm starts at the objects and similarity between objects is computed. Objects sharing the same related subjects are taken as similar. The objects recommended to a subject are taken from objects similar to those the subject is related to. The method can also be used for showing products that are related to a product that is viewed by an anonymous user, as can be seen in the Amazon.com product catalogue: ``Users that bought product $x$ also bought product $y, z$''. The easiest implementation of the item-based memory-based collaborative filtering is the \emph{Slope One} method \cite{wiki_slope_one}. 
                
                Another way how to measure the similarity is the cosine measure, which is used in the \emph{Item-to-Item} algorithm patented by Amazon.com \cite{amazon}. The objects are represented as vectors. To count similarity between two objects, subjects that have a relationship to both of these objects are taken. Each such subject represents a dimension in the object vectors, the value is determined from the subject's rating or $0/1$ (the subject has bought/viewed the object or not). The similarity between two objects is then counted as a cosine of the object vectors \cite{amazon}.

        \subsection{Model-based Collaborative Filtering}
            Model-based recommenders use machine-learning techniques to learn a \emph{model} that predicts unknown relationships. The known relationships are used as training data for the model. The machine-learning techniques include \emph{Bayesian networks}, \emph{latent factor models}, or \emph{artificial neural networks} \cite{survey}.
            
            Latent semantic models use vectors to represent subjects and objects \cite{bellkor_ieee}. For objects, the values in the vectors mean some characteristics of the object. This approach is similar to the one used in content-based filtering (\ref{content_based_filtering}). The difference is in obtaining the vectors: the values in object vectors aren't submitted by a human expert, both subject and object vectors are learned from the known data by various techniques. Therefore the technique is domain-independent. 
            
            Subject and object vectors allow to project the subjects and object into multidimensional space. Recommended objects are those that are ``near'' the given subject in the multidimensional space. Some common techniques for measuring the subject-object distance are vector cosine and dot product. Some dimensions can be coupled with some known object characteristics as genre for movies \cite{bellkor_ieee}. But the meaning of most of the dimensions can hardly be discovered, as they aren't designed by a human but a machine-learining technique. Consequently, the recommenders using matrix factorization usually aren't able to give reasons for their recommendations. 
            
            Figure \ref{pic_latent} shows some users and items projected to a simplified two-dimensional space. Their nature determines their positions in the space. Items that are near each user are likely to produce a positive response from the user and hence they are good for recommendations. 
            
            \fig{pics/latent.png}{Latent factor model recommender}{pic_latent} 

            \subsubsection{Matrix Factorization}
            \label{matrix_factorization}
            The main challenge in latent factor models is computing the subject and object vectors. One of the methods for computing them is \emph{matrix factorization}. The method was used by the BellKor team in the winning solution of the Netflix grand prize \cite{bellkor_ieee}. Since then the matrix factorization has become a dominant method for model-based collaborative filtering recommenders.
            
            The method is described in \cite{bellkor_ieee}. Relationships between subject and objects are projected to a subject-object matrix. For ratings, the values in the matrix are the subject's actual ratings of the appropriate object. For other relationships there are zeros and ones in the matrix. This matrix is decomposed into vectors so that the dot product between a subject and object vector gives the actual or predicted value on the appropriate coordinates in the subject-object matrix. The decomposition could be done by the \emph{single value decomposition} technique, but in \cite{bellkor_ieee} a better method is proposed: The known values are used directly to learn the vectors, using a minimization of the regularized squared error. The learning can be done either by the \emph{stochastic gradient descent} method or by \emph{alternating least squares}. The named methods are thoroughly studied in the section ???.
            
        \subsection{Benefits and Drawbacks}
        \label{cf_benefits_drawbacks}
        
        In general, collaborative filtering methods are currently the most used and the most successful methods for recommending. When properly used, they provide high accuracy and scalability for large ammount of data. However they have some drawbacks too \cite{survey}.
        \begin{description}
            \item[Cold start problem:] As for the conteng-based method, the system doesn't have any data about a new subject. For a user being a subject, this problem can be solved by asking the user to enter some data. This approach is used in the Netflix system. A new user is given a questionnaire for rating some chosen movies \cite{bellkor_2009}. Another solution to the problem is using a hybrid recommender (\ref{hybrid_recommenders}). 
            A similar problem occurs when a new object is added to the system, it's not related to any subject and therefore it can never be recommended. This can be solved also by a hybrid recommender (\ref{hybrid_recommenders}). 
            \item[Sparsity:] The subject-object matrix is usually very sparse - the number of known relationships is very small compared to the number of relationships that should be predicted. Therefore, in most of the collaborative filtering methods, the objects related to few subjects are seldom recommended. This drawback is overcome by some of the model-based methods, e.g. matrix factorization \cite{bellkor_ieee}.
            \item[Grey sheep problem:] This problem is mentioned in \cite{knowledge_spain}. In the system, there might be subjects whose preferences aren't consistently similar to other subjects. Therefore they don't belong to any preference subject group and they can't get any accurate recommendations.
         \end{description}
        \subsection{Suitability for The Universal Recommender}
        One of the biggest advantage of collaborative filtering is its domain independence. Generally, the algorithms don't assume any properties of subjects or objects, they just use the relationships between subjects and objects to make recommendations. Of course, the recommender tuned for a particular domain can't be used directly for other domain, but the core algorithm is domain-independent.
        
        The universal recommender proposed in \cite{white_paper} is based on the idea of matrix factorization, which is a model-based collaborative filtering technique. Therefore, the collaborative filtering methods are very suitable for a universal recommender.
    
    \section{Knowledge-based Recommenders}
        \label{knowledge_based}
        
        Although the main focus in the recommender research field is on collaborative filtering, possibilities of knowledge-based recommenders are still being studied.
        
        There are many approaches to knowledge-based recommending. One of them is presented in \cite{knowledge_burke}. The user interaction to the system is similar as in the case of performing a search. At first, the  user specifies an item that he/she likes. Then the system iteratively presents similar items to the user. The user further specifies his/her preferences, like ``I would like a more romantic/adventurous movie''. This continues until the user is fully specified with the presented item.
        
        One problem of the aproach is that the recommendations aren't personal. There're no user profiles in the system, so the recommendations are based only on data given by the user during the search. The author describes how to reduce this disadvantage in \cite{integrating_burke}. The items found by the knowledge-based recommender are sorted by the integrated collaborative filter. Another problem of this approach is bothering the user. The user has to fully specify his preferences in order to get some good recommendations. Although the system leads the user through the search, it can take a lot of time to find the right item.
        
        The article \cite{knowledge_spain} proposes a bit different approach. Their knowledge-based recommender is trying to solve the ``cold start problem'' (see \ref{collaborative_filtering}). When a new user registers to the system, he/she is asked to choose an example of an item he/she likes in the item catalogue. Then the user is asked to compare the item to some other items, using a scale from zero to one, determining how much the item is preferred over the other. An underlying algorithm exploits this knowledge to the whole item catalogue and uses the data for making recommendations. This approach is a bit better than the first described one, as it bothers the user only once - when he/she is registering. Nevertheless new users are more sensitive to being asked a lot of questions and there's a risk, that the user leaves for a rival system. The presented recommender is only a theoretical suggestion, there might be some problems with scalability to large numbers of users and items.
        
        Recommendation by ordering is also discussed in \cite{order}. The authors of the article describe an advanced algorithm for exploiting the known relative preferences to the whole domain. The performance evaluations of the presented algorithm look very promising. Nevertheless, obtaining reliable relative preferences without bothering the user is diffcult and requires some non-trivial domain knowledge. Therefore such a recommender isn't suitable for our universal recommender. 
        
        Another approach to knowledge-based recommender was used in the \emph{RACOFI} system \cite{racofi}. The system consist of a collaborative filtering engine (\emph{COFI}) and a rule applying agent (\emph{RALOCA}). The primary recommendation is done by COFI. The rules are then used for adjusting the recommendation rate or removing objects from recommendations. The rules are applied on \emph{objective} data we know about the subjects and objects, like age and genre respectively. 
        
        The \cite{racofi} report shows that rules can handle boundary cases by removing inappropriate objects for recommendations - e.g. removing too expensive objects when recommending to student subjects. They can also refine recommendations by applying some rules that were found empirically. We find the idea of applying rules for recommending quite interesting, especially when there's not enough data for making other types of recommendation. The other benefit of rule-based recommending is the ability to give explanations why the objects were recommended.

        \fig{pics/knowledge.png}{Knowledge-based Recommender}{pic_knowledge} 
        
        Accordng to \cite{knowledge_spain}, there are three types of knowledge, a recommender system can deal with:
        \begin{description}
            \item[Catalog knowledge] provides information about objects and their features.
            \item[Functional knowledge] provides information about how objects meet subjects' needs. 
            \item[User knowledge] contains information about subjects' needs. 
        \end{description}
        
        \subsection{Suitability for The Universal Recommender}
        Knowledge can give an added value to a recommender, as some rules are well-known and often cannot be easily extracted from the underlying data. Therefore, if a way how to enter some basic domain-specific rules is found, the knowledge based recommender can be included into the universal recommender. 
            
    \section{Other Domain-specific Methods}
        There are a lot more algorithms for recommending, but all of them rely on specific data that must be available about the subjects or objects for the recommender to work well. As these aren't acceptable for the universal recommender, we list only a few of them.
        \subsection{Social Networks and Link Prediction}
            In social networks, there are links between users, such as the \emph{friends} link. If these are available, the recommender can recommend an object according on what user's friends liked. A schematic picture of the a social network recommender can be seen in the figure \ref{pic_social}.
            
            \fig{pics/social.png}{Recommending in social networks}{pic_social} 

        \subsection{Demographic Filtering}
            When we have some additional information about subjects (users) such as nationality, residence, age or occupation, we can use for determining similarity between the users. A demographic filtering method can be used as an additional measure of user similarity when there's little known about the user's taste. An example of a recommendation made by a demographic filtering recommender can be seen in the figure \ref{pic_demographic}.
            
            \fig{pics/demographic.png}{Demographic Filtering}{pic_demographic} 

    \section{Hybrid Recommenders}
        \label{hybrid_recommenders}
        Hybrid recommenders combine two or more recommending methods in order to enhance their recommendations. There are several ways how to combine them.
         
        For enhancing the success of produced recommendations, we can use a hybrid recommender that uses all its underlying methods when producing any recommendation. The combined methods can be of various types, using various relationships among subjects and objects. A combination of content-based and collaborative filtering is quite popular, possibilities of combining the two methods into a single hybrid recommender are listed in \cite{survey}. The combination of memory-based and model-based collaborative filtering is often used in contemporary commercial recommenders, as in \cite{google_news} 
        
        A hybrid recommender can help to overcome some drawbacks of the recommendation methods, as the \emph{Cold start problem} (see \ref{cf_benefits_drawbacks} for explanations. In this case, when little data is known about a new subject and object, some subsidary recommendation method can be used. This subsidary method wouldn't be suitable for performing the most of the recommendations, but it can make the best of the little data that is available. This approach is used in the default strategy of the Duine recommender framework \cite{duine}.
        
        Figure \ref{pic_hybrid} shows a recommendation for a new user, performed by a hybrid recommender combining social links and collaborative filtering. 
        
        \fig{pics/hybrid.png}{Hybrid Recommender}{pic_hybrid} 
        
        \subsection{Suitability for The Universal Recommender}
        As presented in \cite{white_paper}, the specific combination of methods used in a hybrid recommender depends on the data available in the given domains. Therefore a hybrid recommender can't be generic. The combination of used recommenders would have to be chosen in the addaptation phase. Finding the right combination of recommenders for the specific domain can be non-trivial and thereby hybrid recommenders aren't suitable for a universal recommender. 

    \section{Conclusion}
        \label{algorithm_conclusion}
        In the chapter we have described all common contemporary approaches to recommender systems, their suitability for domain-independent recommending has been evaluated. In a universal recommender we cannot assume that any specific relationships or subject and object properties exists, so our choice narrows a lot.
        
        Our vision of using business rules for recommending intersects with the knowledge based recommender. \ref{knowledge_based}. However there will have to be a domain-independent mechanism for representing and combining the business rules.
        
        From the studied algorithms, the only one that is domain-independent by nature is \emph{collaborative filtering}. All the others are dependent on some specific features of subjects or objects, or they suppose some specific relationships. Therefore, our universal recommender should be based on a collaborative filtering algorithm. 
        
        We have noted, that there's a gap between our requirements for a universal recommender system and collaborative filering algorithms: We would like to make use of multiple data sources including object and subject similarity, and domain specific rules. The collaborative filtering in its typical implementation takes only a single source of data - subject-object rating. The gap between our requirements and the input of a collaborative filtering algorithm should be filled by the Unresyst application. It should process all the inputs it has into a single subject-object preference prediction. This prediction can be then used directly for recommending or it can serve as an input for a common collaborative filtering algorithm.
        
        There are a lot of types of collaborative filtering algorithms, as can be seen in the \ref{collaborative_filtering} section. The algorithms differ in many aspects as time complexity, accuracy of the predictions or possibility to reflect the updates in the parent system. Each parent system has its own requirements on the named aspects and therefore Unresyst shouldn't be bound to a particular algorithm. Rather than that it should be able to use an arbitrary collaborative filtering algorithm in its algorihm layer. When implementing a recommender to a system we should be able to choose whether to use the predictions directly for recommending or to choose the right algorithm to fit the domain properties and needs.
        

        \subsection{Combining Knowledge-based and Collaborative Filtering Recommenders}
            The only method that wasn't generalized by the universal recommender proposed in \cite{white_paper} is the knowledge-based method. As we have shown in \ref{knowledge_based}, simple domain-specific rules can enhance the recommendation accuracy, especially when there's little preference data available. Hence, incorporating a possibility to enter some simple domain-specific set of rules when addapting the universal recommender to a domain, would be interesting. We found a few options how to merge the evaluation of knowledge rules with collaborative filtering:
            \subsubsection{A hybrid recommender for knowledge-based and collaborative filtering}
            
                \fig[7]{pics/knowledge_cf_hybrid.png}{Combining Collaborative Filtering and Knowledge Based Recommender as a Hybrid Recommender}{pic_knowledge_cf_hybrid}
                 
                In this variation there're independent knowledge based and collaborative filtering recommenders. This approach was used in the RACOFI system \cite{racofi}. For a relationship prediction, if a rule is available, it is used for predicting the relationship together with the underlying collaborative filtering algorithm. If not, only the collaborative filtering is used. Although this is a possible combination of the recommenders it has some significant drawbacks. The method introduces a tension between the two recommenders. The results of the collaborative method, which should be universal are in some cases distorted by the knowledge recommender. This problem would lead to incorrect learning in the model-based algorithms, as some manipulations are done outside the model and therefore the method cannot fully affect the resulting predictions.
                
               

            \subsubsection{Using the knowledge-based predictions as an input for collaborative filtering} 
                Alternatively, using the business rules given during the addaptation to a specific domain, we can generate a prediction (a kind of rating) that is later used in the underlying collaborative filtering algorithm. The prediction is available for subject - object pairs, for which some rules can be applied. The rules are only used during the initial recommender build to provide an input for the collabarative filtering. The recommendations then are done solely by the collaborative filtering algorithm. The advantage of the approach is, that the information from the knowledge-based algorithm is available in the initial phase and can be used for the collaborative filtering model build. 
                
                \fig[7]{pics/knowledge_cf_above.png}{Using predictions from Knowledge based recommender as an input to Collaborative Filtering}{pic_knowledge_cf_above}
            
            
            For the given reasons we choose the second option. Another advantage of this approach is that the recommendation time will be dependent only on the recommender algorithm. The implementation of the chosen approach is thoroughly described in the chapter \ref{architecture}.
        
\chapter{Business Rules and Relationships in Studied Systems}
    In the chapter we analyze selected systems where the Unresyst recommender could be used. As we don't have a direct access to the system databases, we use datasets\footnote{Dataset is a set of text files containing some part of data inlcuded in the system database}. The first two datasets - Last.fm and Flixster are publicly available. The third one (Czech travel agency e-shop dataset) was made accessible to the thesis author by the courtesy of the system administrator.
    \section{The Last.fm Dataset}
        basic data about both subjects and objects, relationships
        \fig[14]{pics/lastfm.png}{The data model of the Last.fm dataset}{pic_last_fm}

    \section{The Flixster Dataset}
        classic collaborative filtering having additive social data.
        \fig[8]{pics/flixster.png}{The data model of the Flixster dataset}{pic_flixster}
    
    \section{The Travel Agency Dataset}
        Different kinds of implicit feedback
        \fig[18]{pics/travel2.png}{The data model of the Travel Agency dataset}{pic_travel}
    
    \section{Relationship Abstraction Summary}
        \label{relationship_abstraction_summary}
        This section summarizes the type of rules and relationships that appeared in the studied systems. 

\chapter{Universal Recommender Design and Implementation}
    \label{design_and_implementation}
    TODO projet, doplnit konkretni priklady z uvodu
    
    The chapter describes how the Universal Recommender was implemented. We describe the high-level architecture of the Universal Recommender from outside, then we describe the layers of the program architecture. Finally we give a more detailled overview of the inner classes.

% recommendation rate nejak uzpusobit, zavest special konstantu - pro objekty ktere uz subjekt ``vlastni'' - takovy zaklad konfigurace, kdyz to ma, tak mu to nenabizim. 
    \section{Universal Recommender Architecture}
        \label{architecture}
        The Universal Recommender is designed so that it's independent of the domain of the subjects and objects, working only with the abstract relationships. The set of relationships can be extended easily. Several instances of the recommender can be run on a single system, so the Universal Recommender can run with various configurations recommending various objects to various subjects.
        
        The recommender doesn't have to be directly a part of the parent system, its database is logically independent of the parent database system. The parent system and the recommender communicate only through the interfaces, there are no implicit links on the application nor on the database level. Hence the recommender could be easily run on an independent server.
        
        The figure \ref{pic_unresyst_adaptation} shows an example how Unresyst can be adapted to a domain. In the example we create two recommenders for a domain. A domain expert firstly creates the desired recommenders. In the example it's a \emph{Gear Recommender} and a \emph{Friend Recommender}. Each recommender has two interfaces: \emph{Adaptation Interface} and \emph{Runtime Interface}. The domain expert uses the Adaptation interface to adapt Unresyst to the Tennis domain and performs necessary setup to put the recommenders into operation. 
        \fig{pics/unrest_adaptation.png}{Adaptating Unresyst to a domain done by a domain expert.}{pic_unresyst_adaptation}
        
        In the figure \ref{pic_unresyst_runtime} there is a schema of how a system using Unresyst operates. The system user accesses the system as usually through its graphical interface (GUI). The Unresyst GUI which is a part of Unresyst is plugged into the Tennis Server user interface and it presents recommendations to the user. The Unresyst GUI as well as the Tennis Server uses the Runtime Interface of both recommenders to get recommendations and to provide information needed for making recommendations. Both recommenders transfer the calls to the Unresyst module. The Unresyst module generates recommendations and stores them in a database. Recommendations are provided on demand.  
        \fig[17]{pics/unrest_runtime.png}{Unresyst common usage.}{pic_unresyst_runtime}
        
        obrazek architecture:
            Specific Recommender holds the domain-specific data.
            Recommender provides a domain-independent interface for creating a recommender model, getting recommendations and updating the recommender model.
            Abstractor translates the domain-specific objects into universal ones, converts the given business rules into relationships among subjects and objects.
            Aggregator aggregates all renationships into a single one for subject-object, subject-subject and object-object pairs.
            Recommender Algorithm uses the known relationships among subjects and objects, exploits them to predict all subject-object relationships of the given type.
        
        obrazek build:
            During the build, domain data that have been entered by the domain expert are used for creating a recommender model. 
            Recommender just passes the call to other layers.
            Abstractor goes ove rhe subjects and objects, evalutes the business rules on them, introduces a new relationship or bilas for each rule. It converts subjects and objects to a universal representation that would be used in the rest of Unresyst.
            Aggregator aggregates all relationships int o a sinle one for subject-object, subject-subject and object-object pairs, using the given weights. It does the same for biases.
            Recommender Algorithm uses the aggregated relationships to learn a recommender model.
        
        obrazek class diagram:
	    Classes are displayed as rectangles, objects as rectangles with round corners. All the classes are \emph{purely static} - there are no instances of the classes, the classes contain only class methods. They act as singleton objects.
	    The diamond relationships mean that the given class/object can be accessed only from the containing class. 
    \section{Adaptation Interface}
        \label{adaptation_interface}
        \subsection{Representing Rules}
            \label{representing_rules}
            
            During the adaptation phase, the domain expert can introduce business rules that will be used for creating recmmendations. As in \cite{racofi}, our rule consists of a \emph{condition} determining when the rule should be applied, and an \emph{action} defining what should be done if the condition is satisfied. The representation should use an easy human-editable notation, so that the rules can be easily added and later edited. 
            
            The RACOFI framework \cite{racofi} uses two types of actions: \emph{Modify} that modifies the predicted subject's object rating by a given constant and \emph{Not Offered} that excludes an object from subject's recommendation.
            
            Our rules aren't modifying predictions, but they serve as an input for the predicting algorithm. Therefore we will use absolute values, not relative values as in RACOFI \emph{Modify} rules. The \emph{Not Offered} rule type can be represented by a rule giving minimal value, so we won't have a special rule type for it. 
            
            In our rules we would also like to represent inter-entity similarity. Hence we will use the following types of rules:
            \begin{description}
                \item[Subject-object rules] defining subject-object interactions that can be used for recommending objects to subjects.
                \item[Subject-subject rules] defining similarity between subjects.
                \item[Object-object rules] defining similarity between objects.
             \end{description}
            
            There are several ways how to represent rules. The first studied one is \emph{RuleML (Rule Markup Language)} \cite{ruleml}, a XML-based markup language for representing rules. The language is very powerful, having the same expresiveness as declarative programming languages\footnote{There are serveral convertors between the \emph{Prolog} programming language and RuleML, e.g. \cite{ruleml_prolog}}. RuleML was used for entering rules into the RACOFI recommender system \cite{racofi}.
            
            Creating and editing rules in RuleML isn't very convenient as creating and editing any other XML-based document. That is partially solved by a shortened notation \cite{ruleml_short}, but even that isn't very comfortable to a user that isn't experienced in declarative programing. Another drawback of using RuleML for our purpose is its generality. The set of conditions and actions we'd like to represent is very limited and therefore we don't need such a powerful language.
            
            Another option would be to directly use a logic programming language as \emph{Prolog}. This option has the same drawbacks in over-generality and user-unfriedliness as RuleML. Additionally we would have to incorporate a logic programming language interpreter to Unresyst.  
            
            A better option is to implement our own \emph{Object-oriented rule representation}, where we represent rules as instances of a rule class. In the addaptation phase, the domain expert instantiates the pre-defined classes to create  business rules.
            
            In the figure \ref{pic_semantic_network} there is an example of a semantic network that can be a part of the parent system. The network belongs to a shoe e-shop. Alice and Bob are users living in the same city. Alice has searched the word ``trainers'' which is a part of the description of the pictured trainers. In the trainer shoe description there's also the word ``comfortable'', which is also a part of the description of the displayed rubber boots. Bob has viewed a profile page of the trainers. The trainers and the rubber boots were made by a manufacturer seating in the city where Alice and Bob lives.
            
            \fig{pics/semantic_network.png}{A sample semantic network for demonstrating rules and relationships.}{pic_semantic_network}
            
            The \emph{expectancy} concept (\ref{def_relationship_prediction}) is powerful but not very intuitive for defining the impact of the rules on predicting relationships. By defining a rule with expectancy we would be able to indicate positive as well as negative impact on predicting the given relationship because low values of expectancy have negative impact on preference and high values positive. Defining directly the expectancy of a rule would result in complicated functions and could lead to confusion and misinterpretation. Hence, for rule definition, we use a less general but more intuitive concept of \emph{confidence} and \emph{positiveness}.
            
            Each rule is either defined as \emph{positive} or \emph{negative}. Positive rules increase the prediction of the given relationship, negative rules decrease it. Each rule additionally has a confidence function defining how strong (positive resp. negative) the rule is for the given pair of entities. Events that can have both positive and negative impact should be represented by two rules.
%             synergic
            
            % kdyz chces udelat relationship ktere kdyz neni, tak je to negative, tak si udelej dve relationships
            
            %to samy u rules - idea je aby to pocitalo jenom s tim co mu explicitne zadas. to ze mu reknes, nedoporucuj zimni boty jizanum jeste neznamena doporucuj zimni boty severanum - pokud to chce, at si na to explicitne zada pravidlo.
            
            %expectancy mu vubec nedovolim zadavat - to si budu pocitat sam.
            
            In the examples, we will be predicting the \emph{like} relationship, representing the preference of the user to the given shoe pair. We will demonstrate the rule definition on the following rules:
            \begin{enumerate}
                \item \label{ex_s_o} If a user is from a city in the south, we won't recommend him/her winter shoes (negative).
                \item \label{ex_s_s} If two users are about the same age, they are considered similar (positive).
                \item \label{ex_o_o} When two pairs of shoes have in their description some common words, they are considered similar (positive).
            \end{enumerate}
            
            Note that we define only one side of the rules (either positive or negative). E.g. by defining that we won't recommend winter shoes for southern users, we don't say that we would like to recommend winter shoes to northern users. If we wanted to extend the rule this way we would define a new positive rule. 
            
            For our object-oriented rule representation we need to define a class which instances hold conditions, actions and some additional data. As we have showed, the only possible actions are determining the expectancy of the subject-object relationship and determining inter-entity similarity. Therefore actions will be represented as functions giving an expectancy or similarity respectively. The rule objects contain:
            \begin{description}
                \item[Condition:] A boolean function determining whether the rule can be applied to a given entity pair. The function is defined depending on the rule type:
                \begin{description}
                    \item[Subject-object condition] $C_{so}:S \times O \to \{False, True\}$. A function takes a subject-object pair and determines whether the rule can be applied to the pair. Example \ref{ex_s_o}: If the user $s$ is from a city that is in south and the shoes $o$ are winter shoes, the condition evaluates to \emph{True}. Otherwise it's \emph{False}
                    \item[Subject-subject condition] $C_{ss}:S \times S \to \{False, True\}$. A function takes a subject-subject pair and determines whether the rule can be applied to the pair. Example \ref{ex_s_s}: If we know the age of both of the users, the condition is \emph{True}, otherwise it's \emph{False}.
                    \item[Object-object condition] $C_{oo}:O \times O \to \{False, True\}$. A function takes an object-object pair and determines whether the rule can be applied to the pair. Example \ref{ex_o_o}: If the descriptions of the shoes share some words, the condition is \emph{True}, otherwise it's \emph{False}. 
                \end{description}
                \item[Is Positive:] A  boolean constant (\emph{True} or \emph{False}) for determining whether the rule is positive for the predicted relationship or negative.
                \item[Confidence:] A function determining the strength of the subject-object preference in means of the predicted relationship or subject-subject/object-object similarity in a positive or negative way.
                \begin{description}
                    \item[Subject-object relationship confidence] $D_{so }:S \times O \to [0,1]$. A function takes a subject-object pair and gives a confidence, that the \emph{predicted relationship} appears (when positive) or doesn't appear (when negative). High values mean strong confidence. Low values mean that the rule is unsure about the impact (positive or negative) for the given subject-object relationship - that makes a similar effect as if the condition $C$ wasn't satisfied for the subject-object pair. Example \ref{ex_s_o}: We can use a linear function. The more southern the city is, the higher is the resulting confidence. Or we can simply remove the shoes from the user's recommendation by always returning $1$.
                    \item[Subject-subject similarity] $D_{ss}:S \times S \to [0,1]$. A function takes a subject-subject pair and determines similarity between the subjects. The higher the expectancy, the more similar the subjects are, according to the rule. Example \ref{ex_s_s}: Our function returns a normalized difference between the age of the two users. 
                    \item[Object-object similarity] $D_{oo}:O \times O \to [0, 1]$ A function takes an object-object pair and determines similarity or dissimilarity between the subjects. The higher the confidence, the more similar (or dissimilar when negative) the objects are, according to the rule. Example \ref{ex_o_o}: We can use a function returning the number of common words divided by the number of words in the description.
                \end{description}
                \item[Weight:] $w \in [0,1]$ A constant between $0$ and $1$ determining the strength of the rule. Weight, unlike confidence, is independent of the particular entities on which the rule is evalutated. In our example, the number \ref{ex_s_o} will have a high weight (e.g. $0.8$), because it is quite specific. Other rules would have lower weight, e.g. $0.1$.
                \item[Description:] A text explaining the meaning of the rule. Descriptions can be used when presenting recommendations to users. In the text there can be gaps that that will be filled with a textual representation of entities. Our example rule \ref{ex_o_o} can have a description ``The shoe pairs \{object1\} and \{object2\} are similar because their descriptions contain some words in common.''
            \end{description}
            
            Such rules can represent each of knowledge types described in \cite{knowledge_spain}, described in the section \ref{knowledge_based}. Catalog knowledge can be represented by rules accessing object properties in their Condition and Confidence functions. Functional and user knowledge can be representing by rules using the relatioships between subjects and objects. 

        \subsection{Representing Relationships}
            \label{representing_relationships}
            
            Apart from defining business rules, the domain expert can define which relationships are relevant for performing the prediction. This is done when adapting a system to Unresyst.
            
            We have some specific requirements on the relationship representation. In the system there can be various entities, not only subjects and objects. The relationships can also span such entities. In our example on the figure \ref{pic_semantic_network} there're are the ``city`` entities, which aren't subjects nor objects but we use them in rules. Secondly, the relationships can have various relevance for predicting the given relationship. This should be implemented by assigning weights to relationships. 
            
            We would like to represent relationships of the following types. The relationships don't have to be direct - on the path from subject/object to subject/object there can be an entity of any type. 
            
            As for the rules, there can be both positive and negative relationships. Positive relationships increase the preference or similarity for the relevant entity pairs, negative relationships decrease it.
            
            The following examples are related to the figure \ref{pic_semantic_network}.
            \begin{description}
                \item[Subject-object relationships] indicate a subject's preference for the given object in means of the predicted relationship. In our example, if Bob has viewed a profile page of the trainers, we suppose he is quite interested in them (positive).
                \item[Subject-subject relationships] indicate similarity among subjects. For example if Alice and Bob live in the same city they are considered similar (positive).
                \item[Object-object relationships] indicate similarity among objects. For example if the trainers and the rubber shoes were made by the same manufacturer they are considered kind of similar (positive).
            \end{description}

            Obviously, the requirenemts on the relationship representation are very similar to the requirements we have set on rule representation. Hence, we can use the rule representation for relationships with some corrections:
            \begin{description}
                \item[Condition:] The boolean function means whether the given subjects/objects are in the relationship. The forms of the function remain the same as described in the section \ref{representing_rules}. In the subject-object example, the Condition is a function returning \emph{True} if the user has viewed the profile page of the shoes, otherwise it returns \emph{False}.
                \item[Is Positive: ] A  boolean constant for determining whether the relationship is positive for the predicted relationship or negative. Works analogously to the Is Positive value in rules.
                \item[Confidence:] The function won't be needed for representing relationships. If the Condition function returns $True$ for a subject/object pair the pair surely is (when positive) or isn't (when negative) in a relationship. Hence, such a function would always return $1$ for relationhips.
                \item[Weight:] We need a way how to define the relevance of the relationship for predicting the relationship. Weight can be used on this purpose. In our example the ``viewed profile'' relationship would have higher weight than the others because it's the most specific relationship out of the three. 
                \item[Description:] The textual explanation can be used for clarifying the meaning of the relationship. ``\{subject\} has viewed the profile of \{object\}.
             \end{description}
            
            Such a representation can use semantics of a system independently of its data model. There doesn't have to be a direct link between subjects/objects in the data model to define a relationship. For example Alice has searched for the word ``trainers'' which is in the description of the displayed trainers. Even though there isn't a direct connection in the data model, we can represent such a relationship in our system. Moreover, the relationships can be taken from various sources, e.g. multiple databases, data stores, or log files. The only thing that has to be provided to Unresyst is an implementation of a function returning whether the given subjects/objects are in the relationship.
            
            This representation is a reduction of the full semantic representation used in \cite{white_paper}. The authors propose using all system entities and relationships for recommending. This approach has some significant drawbacks. Firstly, it's not clear how to assign weights for relationships between entities that are not subjects or objects. Such relationship can have a varied meaning in the context of different relationships. In our example, we can use the user-city relationship both in subject-subject similarity relationship (Alice and Bob are from the same city) and in subject-object preference (Alice prefers shoes that are made in the same city where she lives). The significance of the user-city relationship vary in these two contexts and there's no clear way how to statically assign the weight to the user-city relationship. The second drawback of the \cite{white_paper} approach is that most of the main-stream recommender algorithms use only subjects, objects and relationships between them. Therefore the choice of a recommender algorithm is much more limited.
            
            The relationships between entities that are not subjects or objects can be used in our representation as well, but only those that are on a path in a semantic network from a subject to an object, or subject to subject or object to object. For example we can use words searched by users on a path from users to shoes. 
            
            To our relationship definition we can include a relationship of any type:
            \begin{description}
                \item[One-to-one relationships] can be included by directly traversing the relationship. For example a connection between a shoe pair and its profile page. 
                \item[One-to-many relationships] can be included by looping through all related entities of an entity. For example, all shoes a user has viewed are from the same manufacturer. Or we can test whether a given entity is in the related entities of another entity, e.g. we can test if the shoe pairs are from the same manufacturer.
                \item[Many-to-many relationships] can be included in the same means as the one-to-many relationships. E.g. the shoes are one of those the user has viewed. 
             \end{description}
             
             \subsection{Representing Relationship to Predict}
                \label{representing_relationship_to_predict}
                During the adaptation phase, the domain expert has to define which relationship should be predicted. For example, if we want Unresyst to predict which pair of shoes a user would like, we need to tell Unresyst somehow.
                
                This is done in a way similar to defining relationships that are relevant for recommendations. The only attribute that can be ommited is the \emph{weight}. The condition and the description remains as described in the section \ref{representing_relationships}. 
            \subsection{Representing Bias}
                mam subject/object bias, subject v podstate neovlivni doporuceni/nedoporuceni, jen upravuje vysi expectancy. Object naopak ovlivni
    \section{Applying Rules}???
        BFS with the given depth
        \subsection{Matching Rule Conditions to Entities and Entity Pairs}
            \label{matching}
            traversing the pairs, testing condition, optimalization - provide a generator function
            abstractor.
        \subsection{Aggregating Similarities and Biases}
            \label{aggregating}
            aggregator, jak se to kdyz se to sejde see \ref{combining}.
        
        \subsection{Compiling Rules to Preference Predictions}
            \label{compiling}
            compilator
            predicted relationship + similarity, subject-object rules, bias, 
            ukazat na prikladu
            
        \subsection{Combining}
            \label{combining}
            deje se na dvou mistech 
            combining: aggregating phase (biases, similarities) ->, compiling phase (preferences) -> combined preferences,. 
            \subsubsection{Twisted Average}???
                
                \begin{equation}
                    \label{eq_expectancy_combination}
                    f(x) = \left\{\begin{array}{ll}
                            2^{n-1}x^n & \textrm{if $x\in[0,\frac{1}{2}]$}\\
                            & \\
                            1-2^{n-1}(x-1)^n & \textrm{if $x\in(\frac{1}{2}, 1]$}\\
                        \end{array} \right.
                \end{equation}
            \subsubsection{Mycin}
                Confidence factor nevimco, bude se muset lehce ztransformovat.
            \subsubsection{Bayesian}
                $C_{so}$: event, $s$ chooses $o$\\
                $E_{Rso}$ event, rule $R$ covers $s$ - $o$ prediction
                \begin{equation}
                    \label{eq_bayes1}
                    P(C_{so} | E_{Rso}) = \frac{P(E_{Rso} | C_{so}) P(C_{so})}{P(E_{Rso})}
                \end{equation}
                hh\\
                $CPair$: a set of s-o pairs, s has chosen o\\
                $Pair_R$: a set of s-o pairs, $R$ predicts s-o expectancy\\
                $S$: a set of subjects\\
                $O$: a set of objects\\
                $P(C_{so}) \simeq$ expectancy given by $R$\\
                $P(E_{Rso}) \simeq \frac{|Pair_R|}{|S||O|}$\\
                $P(E_{Rso}|C_{so}) \simeq \frac{|CPair \cap Pair_R|}{CPair}$\\
                \begin{equation}
                    \label{eq_bayes2}
                    P(C_{so} | E_{R_1so} \cap E_{R_2so}) = \frac{P(C_{so}) P(E_{R_1so} | C_{so}) P(E_{R_2so} | C_{so} \cap E_{R_1so})}{P(E_{R_1so}) P(E_{R_2so}|E_{R_1so})}
                \end{equation}

    \section{Implementation}
        \subsection{Addaptation Interface}
        misto condition generator
        \subsection{Data Model}
        datovy model - subjekty, objekty v jednom, definice, indexy, agregator si to radi a pak to bere jak to jde
        Vychytavka se symmetric relations. Poradi: v s-o prvni subject, vsude jinde to co ma mensi id tak to prvni.
        \subsection{Runtime Interface}
            jak tam vracim uzasny miry a vysvetleni, jak je to diky buildu rychly. 
        \subsection{Recommendation Viewer}
            \label{viewer}
            The recommendations made by the Universal Recommender can be viewed in a web based application called \emph{Recommendation Viewer}. The application shows recommendations for a chosen subject. It is independent of the object and subject domain. The page for viewing the recommendations can be easily embedded to a webpage.
        
        ...
\chapter{Verifying the Universal Recommender on Real-World Data}
    \label{adapting_to_existing_systems}
    The process of adapting the Universal Recommender to some existing systems is described in the chapter. The chosen systems work on various domains. Each system has some API, so that the Universal Recommender can easily get data about the objects, subjects and their relationships. The way how to run the Universal Recommender in several instances for a system is described here. Some basic rules for the Universal Recommender configuration are given.
        \subsection{Flixster data set}
            z megamnozstvi jsem udelal min - podmnozina uzivatelu, z prvnich 105000 radku friendu, k nim nalezejici ratingy, uzivatele bez hodnoceni smazat, ponevadz nejsem schopen je nijak testovat - je to akorat spam
        \subsection{Last.fm}
            \label{veryfying_last_fm}
            zpusob vyberu z megadatasetu
            musel jsem vyhazet tagy, ktere nejsou sharovane mezi vic artisty, byly jich dve tretiny.
        \subsection{Travel agency}
            byl smaznul jsem i ostatni implicitni feedback z train setu - feedback z budoucnosti neznam. 
        
        implementacni vychytavky:
            symetricke relace serazene podle idecka, zarucene bude s1 s2 a uz ne s2 s1
            
            pridani toho generatoru do pravidel
        ...

\chapter{Evaluating Recommender Results}
    \label{evaluating_recommender_results}
    In the chapter we describe experience with running the Universal Recommender on various systems. The quality of the recommendations are evaluated for each system. The results are compared to the recommender contained in the system, where relevant. 
    
    metriky kde se porovnava poradi v listech jsou mi na pytel, jelikoz v test setu nemam poradi. 
    hh\\
    $p_{so}$: preference of $s$ to $o$ taken from the test set\\
    $\widetilde{p}_{so}$: prediction of the preference of $s$ to $o$
    \begin{equation}
        \label{rmse}
        RMSE = \sqrt{\frac{\sum_{(s,o)\in TestPairs}(p_{so} - \widetilde{p}_{so})^2}{|TestPairs|}}
    \end{equation}
    
    ndcg nemuzu pouzit, protoze nemam poradi v result listu
    korenuv hyperzpusob na par nahodne vybranych uzivatelu.
    hh\\
    $Prec_s$: precision for subject $s$.\\
    $Rec_s$: recall for subject $s$\\
    $R_s$: a set of objects recommended to $s$\\
    $T_s$: a set of objects in test set for $s$\\
    $N$: number of recommended objects\\
    
    \begin{equation}
        \label{precision}
        Prec_s = \frac{|R_s \cap T_s|}{N}
    \end{equation}
    
    \begin{equation}
        \label{recall}
        Rec_s = \frac{|R_s \cap T_s|}{|T_s|}
    \end{equation}
    
    zpusob vyberu test dat z datasetu - nakonec asi podle casu (where available)
    
    timestampy at si resi v pravidlech - to je business vec - jestli plati nejaky decay nebo tak neco, do toho algoritmus nema stourat. 
    
    \section{Metrics}
        je jich hafo, viz clanek. Kdyz nemam negativni hodnoceni, tak je mi RMSE uplne na pytel. Jak jsem dosel k tomu precision recall na urovni usera - je potreba to nejak omezit aby nevyhraval recommender konstantni 1. Rozumna operace pro omezeni je recommende - per user. 
    \section{Last.fm dataset}
        Ze mam dva recommendery - jeden novel - objevovani novych artistu
        druhy nenovel - napr. hrani v personalized radiu, nezalezi na tom jestli hral nebo ne. Tohle nesrovnam s Mahoutem, protoze ten vyrazuje zname dvojice z recommendations
        
        u novel test pairu beru distinct subj, obj. u nenovel beru jak mi to prijde. Pokud recommender trefi objekt, ktery je v test setu vickrat, tak do precision to pocitam jenom jednou (recommended item byla zahrana), do recall vickrat (trefil vic polozek z moznych). 
        
        Results:
        test set randomly chosen, 516 trivial hits
        - unresyst with age rule: prediction Success rate: 0.583559 (646/1107); recommendation: 4 hits recorded, precision, recall (0.0046511627906976744, 0.0042393410852713176)
        - mahout slope one: prediction Success rate: 0.708220 (784/1107), 7 hits recorded, precision/recall (0.0069767441860465115, 0.014426910808489757)
        
        test set taken as the latest scrobbles (non-novel): XXX trivial hits
        - unresyst with age rule and scrobble count rule:
            prediction: Success rate: 0.527125 (583/1106), RMSE: 0.475152
            recommendation: 65 hits recorded, (0.050724637681159424, 0.052776203958823528)
        - mahout slope one (binary):  
            prediction: 0.536166 (593/1106) RMSE: 0.340527
            recommendation: 3 hits recorded, (0.0043478260869565218, 0.0056051034311903883)

    \section{Improving the Recommender Results}
        \label{improving_the_results}
        \subsection{Learning Weights}

\chapter{Conclusion and Future Work}
\label{conclusion}

% zahrnul jsem knowledge-based recommender do matrix factorization (ale na to prijdu az v kapitole algorithms).
% navrhnul jsem expectancy - miru relevance rekomendace nezavislou na hodnoceni, navrhnul jsem jak ji zadavat aby to bylo user-friendly
% oddelil jsem business knowledge od recommender algorithm

\chapter{Software tools}
\label{tools}
 - gedit, http://www.timtim.com (obrazky), Kile (latex),  pdfTeXk version 1.40.3 (Web2C 7.5.6)
 - django 1.2, python 2.7
    
    
%%% Seznam literatury
%%%
%%% Literatura se øadí abecednì. Úvádí se pouze literatura, na kterou se v textu odkazuje.
%%% Pøi odkazu na knihu se v¾dy uvádìjí èísla stránek.

\begin{thebibliography}{99}
%druhy literatury:
%    o universal recommenders
%    o algoritmech a jejich implementaci
%    case studies
\addcontentsline{toc}{chapter}{Bibliography}
% \bibitem{abraham-marsden}Abraham R., Marsden J. E.: {\em Foundations of Mechanics}, Addison-Wesley, Reading, 1985.
    
    \bibitem{patent}Geoffrey J. Hueter, Steven C. Quandt, Noble H. Hueter: \emph{Universal system and method for representing and predicting human behavior} \#20090248599, United States Patent Application Publication, 2009. http://www.freshpatents.com/-dt20091001ptan20090248599.php, http://www.freepatentsonline.com/20090248599.pdf

    \bibitem{netflix_solution}http://www.netflixprize.com/assets/GrandPrize2009\_BPC\_BellKor.pdf
    \bibitem{netflix_wiki}http://en.wikipedia.org/wiki/Netflix\_Prize
    \bibitem{netflix_benefit}http://www.nytimes.com/2009/09/22/technology/internet/22netflix.html
    \bibitem{netflix_end}http://blog.netflix.com/2010/03/this-is-neil-hunt-chief-product-officer.html
        http://glaros.dtc.umn.edu/gkhome/suggest/overview
    hybrid vec na duinu
        http://wwwis.win.tue.nl/hacdais2010/paper4short.pdf 
    \bibitem{survey}Gediminas Adomavicius and Alexander Tuzhilin: \emph{Towards the Next Generation of Recommender Systems:
A Survey of the State-of-the-Art and Possible Extensions}, 2005
    \bibitem{wiki_genome}http://en.wikipedia.org/wiki/Music\_Genome\_Project
    \bibitem{wiki_collaborative}http://en.wikipedia.org/wiki/Collaborative\_filtering
    \bibitem{wiki_slope_one}http://en.wikipedia.org/wiki/Slope\_One
    \bibitem{amazon}Amazon.com Recommendations Item-to-Item Collaborative Filtering http://www.win.tue.nl/\~laroyo/2L340/resources/Amazon-Recommendations.pdf
    \bibitem{bellkor_ieee}Matrix factorization techniques for recommender systems http://research.yahoo4.akadns.net/files/ieeecomputer.pdf
    \bibitem{bellkor_2009}
Yehuda Koren: The BellKor Solution to the Netflix Grand Prize
http://www.netflixprize.com/assets/GrandPrize2009\_BPC\_BellKor.pdf
    \bibitem{google_news}Google News Personalization: Scalable Online Collaborative Filtering http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.80.4329\&rep=rep1\&type=pdf
    
    \bibitem{white_paper}The Universal Recommender http://adsabs.harvard.edu/abs/2009arXiv0909.3472K
    \bibitem{duine}The Duine Framework http://duineframework.org
    \bibitem{knowledge_burke}Knowledge-based recommender systems \verb!http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.3078&rep=rep1&type=pdf!
    \bibitem{integrating_burke}Integrating Knowledge-based and Collaborative-filtering
               Recommender Systems
\verb!http://www.aaai.org/Papers/Workshops/1999/WS-99-01/WS99-01-011.pdf!
\bibitem{racofi}RACOFI: A Rule-Applying Collaborative Filtering System
\verb!http://www.daniel-lemire.com/fr/documents/publications/racofi_nrc.pdf!
\bibitem{knowledge_spain}A Knowledge Based Recommender System Based on Consistent Preference Relations 
\verb!http://www.springerlink.com/content/m64g474m7p0t4r26/!
\verb!http://books.google.cz/books?id=LN4dVFPXBioC&lpg=PP1&ots=EwNO8Bpeyy&dq=Intelligent%20Decision%20and%20Policy%20Making%20Support%20Systems&pg=PP1#v=onepage&q&f=false!
\bibitem{order}Learning to order things
\verb!http://www.jair.org/media/587/live-587-1790-jair.pdf!
\bibitem{ruleml}\verb!http://ruleml.org/!
\bibitem{ruleml_short}\verb!http://ruleml.org/submission/ruleml-shortation.html!
\bibitem{ruleml_prolog}\verb!http://centria.di.fct.unl.pt/~cd/projectos/w4/ruleml/index.htm!
\bibitem{lastfm_festivals}\verb!http://www.last.fm/festivals!
\bibitem{mahout}\verb!http://mahout.apache.org/!
\bibitem{collaborative_filtering}Collaborative filtering recommender systems \verb!http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.4520&rep=rep1&type=pdf!
\bibitem{last_fm}Last.fm recommendation service \verb!http://www.last.fm/about!
\bibitem{yahoo_cup}KDD cup recommender competition \verb!http://kddcup.yahoo.com/index.php!
\bibitem{probabilistic_analysis}Recommendation systems: a probabilistic analysis \verb!http://www.tomkinshome.com/site_media/papers/papers/KRR+98.pdf!
\bibitem{yahoo} Seung-Taek Park, David M. Pennock: Applying collaborative filtering techniques to movie search for better ranking and browsing \verb!http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.8109&rep=rep1&type=pdf!
\bibitem{google_api}The Google Prediction API \verb!http://code.google.com/apis/predict/!

http://ids.csom.umn.edu/faculty/gedas/papers/recommender-systems-survey-2005.pdf
odkazy:
    http://en.wikipedia.org/wiki/Recommender\_system
    http://www.deitel.com/ResourceCenters/Web20/RecommenderSystems/RecommenderSystemsConferences/tabid/1323/Default.aspx
    http://lucene.apache.org/mahout/taste.html\#useful .. tam toho neni moc
    Univerzalni recommender, projekty:
        Aura (dead since 2009):
            \bibitem{aura}The Advanced Universal Recommendation Architecture (AURA) Project home page. http://labs.oracle.com/projects/dashboard.php?id=196
            \bibitem{music_explaura}The Music Explaura, an experimental music recommender based on AURA. Currently inactive. http://music.tastekeeper.com/
            \bibitem{aura_wiki}The AURA project wiki. http://kenai.com/projects/aura/pages/Home
        Loomia (komercni):
            http://www.loomia.com/
        SUGGEST (dead since 2000):
            http://glaros.dtc.umn.edu/gkhome/suggest/overview
            + http://pypi.python.org/pypi/pysuggest/1.0
        easyrec (opensource, vypada ze moc neumi, ale bezi jako service):
            http://easyrec.org/api-js
        duine (opensource):
            http://duineframework.org
    knihovny na recommendaci
        mahout
            http://lucene.apache.org/mahout/
            http://svn.apache.org/repos/asf/mahout/
    
    algoritmy
        http://tastecliq.posterous.com/comparing-state-of-the-art-collaborative-filt
        tagy:
            http://stackoverflow.com/questions/2794272/tag-keyword-based-recommendation
        
        
    python to Java
        http://www.slideshare.net/onyame/mixing-python-and-java
        http://wiki.cacr.caltech.edu/danse/index.php/Communication\_between\_Java\_and\_Python
        Pres generovane c++
            http://pypi.python.org/pypi/JCC/
        nejak jinak (asi obracene)
            http://jepp.sourceforge.net/
        primo pres masiny (dead since 2009)
            http://hustleplay.wordpress.com/2010/02/18/jpype-tutorial/
            http://jpype.sourceforge.net/
            
            
        
    
 
% \bibitem{derbes}Derbes D.: {\em Reinventing the wheel: Hodographic solutions to the Kepler problems}, Am. J. Phys. {\bf 69} (2001) 481--489.
% \bibitem{kvasnica}Kvasnica J.: {\em Teorie elektromagnetického pole}, Academia, Praha, 1985.
\end{thebibliography}

\end{document}
