%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% iso8859-2

%%%                                    %%%
%%% ©ablona bakaláøské práce na MFF UK %%%
%%%                                    %%%
%%% (c) Franti¹ek ©trupl, 2005         %%%
%%%                                    %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% POZOR: Úprava bakaláøské práce je závislá rovnì¾ na volbì jednostranného resp. oboustranného tisku.
%%%        Bli¾¹i informace naleznete v dokumentu Úprava bakaláøské práce, který se nalézá na adrese:
%%%        http://www.mff.cuni.cz/studium/obecne/bplayout/pok12mo4.pdf

\documentclass[12pt,notitlepage]{report}
%\pagestyle{headings}
\pagestyle{plain}

% \frenchspacing aktivuje pou¾ití nìkterých èeských typografických pravidel

\usepackage[latin2]{inputenc} % nastavuje pou¾ité kódování, u¾ivatelé Windows zamìní latin2 za cp1250
%\usepackage[czech]{babel}
\usepackage{a4wide} % nastavuje standardní evropský formát stránek A4
%\usepackage{index} % nutno pou¾ít v pøípadì tvorby rejstøíku balíèkem makeindex
%\usepackage{fancybox} % umo¾òuje pokroèilé rámeèkování :-)
\usepackage{graphicx} % nezbytné pro standardní vkládání obrázkù do dokumentu
\usepackage{amsfonts}
\usepackage{amsmath}

\usepackage[left=2.5cm]{geometry} % nastavení dané velikosti okrajù

%\newindex{default}{idx}{ind}{Rejstøík} % zavádí rejstøík v pøípadì pou¾ití balíku index

% promenne:
\newcommand{\vedouci}{prof. RNDr. Peter Vojtá¹, DrSc.}
\newcommand{\ja}{Petr Cvengro¹}
\newcommand{\katedra}{Katedra softwarového in¾enýrství}
\newcommand{\nazev}{Univerzální doporuèovací systém}
\newcommand{\datum}{DATUM}
\newcommand{\vedoucimail}{Peter.Vojtas@mff.cuni.cz}

% prikazy s parametry

% obrazek
\newcommand{\fig}[4][13]{
    \begin{figure}[!ht]
        \vspace{3mm}
        \begin{center}
            \includegraphics[width=#1cm]{#2}
            \caption{#3}
            \label{#4}
        \end{center}
    \end{figure}
}
% parameters: [width in cm], filename, caption, label


\title{Název práce}   % tyto dvì polo¾ky jsou zde v podstatì formálnì, ve skuteènosti nejsou nikde 
\author{Petr Cvengro¹} % dále v dokumentu pou¾ity

%\date{}

\begin{document}

%\csprimeson % zapne jednoduché psaní èeských uvozovek pomocí klasických znakù, ale potom pozor 
             % na originální apostrofy, které budou chybnì interpretovány!!!

%%% Následuje první, úvodní, strana bakaláøské práce. Jednotlivé polo¾ky nahraïte dle vlastních
%%% údajù. Zmìnit podle konkrétní délky jednotlivých polo¾ek mù¾ete i zalomení øádkù.
\begin{titlepage}
\begin{center}
\ \\

\vspace{15mm}

\large
Univerzita Karlova v Praze\\
Matematicko-fyzikální fakulta\\

\vspace{5mm}

{\Large\bf DIPLOMOVÁ PRÁCE}

\vspace{10mm}

%%% Aby vlo¾ní loga v¹e správnì fungovalo, je tøeba mít soubor logo.eps nahraný v pracovním adresáøi,
%%% tj. v adresáøi, kde se nachází pøekládaný zdrojový soubor. Soubor logo.eps je mo¾né získat napø.
%%% na adrese: http://www.mff.cuni.cz/fakulta/symboly/logo.eps
\includegraphics[scale=0.3]{pics/logo.jpg} 

\vspace{15mm}

%\normalsize
{\Large \ja}\\ % doplòte va¹e jméno
\vspace{5mm}
{\Large\bf \nazev}\\ % doplòte název práce
\vspace{5mm}
\katedra\\ % doplòte název katedry èi ústavu
\end{center}
\vspace{15mm}

\large
\noindent Vedoucí diplomové práce: \vedouci % doplòte odpovídající údaje
%%% dal¹í øádek mù¾ete ve vìt¹inì pøípadù (tj. pokud údaje uvedené vý¹e nejsou pøíli¹ dlouhé) zru¹it
\hskip20mm 
\vspace{1mm} 

\noindent Studijní program: Informatika, Softwarové systémy, Softwarové in¾enýrství % doplòte odpovídající údaje
%%% dal¹í øádek mù¾ete ve vìt¹inì pøípadù (tj. pokud údaje uvedené vý¹e nejsou pøíli¹ dlouhé) zru¹it
%\hskip20mm 

\vspace{20mm}

\begin{center}
2010-2011 % doplòte rok vzniku va¹í bakaláøské práce
\end{center}

\end{titlepage} % zde konèí úvodní strana

\normalsize % nastavení normální velikosti fontu
\setcounter{page}{2} % nastavení èíslování stránek
\ \vspace{10mm} 

\noindent Na tomto místì mohou být napsána pøípadná podìkování (vedoucímu práce, konzultantovi, tomu, kdo pùjèil software, literaturu, poskytl data apod.). % doplòte vlastní text

\vspace{\fill} % nastavuje dynamické umístìní následujícího textu do spodní èásti stránky
\noindent Prohla¹uji, ¾e jsem svou diplomovou práci napsal samostatnì a výhradnì s pou¾itím citovaných pramenù. Souhlasím se zapùjèováním práce.

\bigskip
\noindent V Praze dne \datum \hspace{\fill}\ja\\ % doplòte patøièné datum, jméno a pøíjmení

%%%   Výtisk pak na tomto míste nezapomeòte PODEPSAT!
%%%                                         *********

\tableofcontents % vkládá automaticky generovaný obsah dokumentu

\newpage % pøechod na novou stránku

%%% Následuje strana s abstrakty. Doplòte vlastní údaje.
\noindent
Název práce: \nazev\\
Autor: \ja\\
Katedra (ústav): \katedra\\
Vedoucí diplomové práce: \vedouci\\
e-mail vedoucího: \vedoucimail\\

\noindent Abstrakt:  V pøedlo¾ené práci studujeme ... Uvede se abstrakt v rozsahu 80 a¾ 200 slov. %Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Ut sit amet sem. Mauris nec turpis ac sem mollis pretium. Suspendisse neque massa, suscipit id, dictum in, porta at, quam. Nunc suscipit, pede vel elementum pretium, nisl urna sodales velit, sit amet auctor elit quam id tellus. Nullam sollicitudin. Donec hendrerit. Aliquam ac nibh. Vivamus mi. Sed felis. Proin pretium elit in neque. Pellentesque at turpis. Maecenas convallis. Vestibulum id lectus. Fusce dictum augue ut nibh. Etiam non urna nec mi mattis volutpat. Curabitur in tortor at magna nonummy gravida.\\

\noindent Klíèová slova: klíèová slova (3 a¾ 5)

\vspace{10mm}

\noindent
Title: Universal Recommender System\\
Author: \ja\\
Department: Department of Software Engineering\\
Supervisor: \vedouci\\
Supervisor's e-mail address: \vedoucimail\\

\noindent Abstract: In the present work we study ... Uvede se anglický abstrakt v rozsahu 80 a¾ 200 slov. %Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Ut sit amet sem. Mauris nec turpis ac sem mollis pretium. Suspendisse neque massa, suscipit id, dictum in, porta at, quam. Nunc suscipit, pede vel elementum pretium, nisl urna sodales velit, sit amet auctor elit quam id tellus. Nullam sollicitudin. Donec hendrerit. Aliquam ac nibh. Vivamus mi. Sed felis. Proin pretium elit in neque. Pellentesque at turpis. Maecenas convallis. Vestibulum id lectus. Fusce dictum augue ut nibh. Etiam non urna nec mi mattis volutpat. Curabitur in tortor at magna nonummy gravida.\\

\noindent Keywords: klíèová slova (3 a¾ 5) v angliètinì

\newpage

%%% Následuje text bakaláøské práce èlenìný do kapitol, které se èíslují, oznaèí názvy a graficky oddìlí.
%%% Nedoporuèuje se pou¾ívat víc ne¾ dvì úrovnì èíslování kapitol, viz pøíklad ní¾e.

\chapter{Introduction}
    \label{introduction}

    A present-day internet user is facing a plentitude of options. E-shops are offering a wide choice of various products, internet newspapers publish thousands of articles every day, loads of videos are published or uploaded by users every second. When a user is deciding what to buy, read or see, there are by far too many options to browse and choose the optimal one. Search engines don't help much, because a query like ``find something I would like'' is too vague. That's where recommender systems emerge. They help users to deal with the information overload, retailers to offer the most appropriate product for each client which results in increased customer satisfaction and loyalty. 
    
    The key feature of recommender systems is \emph{personalization}. Unlike search engines, recommenders take into account the personality and past behaviour of each user. A typical recommender wouldn't present the same set of items to two different users.
    
    Recommender systems are programs operating on large amount of data in software systems. Recommender systems try to present items such as books, music, news, etc. that are likely to be interesting for a given user. These systems may be helpful for users that are choosing between a large number of items and aren't willing to browse information about all available items.
    
    Traditional recommender systems are specific to a particular domain of recommended items. Our view is more general and involves domain independence and utilization of any relationships among the entities in the domain. The thesis aims to create a prototype of a \emph{Universal Recommender} system, a system applicable to various domains, predicting relationships of the given type using already known relationships. Our recommender adds a new layer above algorithms implemented in recommender frameworks, making the recommender easily applicable to any domain and system.
    
    %TODO tohle opravit
    In the introductory chapter we describe the basic structure of the thesis. Then we give a formal definition of a recommender system. Finally we review projects and papers that have been created on the universal recommender topic.
    
    \section{Thesis Structure}
        \label{thesis_structure}
        In the \emph{\ref{introduction} Introduction} chapter we describe some basic ideas of the thesis, give a formal definition of a recommender system and explore the works that have been made on the topic.
        
        TODO doplnit
    \section{Thesis Concepts}
        The section describes the main concepts of the thesis. We list the most important features and describe the purpose of the thesis.
        \subsection{Motivation}
            \label{motivation}
            Modern web applications like e-shops or social networks tend to have much information about items in the system, they collect much data about users and their behaviour. When implementing a recommender in the system, it would be natural to use all the available knowledge for generating recommendations. However, current algorithms used for recommending usually employ only a single source of knowledge: a user-item rating. Using all available knowledge for recommending would lead to better recommendation accuracy and better reasoning for the provided recommendations.
            
            Using multiple sources of data for recommending is also a current trend in the recommender research field, as illustrated by the current recommender system competition, organized by members of the Netflix prize winning team \cite{yahoo_cup}.
            
            We would like our Universal recommender system (Unresyst) to take advantage of all available relationships. Let's show our idea on an example. Suppose, we have to generate recommendations in a system like Last.fm \cite{last_fm}. Registered users can let the system know what music they are playing on their computers through a media player plugin. Moreover, users can fill in some basic personal information, like gender and age. Songs and artists can be marked by tags\footnote{Tag is a short textual notice, provided by a user to describe the song or an artist. For example, music can be tagged as ``Rock'', ``Jazz'', ``Pop`` or ``Slow'', ``Indie''.}. In a recommender, we would like to be able to provide user-artist recommendations as illustrated on the figure \ref{pic_similarity}. The links between a user and an artist he/she has listened is displayed as solid line. The similarity derived from user attributes and artist tags is displayed as dotted line. The user-item recommendations, we would like to generate, are displayed as dashed lines. 
            
            \fig[11]{pics/intro_similarity.png}{Using domain-specific similarity for recommending}{pic_similarity}

            Then there are some domain-specific rules we would like to incorporate to the recommendation process. Some music is usually disliked by listeners with given demographic information. For example girls are seldom fans of ``Heavy Metal'' music, so we would like to decrease the chance of ``Heavy Metal'' music being recommended to girls. The situation is illustrated on the figure \ref{pic_rule}, the expected negative preference is displayed as a zig-zag line.
            
            \fig[10]{pics/intro_rule.png}{Applying domain specific rules for deprecating recommendations}{pic_rule}
            
            Moreover, some artists are more likely to be played in a given period, e.g. because they have released a new album recently or they are on a tour. Such artists should be recommended more often to listeners. This artist property doesn't depend on the particular listener, it should just ``help'' the artist to get to recommendations for more users.
            
            \fig[10]{pics/intro_bias.png}{Using item property for recommendations}{pic_bias}
            
            The obtained \emph{compiled predictions} can be used directly for recommending or they can serve as an input for an ordinary recommender algorithm. More about recommending in the Last.fm dataset can be found in chapter \ref{verifying_last_fm}. 
            
        \subsection{Main Features}
            \label{main_features}
            The main concepts of the thesis are:
            \begin{description}
                    \item[Problem analysis and design of a solution.] The main goal of the work is to analyze the problem of a universal recommender, to create an architecture of the recommender system, design its interfaces and provide an implementation draft. The interfaces should be usable in real-world applications.
                    \item[Domain independence.] The recommender should work on any domain it's adapted to. It can't rely on any domain-specific assumptions. 
                    \item[Using various relationships.] For the recommendation, the recommender should be able to use any number of relationships available in the domain.
                    \item[Recommending given relationship.] The recommender should be able to predict any given relationship, not just the ``rating'' relationship as most recommenders do.
                    \item[A recommender, not a framework.] The adaptation to the given domain should be simple and should require minimum changes in the parent system. As opposed to recommendation frameworks that give resources to implement a recommender, our system should be a complete recommender ready to be adapted and used on an arbitrary domain.
                    \item[Pluggable user interface.] The recommender should contain a web-based user interface for presenting the recommendations. The interface should be pluggable to an existing web application, so that it can look like a part of the system and the user doesn't have to leave system web pages to see his/her recommendations. 
                    \item[Verification on various domains.] The recommender should be adapted to at least three domains to verify its universality and usability of the recommender interfaces. 
            \end{description}
        \subsection{Thesis Classification}
            \label{classification}
                
                The recommender system research field can be divided into the following the following areas, as stated in \cite{probabilistic_analysis}:
                
                \begin{enumerate}
                    \item Gathering user preference
                    \item Algorithms transforming past user actions and other data to recommendations \label{algo}
                    \item Privacy, legacy and other aspects
                    \item Measuring recommender accuracy \label{measure}
                    \item Recommender system implementation
                \end{enumerate}
                
                The thesis primarily concentrates on \ref{algo}: generating recommendations from known data. The area \ref{measure} is also partly covered in the thesis, as the results of the recommender on various domains had to be compared to other known approaches. The resting areas are undoubtedly as important as the selected ones, however the selected fit the best to the demonstration of our universal recommender idea. 

                Finally we list the topics that are out of the scope of our work:
                \begin{description}
                    \item[Scalable implementation] The provided recommender application is meant as a prototype and isn't intended to be scalable for large datasets. 
                    \item[Central server for multiple systems.] A single Unresyst instance isn't intended to be used as a central server for multiple domains - a Unresyst instance always refers to a single domain. Unresyst doesn't deal with matching the same subjects and objects appearing in multiple systems. 
                    \item[Collecting user preference] Unresyst doesn't help the system collecting any user actions for recommending. Implicit and explicit user feedback can be used for generating recommendations in Unresyst, but it has to be handled by the outer system and passed to Unresyst in the form of business rules and relationships.
                \end{description}

\chapter{Analysis}
    \label{analysis}
    In the chapter we discuss the circumstances under which recommender systems are a preferred option both for users and system holders. Later we describe the reasons for using our universal recommender system (Unresyst), we compare our recommender to existing solutions. We propose draft of a process model for activities related to running Unresyst. Finally we formally define the problem of recommending.
    
    Recommender system is a part of a web-based application, that uses data about users and their behaviour to provide them with items which are the most relevant to them. The recommended items are typically things that are liable to user taste, like books, music, news, etc.
    
    \section{Recommender System Applicability}
        \label{recommender_system_applicability}
        For a successful implementation of a recommender system, several conditions have to be fulfilled. A summary of applicability conditions for a collaborative filtering recommender can be found in \cite{collaborative_filtering}. We list some of them that are valid for any recommender, independently of the recommender algorithm.
        
        \begin{description}
            \item[Many items:] In the domain there are many items that might be interesting for a user. It is not possible for the user to browse all of them.
            \item[Choice based on taste:] The choice of the items depends on the taste of each user. If there were some objective criteria for recommending items to users the recommender system wouldn't be much helpful.
            \item[Taste data:] In the system there have to be some data about the users interacting with items that can be interpreted as expressing taste. It doesn't matter if these are explicit rating data or implicit capture of user behaviour, but there have to be some.
            \item[Homogeneous items:] The items in the domain have some common attributes, they can all be covered by taste data, e.g. they can all be viewed or rated.
        \end{description}
    
    \section{Recommender System Benefits}
        \label{recommender_system_benefits}
        The section summarizes reasons why recommender systems are useful for both users and system holders.
        
        \fig[8]{pics/use_case_recommender.png}{Use cases for a recommender system.}{pic_use_case_recommender}
        
        \subsection{Benefits for System Users}
            \label{benefits_for_users}
            In a web-system like an e-shop or an internet radio a user is overloaded with items. The system database typically contains thousands of items divided into several categories. The recommender provides user with items that are likely to be interesting without requiring him/her to search for them. This saves user's time and helps him/her spend more time exploring the interesting items than messing around uninteresting items. The provided recommendations are personalized, they reflect the past user's behaviour and available data, so the recommendations are likely to be much accurate. 
            
            In comparison to advanced multi-criteria search, recommender systems are better at reflecting users' preference in criteria that aren't easy to express and depend on the taste of the user. The advantage of recommender system is their user-friendliness - they don't require any explicit search terms, they just use the facts they already know about the user. This can be a significant advantage for inexperienced internet users. 
            
            Opposed to search engines, recommender systems present items ordered by the expected preference, which can be more accurate when taste is important. However, multi-criteria search can act as a supplement to a recommender system, for performing well defined search queries. E.g. if the user is absolutely certain he/she wants a red lap-top with the given display size at the lowest price, the multi-criteria search is the best option to find such a product.
            
            Recommender systems help users find novel items. When a user only browses and searches the system items, he/she usually gets stuck to a relatively small group of items. The recommendations usually contain items chosen by various criteria, so that they contain both items the user is familiar with and items that are likely to be interesting for the user, but the user wouldn't otherwise discover them.
            
            Apart from that, a recommender system can predict user's interest for a particular item. E.g. the last.fm festival recommender can predict user's interest in a particular festival based on the user's taste and the festival lineup \cite{lastfm_festivals}. This also saves user's time, he/she doesn't have to examine details of the items that aren't likely to be interesting for him/her.
        
        \subsection{Benefits for a System Holder}
            \label{benefits_for_holders}
            A satisfied user is a key for the success of a web-system business. If the user easily finds interesting items in the system, he/she tends to return to the system regularly, which results in a high visit rate. 
            
            In an e-shop, if a user easily finds items that are appropriate for him/her, he/she is more likely to buy them. In a non-retail system like an internet radio, the system holder can also profit from a user finding appropriate items quickly. The user spends more time on pages that provide interesting information for him/her, which leads to more appropriate context advertisements with higher earnings.
            
            Another interesting feature recommender systems provide to e-shop holders is the ability to include promoted items to recommendations. E-shop holders can artificially increase the recommendation rates of the promoted goods so that they appear in recommendations for more users. However, this feature should be used moderately because it distorts the results of the recommender algorithm. A massive propagation of items that are promoted by the system holder but are not very interesting for particular users may lead to a loss of user's trust for the recommender.
            
            And last but not least, a recommender system provides a competitive advantage. Web business leaders like Google \cite{google_news}, Amazon \cite{amazon} or Yahoo! \cite{yahoo} have already implemented recommenders in their systems, for smaller companies a recommender system may be a key advantage over their rivals.
    
    \section{Universal Recommender Analysis}
        \label{universal_recommender_analysis}
        In the section we describe the position of the proposed universal recommender system (Unresyst) on the market. We depict advantages and disadvantages of the Unresyst recommender, we compare Unresyst to existing solutions. Finally we propose processes for incorporating Unresyst to a web-based system and for running a system with Unresyst.
        
        The proposed Unresyst recommender is a domain-independent recommender system that is able to use various relationships between the domain entities. Unresyst is an independent software component that logically stands outside the web-based parent system. It communicates with the parent system through a defined API\footnote{API stands for Application Programming Interface.}. Detailed information on the system architecture can be found in the section \ref{architecture}. 
        
        Unresyst itself doesn't contain any domain-specific data or methods. In order to work correctly on the given domain, it has to be adapted to it. Adaptation data make Unresyst use domain knowledge for making recommendations. Adaptation is designed so that it's as easy as possible. Adaptation data are stored in the parent system and are used during the communication with Unresyst. Detailed description on the adaptation can be found in the section \ref{adaptation_interface}. 
        
        In order to provide high quality recommendations, Unresyst can take use of any \emph{relationships} between the entities in the system domain. Additionally, the business knowledge can be transformed to \emph{rules} and used for generating recommendations. Both rules and relationships are stored in the adaptation data. See sections \ref{representing_rules}, \ref{representing_relationships} for details on rule and relationship representation.
        
        \subsection{Universal Recommender Applicability}
            \label{universal_recommender_applicability}
            
            Companies that run big global web-systems generally have enough resources to develop their own recommender systems that are specifically designed for their needs. Therefore, Unresyst is aimed at small and mid-size web systems. The goal of the Unresyst concept is to provide companies a way to implement a recommender system without having to develop their own recommender solution, which is often both time and money consuming. With a bit of configuration, Unresyst can provide recommending accuracy comparable to a custom-made recommender system. We suppose the web-system application uses a database to store its data. The data are manipulated trough an SQL\footnote{SQL stands for Structured Query Language, a language most commonly used for structured data manipulation.} or ORM\footnote{ORM stands for Object-relational mapping, a technique used for manipulating data directly in the application without using SQL.} layer.
            
            \fig{pics/owner.png}{Choosing the way of recommender system implementation.}{pic_owner}
            
            Unresyst can take use of any attributes and relationships that can be tracked in the parent system. Data that can be used by Unresyst include but are not limited to:
            \begin{description}
                \item[User behaviour:] In recommendations we can use data about user viewing item pages, the time users spent on each page, analysis of user's mouse move and any other implicit feedback provided by users.
                \item[Explicit feedback:] We can also use the explicit user feedback, like rating on a scale, thumb up/thumb down rating, in systems where such mechanisms are available.
                \item[Demographic information:] In systems where demographic data are available, we can use them for making recommendations. For users we can use attributes like age, place of residence, or education. For items we can use the data about their manufacturers like country or size of the company.
                \item[Social relations:] In systems, where users interact between each other, the social data can be used for providing recommendations. We can use relationships between users like friends, sent personal messages or viewing other user's profile.
                \item[Other relationships:] Any other relationships between entities of the system can be used for making recommendations. Such relationships include user-defined tags which can be used for determining similarity of the entities marked with the same tag, or user's preference for items marked with a particular tag.
             \end{description}
             
             Recommendations produced by Unresyst can take into account both objective and subjective criteria. Objective criteria for recommending can be expressed in business rules (e.g. not recommending expensive items to users with low income). Subjective criteria, as the expressed preference for an item are used both for the user and users that are observed to have similar taste.
             
             The most common operations for a recommender, providing recommendations and predicting the preference for a particular item, are performed in time independent of the number of the entities in the system. The exact recommendation and prediction time may vary between the recommender algorithms. However most of the presented current algorithm use some kind of recommendation index which enables them to perform recommendations in constant time.
             
             The Unresyst software component is logically independent of the parent system, it provides an API for all common operations. The API and the domain-specific configuration is made so that the adaptation to the domain and to the parent system is as easy as possible. Unresyst also contains a pluggable user interface for presenting recommendations to the user. The user interface can be incorporated into the parent system user interface so that the user doesn't have to leave the parent system in order to see the recommendations.
             
        \subsection{Comparison to Other Solutions}
            \label{comparison_to_other_solutions}
            In the section we compare Unresyst to other solutions that are available for a small to mid-size company that likes to implement a recommender system at a reasonable time and cost. Unresyst is laying somewhere between the presented options, using the advantages of all and minimizing their drawbacks.
            
            \subsubsection{Filtering Items in Queries}
                \label{filtering_items_in_queries}
                For a system holder, a minimalistic approach to item recommending is to implement item filtering in a query language (e.g. SQL) above the system database. This approach can be very efficient when the holder wishes to implement a small set of well-defined filtering rules, that don't imply user's taste. Such an implementation can be fast and cheap, as it doesn't require any significant changes to the system, nor incorporation of a third party component to the system. 
                
                \fig[4]{pics/options_a_own_circle.png}{Implementing recommendations directly in the application.}{pic_direct}

                However this approach works well only for well-defined and static filtering criteria that aren't costly to evaluate. With an increased size of the rule set, the maintenance of the queries becomes difficult. When the system holder wishes to implement some kind of evaluation of user taste, the situation even complicates. Complex queries combining various data can take a long time to evaluate, which results in slow generating of the system web pages and nervous users.
                
                Simple hard coded filtering queries don't allow exceptions to the expressed rules. E.g. if we set up a hard coded query for not recommending an item to users with the given demographic data, the item won't be recommended even if we have a high preference signs from other sources such as user behaviour.
                
                The Unresyst recommender offers a transparent way of managing the business knowledge that is used for generating recommendations. The rules and relationships aren't written in query language but in a more human-friendly form. The business knowledge is kept in one place and is separated from the recommender algorithm. Changing the significance of the rules and relationships can be done there too. All recommendations are produced using the given business knowledge. The rules and relationships are combined according to their significance.
                
                The recommender algorithm which is one of the Unresyst layers, can use complex techniques to exploit the business knowledge. Therefore the recommendations produced by Unresyst are generally more accurate. At the same time the algorithm uses a recommender index that makes the prediction time independent of the number of entities in the system. 
                
                The main disadvantage of Unresyst compared to the minimalistic option is the required initiatory effort required to start producing recommendations. Firstly, Unresyst has to be configured for the system, which means specifying the subject and object domain, definition of the predicted relationship  and finally writing down the business knowledge in the form of rules and relationships. Then the recommendations have to be incorporated to the parent system - calling of Unresyst methods has to be added to necessary places, the recommender user interface has to be incorporated to the system. However the initial effort pays off as the latter changes in recommender configuration can be done easily at one place.
                
                Running a system that uses a recommender involves some additional effort. The index of the recommender algorithm has to be built before the recommender is used. This can be a time-consuming action, depending on the algorithm and number of entities in the system. The recommender index has to be kept up to date by either rebuilding now and then or by continuously calling methods for index update. These methods keep update the index with every change in the system but they require some additional time during save and update of the system entities and they might be unavailable for some recommender algorithms. The issues of the recommender index however occur when running any recommender that takes constant time for recommending items.
                
                To summarize the comparison, Unresyst is a better option than filtering items in queries unless the system holder only wishes to implement a small set of fixed filtering rules, that don't need to be changed over time and he/she isn't interested in exploiting the rules by a recommender algorithm.
                
            \subsubsection{Using a Recommender Framework}
                \label{using_a_recommender_framework}
                The system holder can choose to implement a recommender based on a recommender framework library like Duine \cite{duine} or Mahout \cite{mahout}. These are software libraries providing implementations of common present-day algorithms like collaborative filtering or content-based algorithms. For details on recommender algorithms see the section \ref{algorithms}.
                
                \fig[8]{pics/options_b_library.png}{Implementing recommendations using a recommender framework.}{pic_framework}

                
                Recommender frameworks aren't real rivals to Unresyst as they can be used in the Algorithm layer of Unresyst. In this section we compare the usage of mere recommendation framework directly incorporated  into the system and the usage of Unresyst with a recommender algorithm below, no matter if the in-built recommender algorithm is used, or if the algorithm implementation is overtaken from a third party library.
                
                Most algorithms in recommender frameworks rely on presence of a single explicit preference indicator like rating. If a system holder likes to use more sources of negative or positive preference data, he/she has to care about converting the preference to the rating used in the recommender algorithm. Using multiple sources of preference data, like data about user behaviour, social data or demographic data about users, is necessary for the algorithm to provide good recommendations. Only recommenders that use all available knowledge can produce high quality recommendations.
                
                \fig[8]{pics/options_c_unresyst.png}{Implementing recommendations through Unresyst, optionally using a recommender framework algorithm.}{pic_unresyst}
                
                The API of most of the present-day recommender frameworks isn't very developer-friendly and let the developer deal with converting between the system entities and recommender entities. This requires additional programming. Moreover, the algorithm API often lacks methods for updating the entities. Therefore in order to propagate the changes in the system data to recommender, the system administrator has to rebuild the index of the recommender algorithm. The recommendations can't be made ``on-line'' from the current system data. Unresyst brings up a simple and complete interface for using the recommender in the parent system.
                
                In addition, Unresyst enables system holders to run multiple instances of a recommender in one parent system. E.g. there can be a product recommender and user group recommender in the system, that is working in one Unresyst installation, but is independent of each other and can be using different rules and relationships to produce recommendations. 

                
                To summarize the comparison, incorporating a recommender framework is usually complicated both technically and intellectually. This may be one of the reasons why the present-day recommender frameworks haven't been widely used in real world web-based systems. Unresyst adds a new layer above the algorithms that solves the problems with combining different sources of preference data and enables the system holder to incorporate the business knowledge to recommendations.
            \subsubsection{Using a Recommender Service}
                \label{service_through_api}
                Another option, the system holder can possibly use in future is implementing a recommender using a recommender service. The first attempt to provide a such a service is the Google Prediction API \cite{google_api}. The service is still in development in Google Labs, available for experiments only through a waiting list. Only little data about the way the service internally works is available for public. There's only one obvious disadvantage of the approach: all data that are to be used for recommending have to be passed and regularly updated through the API. This can raise privacy issues system owner's distrust.
                
                \fig[8]{pics/options_d_google.png}{Implementing recommendations using a recommender service}{pic_google}

        \subsection{Unresyst Process Model Draft}
            \label{unresyst_process_draft}
            In the section we propose a design of processes related to Unresyst setup and maintenance. Note that this is only a brief simplified sketch illustrating how real processes could possibly look like. The actual usage of the system would be highly dependent on particular company, its environment and people. A more technical view on Unresyst setup and evaluation can be found in chapters about Unresyst architecture (\ref{architecture}) and evaluation (\ref{evaluating_recommender_results}).

            \subsubsection{Unresyst Setup}
                \label{unresyst_setup}
                After the system holder or the company management agrees on using Unresyst for recommending in their system, the setup activities may begin. One of the main roles in the recommender operation is the \emph{Domain Expert}. He/She is familiar with the business the system is operating in, knows a lot about entities and their relationships both in the real world and in the system. 
                
                \fig{pics/process_setup.png}{Unresyst Setup process, a draft of a process model.}{pic_setup}
                
                Firstly, the \emph{Business Analyst} interviews the \emph{Domain Expert} in order to find out the requirements for the recommender and type and amount of data that is available for making recommendations.  The output of this activity is a report that thoroughly describes the purpose of the recommender and knowledge that is available for recommending in the parent system. The report should at least include the list of recommender instances that will be incorporated to the system and for each recommender it should describe the subjects and objects of recommendations, the description of the predicted relationship and finally a description of all relationships and business rules that are available for the domain. The report is prepared by the \emph{Business Analyst}, is approved by the \emph{Domain Expert} and is imperative for the later activities. This activity should be done properly, multiple iterations of interviewing and recording will be needed.
                
                The report is delivered to the \emph{Data Specialist}. \emph{Data Specialist} is a person highly familiar with the data model of the system. He/she transforms the report into an Unresyst configuration, which formally defines subjects, objects, rules and relationships for each recommender. After the configuration, the \emph{Data Specialist} performs the recommender build, evaluates the results of the recommender and verifies sample recommendations with the \emph{Domain Expert}. \emph{Data Specialist} tries improving the recommender evaluation by tuning the rule and relationship parameters, until a given accuracy threshold is reached.
                
                The \emph{Developer} is next to come. \emph{Developer} is familiar with the implementation of the parent system. He/she incorporates the Unresyst API calls to the appropriate parts of the system, includes the recommender user interface into the parent system interface.
                
                After enough tests have been performed, the version of the parent system using Unresyst is put into operation. Tests should include user-testing inquiring real users of the system.
                
            \subsubsection{Unresyst Maintenance}
                \label{unresyst_maintenance}
                
                Running a recommender system isn't just a matter of setup. Keeping the recommendation quality high requires a regular maintenance activity. The frequency of the maintenance tasks depend on many factors such as  domain dynamics and internal capacities of the company. It should be done at least a few times a year.
                
                \fig{pics/process_review.png}{Unresyst Review process, a draft of a process model.}{pic_review}
                
                Maintenance activities follow selected setup activities in order to improve accuracy of the recommender. \emph{Business Analyst} interviews the \emph{Domain Expert} to find out what has happened in the domain business since the last maintenance activity. Requests for collecting new types of user-data can be included. The news are delivered to the \emph{Data Specialist}, who incorporates them to the recommender configuration. He/She also revises the changes in the system that could have affected the recommendation sources and adjusts the configuration to use any newly available data. Finally he/she evaluates the recommender with the new configuration and tunes the parameters until the desired evaluation is obtained. The new Unresyst configuration and sample recommendations are consulted with the \emph{Domain Expert}. The new configuration is finally tested and put into operation.
        
    \section{Definitions}
        \label{definitions}
        XXXX TODO zkontrolovat, doplnit.
        In this section we give some basic definitions of terms and problems that appear in the whole thesis.
        
        \subsection{Basic Terms}
        \label{basic_terms}
            The basic terms used both in definitions and throughout the thesis are:
            \begin{description}
                \item[Subject]: Subject of a recommendation is an entity to which the recommender presents its recommendations. A subject can be a user as well as a user group or any other entity.
                \item[Object]: Object of a recommendation is an entity which can be recommended to subjects. Objects can be books, songs, or any other entities.  
                \item[Entity]: Entity is a subject, an object or any other thing that occurs in the domain.
                \item[Predicted relationship]: Predicted relationship is a subject-object relationship that we try to predict for making recommendations. An example of such a relationship is the \emph{likes} relationship between a user and an item. 
                \item[Expectancy of the predicted relationship]: For predicting a relationship we need a rate - a number determining the estimated probability that the \emph{predicted relationship} will occur between the subject and object. In other words, Expectancy can be explained as subject-object preference in means of the predicted relationship. In our user-item \emph{like} example, the expectancy would mean how much the user is likely to like the item. 
             \end{description}
        
        \subsection{Recommender System}
        \label{def_recommender_system}
            Informally, a recommender system is a system that presents some chosen \emph{objects} to a given \emph{subject}. The objects are chosen so that they are likely to invoke a positive response of the subject.
            
            Similarly to the recommender problem definition in \cite{survey}, we formally define the recommendation as choosing the object $o_s$ for each subject $s$, so that the object maximizes the subject's utility $u_R$:
            \begin{equation}
            \label{eq_recommender_problem}
            \forall s \in S: o_s = \underset{o \in O}{arg \  max \  u_R(s, o)},
            \end{equation}
            where $S$ is the subject domain, $O$ is the object domain. The usefulness of the object to the subject is measured by the $u_R$ function, $u_R: S \times O \to T$, where $T$ is a totally ordered set. 
            
            There are two differences to the definition in \cite{survey}. Firstly, we define our function on a \emph{Subject domain $S$}, instead of the User domain. In our view an addressee of a recommendation can be anything, not just a user. In some cases $S=O$, e.g. when we are recommending new friends to a user.  Secondly, we parametrize the utility function by the given relationship type $R$. In our system a recommendation can be done in the means of the given relationship type. 
            
        \subsection{Relationship Prediction}
            \label{def_relationship_prediction}
            \emph{Relationship Prediction} $\hat{u}$ is an approximation of the utility function $u$: 
            \begin{equation}
                \label{eq_relationship_prediction}
                \hat{u}: S \times O \to [0, 1]  \times E,
            \end{equation}
            where $E$ is a set of textual explanations.
            
            For a given subject-object pair, $\hat{u}$ gives:
            \begin{description}
                \item[Expectancy:] the predicted probability of occurrence of the given relationship type between the subject and the object. It's a number between $0$ and $1$. The value $1$ is reserved for the subject-object pairs, that are already connected by the relationship of the given type. Thus, the objects with relationship expectancy $1$ usually aren't presented. The recommended objects are usually presented ordered by the expectancy. The exact expectancy value doesn't have to be presented.
                \item[Explanation:] a textual explanation why the object has been recommended. For some recommender algorithms explanations aren't available.
                %\item[Relationship metadata values]: coming soon
            \end{description}

            For instance, if the object and subject domains are community server users and the relationship type is friendship, for Alice and Bob the recommender can give a relationship prediction of $0.75$, with an explanation, that they have four friends in common. This means that the predicted probability of friendship between Alice and Bob is $0.75$. 
            
            Our concept is similar to the one used in the Duine framework \cite{duine}. The prediction techniques in Duine give a \emph{Prediction}, \emph{Validity indicators} and an \emph{Explanation} for each subject-object pair. \emph{Prediction} is an estimation of subject's rating of the object. \emph{Validity indicators} determine the \emph{confidence} of the technique when predicting the rating. Low values mean, that the technique isn't confident about the \emph{Prediction} for the given subject-object pair, e.g. it doesn't have enough information to make a valid prediction. \emph{Explanation} has the same meaning as the one in our recommender. 
             
            In a universal recommender we can't assume there will be a rating relationship between subjects and objects. Moreover, we are supposed to be able to predict any given relationship between subjects and objects, not just the preference expressed by the rating. In a Universal recommender, we only predict a $0/1$ indicator: there is the predicted relationship between the given subject and object, or there isn't. Hence we can shrink the prediction and confidence concepts into one - relationship \emph{expectancy}. 
            
            Let's show the reduction on an example. A recommender predicts, that \emph{Bob} will like the \emph{Five Days In Paris} book with $20\%$ probability. The like expectancy is $0.2$. For us, this is the same as predicting that Bob won't like it with $80\%$ probability. This is because, in our relationship representation, Bob either likes the book, or he doesn't. The events ``Bob likes the book'' and ``Bob doesn't like the book'' are complementary.
            
	    % like s 20% confidence neni to samy jako like s 20% expectancy. Confidence u like musi zacinat na 0.5. Pod 0.5 je to dislike - pomoci confidence se nejde prepnout z like do dislike.
            
            % napr. prediction 0, confidence 0.75 je to samy jako prediction 1, confidence 0.25. Protoze P(0) = 0.75 = 1-0.25 - protoze jevy 0 a 1 se vylucuji. 
            
            The dependency between relationship expectancy and prediction confidence is illustrated on the figure \ref{pic_expectancy_confidence}. Let prediction confidence be a function to $[0,1]$ determining how sure the recommender is about the given relationship prediction. Expectancy values just above zero indicate that the recommender is quite sure that there won't be the given relationship between the given subject-object pair. Expectancy values near $0.5$ mean low confidence for the prediction. Especially $0.5$ means that according to the recommender, the probability of the relationship occurrence is the same as for non-occurrence. Expectancy values close to $1$ mean that recommender is quite sure, that the given subject-object pair will be connected by the given relationship. 

            \fig[9]{pics/expectancy_confidence.png}{The dependency between relationship expectancy and prediction confidence.}{pic_expectancy_confidence}
	    
	    Expectancy can be useful for ordering the obtained recommended objects. For example, let's suppose we are predicting the ``like`` relationship and the list of recommended objects is ordered by the expectancy. At the beginning of the list there are objects the subject will probably like (the expectancy is close to $1$). Then there are objects the recommender is not sure about (the expectancy is around $0.5$). At the bottom of the list there are objects that will be probably disliked by the subject (the expectancy is close to $0$).
	    
	    On the other hand, expectancy isn't much intuitive for specifying the relationships in a system, so giving positiveness and confidence are used there (see \ref{representing_relationships}, \ref{representing_rules}).
	    
            In our universal recommender we don't support rating prediction directly. But as subject-object rating means a level of subject-object preference, we can estimate rating using our relationship expectancy. We only need to define mapping from relationship expectancy values to rating. Taking the subject and object from the previous example (Bob and Five Days in Paris), we can interpret Bob's $0.2$ like relationship expectation, to the rating 1 star on a 0 to 5 star scale. 

        \subsection{Recommendation}
            \label{recommendation}
            For the given subject, the \emph{Recommender System} or \emph{Recommender} performs a \emph{Recommendation} $\varrho$ -- it chooses at most $N$ subjects with the highest relationship prediction rate:
            \begin{equation}
                \label{eq_recommendation}
                \varrho: S \to \mathcal{P}_{\leq N}(O),
            \end{equation}
            where $\mathcal{P}_{\leq N}(O)$ is a $N$-limited powerset of $O$ (the set of subsets of $O$ of cardinality lower or equal to $N$).
            
            The recommender always chooses exactly $N$ objects, except the case where there are less than $N$ objects available for recommendation. The chosen objects are presented to the subject ordered by the Recommendation Rate.
            
            For instance, using the example in \ref{def_relationship_prediction}, the friendship recommender presents ten other community server users to Alice. The users are sorted by the relationship prediction rate which reflects the number of mutual friends.
        
        \subsection{Adaptation}
    
    \section{Operations in Recommender Systems}
        \label{operations}
        In a recommendation system, some common operations are:
        \begin{description}
            \item[Recommender setup:] After a configuration of the recommender is done, the recommender has to prepare itself for recommending objects. This operation can be pretty time consuming, as this doesn't have to be performed very often. 
            \item[Recommendation (see \ref{recommendation}):] Recommendation is the most common operation for a recommender system. Choosing objects with the highest Recommendation Rate for the given subject among all objects can be a very expensive operation. That's why most recommender systems introduce some kind of index, enabling the recommender to recommend objects real-time. This operation should be performed very fast, ideally in a constant time.
            \item[Prediction:] Prediction is used for estimating the subject's preference in a particular object. It can be used for direct displaying when browsing through the objects or for ordering displayed objects when browsing in an object catalog. Usually it is not possible to store predictions for all subject-object pair, so the prediction has to be computed on-line. Therefore it has to be pretty fast.
        \end{description}
    
    \section{Related Work}
        \label{related_work}
        XXX TODO doplnit white paper a duine
        The recommender research area has been strongly influenced by the Netflix prize \cite{netflix_wiki}. In the years 2006-2009, the Netflix DVD rental company held a competition on improving their recommender, awarded by the grand prize of US\$1,000,000. To the competition participants, Netflix exposed a data set of over hundred millions of ratings. Over 48,000 teams from 182 different countries participated, the competition had a huge response in both scientific and mainstream media. A paper describing the winning solution was publicly released \cite{netflix_solution}. The competition brought benefits for the Netflix company as well as for the whole recommender research world \cite{netflix_benefit}  Unfortunately, the second Netflix prize was canceled after some user privacy issues \cite{netflix_end}.
        
        \subsection{Domain Independent Recommenders}
            \label{domain_independent_recommenders}
            The idea of a domain-independent recommender isn't completely new. The most notable project in this field is an open-source project called \emph{AURA} (The Advanced Universal Recommendation Architecture) \cite{aura}. The project was supported by Sun and later by Oracle, but since the end of 2009 there's been no activity on the source code repository. The experimental music recommender based on AURA, \emph{The Music Explaura} \cite{music_explaura} seems to be inactive. The project aimed to create a universal hybrid recommender system, combining the two most used approaches: collaborative filtering and content-based recommendation (see \ref{collaborative_filtering}, \ref{content_based_filtering}). The system should have been working above a data store. More on the project can be found in \cite{aura_wiki}.  
            
            Another notable work on universal recommender is a US software patent application \emph{Universal system and method for representing and predicting human behavior} \cite{patent}. The text contains a mixture of marketing proclamations, ideas on the recommender architecture, description of recommender and machine-learning algorithms and ideas on capturing implicit user ratings. In our opinion, the recommending methods presented in the text could be working well only on very small sets of data, for larger data sets, the ammount of time needed for performing some basic operations wouldn't be acceptable. The final paragraph, trying to claim everything around, from vector object representation to capturing the action of user adjusting the volume on his music player, gives a negative example of where the idea of software patents can lead. As far as we know there's no functional recommender system based on this patent. 
            
            white paper, 
            Duine - trochu moc se tam pracuje s tim user ratingem. mixuju podobne pravidla a relationships jako on recommendation techniques. (minimalne mam podobne prostredky), ale nekaskaduju. 


\chapter{Recommender Algorithms}
    \label{algorithms}
    In the chapter we list and describe algorithms that are commonly used for recommending. For each algorithm we describe its capability to be domain-independent, and the its capacity to use multiple data sources as an input.

    \section{Content-based Methods}
        \label{content_based_filtering}
        Content-based filtering methods are one of the oldest and most popular methods for recommending. The principle of these methods is recommending objects that are similar to some objects, the user liked in past. The similarity among the objects is determined from the values of their characteristics. 
        
        These methods are widely used in text-based applications, for recommending documents or web sites \cite{survey}. One of the implementations of a content based based recommender is the Music Genome Project \cite{wiki_genome}. A musician analyzes each song in the system, giving a value for each of the musical characteristics. 
        
        The figure \ref{pic_content_based} shows an example of a content based recommender. The known relationships are marked as full arrows, the calculated or inserted object similarity by the dotted arrow and the predicted relationship by the dashed arrow.
        
        \fig{pics/content-based.png}{Content-based Methods}{pic_content_based}

        More formally, according to \cite{survey}, the utility function $u_R(s, o)$ of subject $s$, object $o$ and relationship $R$ is estimated based on the utilities $u_R(s, o_i)$ assigned by subject $s$ to objects $o_i \in O$ that are similar to object $o$. The method can be enhanced by introducing \emph{subject profiles} containing information about subjects' tastes. 
        
        \subsubsection{Benefits and Drawbacks}
        The accuracy of the provided recommendations strongly depends on the similarity determination. If the items are characterized properly and the subjects tend to like uniform sets of objects, the recommender can be pretty successful, as \cite{wiki_genome} mentioned above. However there are several drawbacks of the method, as mentioned in \cite{survey}:
        \begin{description}
            \item[Limited content analysis:] The set of characteristics assigned to each object is always limited and is never able to fully characterize the object. Moreover the values of the characteristics have to be determined either manually which is time-consuming or automatically which currently works well only for text documents. 
            \item[Overspecialization:] The method always recommends objects that are similar to some that the subject liked in the past. Therefore the recommender never broadens subjects' horizon by recommending diverse objects.
            \item[New user problem:] When a new subject emerges in the system and has no relationships to objects, the system cannot make any recommendations to the subject.
        \end{description}

        \subsubsection{Suitability for The Universal Recommender}
        In a domain-independent recommender we cannot assume that there are sufficient object characteristics available. However we would like to use the concept of recommending objects that are similar to the ones that were already liked. The concept has to be implemented so that the similarity rules are given in the adaptation phase. Therefore the recommender wouldn't rely on any specific object attributes and would remain domain-independent.
        
        The advantage of the content-based method is its capability of using multiple attributes for determining object similarity. 

    \section{Collaborative Filtering}
        \label{collaborative_filtering}
        Collaborative filtering is currently one of the most widely used technique for recommending. Market leaders as Google \cite{google_news}, Amazon \cite{amazon} or Yahoo! \cite{yahoo} use recommenders at least partially based on collaborative filtering. 
        
        For recommending an object to a subject, the method uses relationships between other subjects and objects. For a given subject $s$, the algorithm finds subjects that like most of the objects that $s$ likes. Recommended objects are then taken from other objects liked by the found subjects. 
        
        In the figure \ref{pic_collaborative} there is a simplified example of a recommendation made by collaborative filtering. The full arrows represent already known relationships. The two subjects both have a relation to one item and therefore they are treated as similar. The recommendation is marked by the dashed arrow. An object to be recommended is chosen from the similar subject's related objects so that the subject isn't related to the object.
        
        \fig{pics/collaborative.png}{Collaborative Filtering}{pic_collaborative}
        
        The collaborative filtering methods can be divided into several groups. The overview of the groups can be seen in the figure \ref{pic_collaborative_groups}), names of the techniques and algorithms belonging to the given groups are in italics.
        
        \fig{pics/collaborative_groups.png}{Classification of the collaborative filtering algorithms}{pic_collaborative_groups}
        
        By the manner in which the unknown relationships are predicted, collaborative filtering methods can be divided into two groups: \emph{Memory-based} and \emph{Model-based} \cite{survey}.
        
        \subsection{Memory-based Collaborative Filtering}
            Memory based (or heuristic-based) methods are historically the first collaborative filtering methods. In memory-based prediction methods, the predictions of possible relationships are counted as an aggregate of the known subject-object relationships. The aggregate function can be a simple average or some more sophisticated measure using relative differences to average ratings or inter-subject similarity. 
            
            \emph{Neighbourhood methods} belong to this category. For recommending an object to a subject they use relationships of the neighbouring subject or object (depending on the recommender being subject-based or object-based). The neighbour is defined as the subject/object having the highest similarity to the given subject/object. The similarity can be counted in many ways, including the Pearson correlation coefficient or Cosine measure \cite{survey}. 
            
            The memory-based methods can further be divided into two groups by the direction which is used for recommending: \emph{Subject-based} or \emph{Object-based}. 
            
            \subsubsection{User-based Collaborative Filtering}
                Subject-based (or user-based) methods are centered to the subjects. In this traditional variation, the similarity of subjects is computed. More formally, according to \cite{survey}, the utility function $u_R(s, o)$ of subject $s$, object $o$ and relationship $R$ is estimated based on the utilities $u_R(s_j, o)$ assigned to object $o$ by the subjects $s_j \in S$  who are similar to subject $s$. Usually the similarity between subjects is determined by comparing their relationships to objects. 
            \subsubsection{Item-based Collaborative Filtering}
                Object-based (or item-based) methods have been popularized by Amazon.com \cite{amazon}. The principle of the algorithm remains the same, but the algorithm starts at the objects and similarity between objects is computed. Objects sharing the same related subjects are taken as similar. The objects recommended to a subject are taken from objects similar to those the subject is related to. The method can also be used for showing products that are related to a product that is viewed by an anonymous user, as can be seen in the Amazon.com product catalogue: ``Users that bought product $x$ also bought product $y, z$''. The easiest implementation of the item-based memory-based collaborative filtering is the \emph{Slope One} method. 
                
                Another way how to measure the similarity is the cosine measure, which is used in the \emph{Item-to-Item} algorithm patented by Amazon.com \cite{amazon}. The objects are represented as vectors. To count similarity between two objects, subjects that have a relationship to both of these objects are taken. Each such subject represents a dimension in the object vectors, the value is determined from the subject's rating or $0/1$ (the subject has bought/viewed the object or not). The similarity between two objects is then counted as a cosine of the object vectors \cite{amazon}.

        \subsection{Model-based Collaborative Filtering}
            Model-based recommenders use machine-learning techniques to learn a \emph{model} that predicts unknown relationships. The known relationships are used as training data for the model. The machine-learning techniques include \emph{Bayesian networks}, \emph{latent factor models}, or \emph{artificial neural networks} \cite{survey}.
            
            Latent semantic models use vectors to represent subjects and objects \cite{bellkor_ieee}. For objects, the values in the vectors mean some characteristics of the object. This approach is similar to the one used in content-based filtering (\ref{content_based_filtering}). The difference is in obtaining the vectors: the values in object vectors aren't submitted by a human expert, both subject and object vectors are learned from the known data by various techniques. Therefore the technique is domain-independent. 
            
            Subject and object vectors allow to project the subjects and object into multidimensional space. Recommended objects are those that are ``near'' the given subject in the multidimensional space. Some common techniques for measuring the subject-object distance are vector cosine and dot product. Some dimensions can be coupled with some known object characteristics as genre for movies \cite{bellkor_ieee}. But the meaning of most of the dimensions can hardly be discovered, as they aren't designed by a human but a machine-learning technique. Consequently, the recommenders using matrix factorization usually aren't able to give reasons for their recommendations. 
            
            Figure \ref{pic_latent} shows some users and items projected to a simplified two-dimensional space. Their nature determines their positions in the space. Items that are near each user are likely to produce a positive response from the user and hence they are good for recommendations. 
            
            \fig{pics/latent.png}{Latent factor model recommender}{pic_latent} 
            
        \subsection{Benefits and Drawbacks}
        \label{cf_benefits_drawbacks}
        
        In general, collaborative filtering methods are currently the most used and the most successful methods for recommending. When properly used, they provide high accuracy and scalability for large ammount of data. However they have some drawbacks too \cite{survey}.
        \begin{description}
            \item[Cold start problem:] As for the content-based method, the system doesn't know any liked objects for a new subject. For a user being a subject, this problem can be solved by asking the user to enter some data. This approach is used in the Netflix system. A new user is given a questionnaire for rating some chosen movies \cite{bellkor_2009}. Another solution to the problem is using a hybrid recommender (\ref{hybrid_recommenders}) that would use an easier recommender (like giving the most popular objects) when predictions from collaborative filtering aren't available.
            A similar problem occurs when a new object is added to the system, it's not related to any subject and therefore it can never be recommended. This can be solved also by a hybrid recommender (\ref{hybrid_recommenders}). 
            \item[Sparsity:] The subject-object matrix is usually very sparse - the number of known relationships is very small compared to the number of relationships that should be predicted. Therefore, in most of the collaborative filtering methods, the objects related to few subjects are seldom recommended. This drawback is overcome by some of the model-based methods, e.g. matrix factorization \cite{bellkor_ieee}.
            \item[Grey sheep problem:] This problem is mentioned in \cite{knowledge_spain}. In the system, there might be subjects whose preferences aren't consistently similar to other subjects. Therefore they don't belong to any preference subject group and they can't get any accurate recommendations.
         \end{description}
        \subsubsection{Suitability for The Universal Recommender}
        One of the biggest advantage of collaborative filtering is its domain independence. Generally, the algorithms don't assume any properties of subjects or objects, they just use the relationships between subjects and objects to make recommendations. Of course, the recommender tuned for a particular domain can't be used directly for other domain, but the core algorithm is domain-independent.
        
        The universal recommender proposed in \cite{white_paper} is based on the idea of model-based collaborative filtering techniques. 
        
        The disadvantage of collaborative filtering is that it's limited to a single subject-object preference data source - usually an explicit rating. For our purposes it would have to be adapted so that it can process multiple data sources.
    
    \section{Knowledge-based Recommenders}
        \label{knowledge_based}
        
        Although the main focus in the recommender research field is on collaborative filtering, possibilities of knowledge-based recommenders are still being studied.
        
        There are many approaches to knowledge-based recommending. One of them is presented in \cite{knowledge_burke}. The user interaction to the system is similar as in the case of performing a search. At first, the  user specifies an item that he/she likes. Then the system iteratively presents similar items to the user. The user further specifies his/her preferences, like ``I would like a more romantic/adventurous movie''. This continues until the user is fully satisfied with the presented item.
        
        One problem of the approach is that the recommendations aren't personal. There are no user profiles in the system, so the recommendations are based only on data given by the user during the search. The author describes how to reduce this disadvantage in \cite{integrating_burke}. The items found by the knowledge-based recommender are sorted by the integrated collaborative filter. Another problem of this approach is bothering the user. The user has to fully specify his preferences in order to get some good recommendations. Although the system leads the user through the search, it can take a lot of time to find the right item.
        
        The article \cite{knowledge_spain} proposes a bit different approach. Their knowledge-based recommender is trying to solve the ``cold start problem'' (see \ref{collaborative_filtering}). When a new user registers to the system, he/she is asked to choose an example of an item he/she likes in the item catalogue. Then the user is asked to compare the item to some other items, using a scale from zero to one, determining how much the item is preferred over the other. An underlying algorithm exploits this knowledge to the whole item catalogue and uses the data for making recommendations. This approach is more usable than the first described one, as it demands the user input only once - when he/she is registering. Nevertheless new users are more sensitive to being asked a lot of questions and there's a risk, that the user leaves for a rival system. The presented recommender is only a theoretical suggestion, there might be some problems with scalability to large numbers of users and items.
        
        Recommendation by ordering is also discussed in \cite{order}. The authors of the article describe an advanced algorithm for exploiting the known relative preferences to the whole domain. The performance evaluations of the presented algorithm look very promising. Nevertheless, obtaining reliable relative preferences without bothering the user is difficult and requires some non-trivial domain knowledge. 
        
        Another approach to knowledge-based recommender was used in the \emph{RACOFI} system \cite{racofi}. The system consist of a collaborative filtering engine (\emph{COFI}) and a rule applying agent (\emph{RALOCA}). The primary recommendation is done by COFI. The rules are then used for adjusting the recommendation rate or removing objects from recommendations. The rules are applied on \emph{objective} data we know about the subjects and objects, like age and genre respectively. 
        
        The \cite{racofi} report shows that rules can handle boundary cases by removing inappropriate objects for recommendations. They can also refine recommendations by applying some rules that were found empirically. We find the idea of applying rules for recommending interesting, especially when there's not enough data for making other types of recommendation. The other benefit of rule-based recommending is the ability to give good explanations why the objects were recommended.

        \fig{pics/knowledge.png}{Knowledge-based Recommender}{pic_knowledge} 
        
        Accordng to \cite{knowledge_spain}, there are three types of knowledge, a recommender system can deal with:
        \begin{description}
            \item[Catalog knowledge] provides information about objects and their features.
            \item[Functional knowledge] provides information about how objects meet subjects' needs. 
            \item[User knowledge] contains information about subjects' needs. 
        \end{description}
        
        \subsubsection{Suitability for The Universal Recommender}
        Business knowledge can give an added value to a recommender, as some rules are well-known and often cannot be easily extracted from the underlying data. Therefore, if a way how to enter some basic domain-specific rules is found, the knowledge based recommender can be included into the universal recommender. 
            
    \section{Other Domain-specific Methods}
        There are a lot more algorithms for recommending, but all of them rely on specific data that must be available about the subjects or objects for the recommender to work well. As these aren't acceptable for the universal recommender, we list only a few of them.
        \subsection{Social Networks and Link Prediction}
            In social networks, there are links between users, such as the \emph{friends} link. If these are available, the recommender can recommend an object according on what user's friends liked. A schematic picture of the a social network recommender can be seen in the figure \ref{pic_social}.
            
            \fig{pics/social.png}{Recommending in social networks}{pic_social} 

        \subsection{Demographic Filtering}
            When we have some additional information about users such as nationality, residence, age or occupation, we can use it for determining similarity between the users. A demographic filtering method can be used as an additional measure of user similarity when there's little known about the user's taste. An example of a recommendation made by a demographic filtering recommender can be seen in the figure \ref{pic_demographic}.
            
            \fig{pics/demographic.png}{Demographic Filtering}{pic_demographic} 
            
        Even though these methods require some specific data to be present in the domain, we would like our universal recommender to work with such data. E.g. in the domain where demographic data is available, we should be able to use them for making recommendations.

    \section{Hybrid Recommenders}
        \label{hybrid_recommenders}
        Hybrid recommenders combine two or more recommending methods in order to improve the produced recommendations. There are several ways how to combine them.
         
        For enhancing the success of produced recommendations, we can use a hybrid recommender that uses all its underlying methods when producing any recommendation. The combined methods can be of various types, using various relationships among subjects and objects. A combination of content-based and collaborative filtering is quite popular, possibilities of combining the two methods into a single hybrid recommender are listed in \cite{survey}. The combination of memory-based and model-based collaborative filtering is often used in contemporary commercial recommenders, as in \cite{google_news} 
        
        A hybrid recommender can help to overcome some drawbacks of the recommendation methods, as the \emph{Cold start problem} (see \ref{cf_benefits_drawbacks}). In this case, when little data is known about a new subject and object, some subsidiary recommendation method can be used. This subsidiary method wouldn't be suitable for performing the most of the recommendations, but it can make the best of the little data that is available. This approach is used in the default strategy of the Duine recommender framework \cite{duine}.
        
        Figure \ref{pic_hybrid} shows a recommendation for a new user, performed by a hybrid recommender combining social links and collaborative filtering. 
        
        \fig{pics/hybrid.png}{Hybrid Recommender}{pic_hybrid} 
        
        \subsubsection{Suitability for The Universal Recommender}
        As presented in \cite{white_paper}, the specific combination of methods used in a hybrid recommender depends on the data available in the given domains. Therefore a hybrid recommender can't be generic. Finding the right combination of recommenders for the specific domain can be non-trivial and thereby hybrid recommenders aren't suitable for a universal recommender. 

    \section{Algorithm Selection}
        \label{algorithm_conclusion}
        In the chapter we have described all common contemporary approaches to recommender systems, their suitability for domain-independent recommending has been evaluated. In a universal recommender we cannot assume that any specific relationships or subject and object properties exist, so our choice narrows a lot.
        
        Our vision of using business rules for recommending intersects with the knowledge based recommender. \ref{knowledge_based}. However there will have to be a domain-independent mechanism for representing and combining the business rules.
        
        From the studied algorithms, the only one that is domain-independent by nature is \emph{collaborative filtering}. All the others are dependent on some specific features of subjects or objects, or they suppose some specific relationships. Therefore, our universal recommender should be based on a collaborative filtering algorithm. 
        
        We have noted, that there's a gap between our requirements for a universal recommender system and collaborative filtering algorithms: We would like to make use of multiple data sources including object and subject similarity, and domain specific rules. The collaborative filtering in its typical implementation takes only a single source of data - subject-object rating. The gap between our requirements and the input of a collaborative filtering algorithm should be filled by the Unresyst application. It should process all the inputs it has, into a single subject-object preference prediction. This prediction can be then used directly for recommending or it can serve as an input for a common collaborative filtering algorithm.
        
        There are a lot of types of collaborative filtering algorithms, as can be seen in the \ref{collaborative_filtering} section. The algorithms differ in many aspects as time complexity, accuracy of the predictions or possibility to reflect the updates in the domain. Each domain has its own requirements on the named aspects and therefore Unresyst shouldn't be bound to a particular algorithm. Rather than that it should be able to use an arbitrary collaborative filtering algorithm in its algorithm layer. When implementing a recommender to a system we should be able to choose whether to use the predictions directly for recommending or to choose the right algorithm to fit the domain properties and needs.

        \subsection{Combining Knowledge-based and Collaborative Filtering Recommenders}
            \label{combining_knowledge_and_cf}
            The only method that wasn't generalized by the universal recommender proposed in \cite{white_paper} is the knowledge-based method. As we have shown in \ref{knowledge_based}, simple domain-specific rules can enhance the recommendation accuracy, especially when there's little preference data available. Hence, incorporating a possibility to enter some simple domain-specific set of rules when adapting the universal recommender to a domain, would be interesting. We found a few options how to merge the evaluation of knowledge rules with collaborative filtering:
            \subsubsection{A hybrid recommender for knowledge-based and collaborative filtering}
            
                \fig[7]{pics/knowledge_cf_hybrid.png}{Combining Collaborative Filtering and Knowledge Based Recommender as a Hybrid Recommender}{pic_knowledge_cf_hybrid}
                 
                In this variation there are independent knowledge based and collaborative filtering recommenders. This approach was used in the RACOFI system \cite{racofi}. For a relationship prediction, if a rule is available, it is used for predicting the relationship together with the underlying collaborative filtering algorithm. If not, only the collaborative filtering is used. Although this is a possible combination of the recommenders it has some significant drawbacks. The method introduces a tension between the two recommenders. The results of the collaborative method, which should be universal are in some cases distorted by the knowledge recommender. This problem would lead to incorrect learning in the model-based algorithms, as some manipulations are done outside the model and therefore the method cannot fully affect the resulting predictions.
               
            \subsubsection{Using the knowledge-based predictions as an input for collaborative filtering} 
                Alternatively, using the business rules given during the adaptation to a specific domain, we can generate a prediction (a kind of rating) that is later used in the underlying collaborative filtering algorithm. The prediction is available for subject - object pairs, for which some rules can be applied. The rules are only used during the initial recommender build to provide an input for the collaborative filtering. The recommendations then are done solely by the collaborative filtering algorithm. The advantage of the approach is, that the information from the knowledge-based algorithm is available in the initial phase and can be used for the collaborative filtering model build. 
                
                \fig[7]{pics/knowledge_cf_above.png}{Using predictions from Knowledge based recommender as an input to Collaborative Filtering}{pic_knowledge_cf_above}
            
            
            For the given reasons we choose the second option. Another advantage of this approach is that the recommendation time will be dependent only on the recommender algorithm. The implementation of the chosen approach is thoroughly described in the chapter \ref{architecture}.
        
\chapter{Business Rules and Relationships in Studied Systems}
    In the chapter we analyze selected systems where the Unresyst recommender could be used. As we don't have a direct access to the system databases, we use datasets\footnote{Dataset is a set of text files containing some part of data included in the system database}. The first two datasets - Last.fm and Flixster are publicly available. The third one (Czech travel agency e-shop dataset) was made accessible to the thesis author by the courtesy of the system administrator.
    \section{The Last.fm Dataset}
        \label{rel_last_fm}
        basic data about both subjects and objects, relationships
        \fig[14]{pics/lastfm.png}{The data model of the Last.fm dataset}{pic_last_fm}

    \section{The Flixster Dataset}
        classic collaborative filtering having additive social data.
        \fig[8]{pics/flixster.png}{The data model of the Flixster dataset}{pic_flixster}
    
    \section{The Travel Agency Dataset}
        Different kinds of implicit feedback
        \fig[18]{pics/travel2.png}{The data model of the Travel Agency dataset}{pic_travel}
    
    \section{Relationship Abstraction Summary}
        \label{relationship_abstraction_summary}
        This section summarizes the type of rules and relationships that appeared in the studied systems. 

\chapter{Universal Recommender Design and Implementation}
    \label{design_and_implementation}
    
    The chapter describes how the Universal Recommender was implemented. Firstly we give an overview of the architecture, then we describe the interfaces through which Unresyst communicates with the parent system. Then we describe the algorithm used for applying rules. High-level architecture of the Universal Recommender, the layers of the application, are studied in the following section. Finally we give a more detailed overview of the inner structure of Unresyst.

    \section{Universal Recommender Architecture Overview}
        \label{architecture}
        The Universal Recommender System (Unresyst) is an independent application working with database. The parent system uses Unresyst for creating recommendations through a set of interfaces.
        
        The Universal Recommender is designed so that it's independent of the domain, working only with abstract relationships. Several instances of the recommender can be run on a single system, so the Universal Recommender can run with various configurations for one parent system.
        
        The recommender doesn't have to be directly a part of the parent system, its database is logically independent of the parent database system. The parent system and the recommender communicate only through the interfaces. There are no implicit links on the application nor on the database level. Hence the recommender could be easily run on an independent server.
        
        Unresyst provides two interfaces to the parent system: the \emph{Adaptation Interface} and the  \emph{Runtime Interface}. The Adaptation Interface is used only during the system setup and maintenance. See the section \ref{unresyst_process_draft} for a more detailed description of the actions taken during the adaptation. On the other hand, the Runtime Interfaced is used continuously by the parent system to provide recommendations.
        
        The figure \ref{pic_unresyst_adaptation} shows how Unresyst can be adapted to a domain on the example of the music domain. In the example we create two recommenders for a domain. A domain expert firstly creates the desired recommenders. In the example it's a \emph{Novel Artist Recommender} and a \emph{Artist Radio Recommender}. Both recommenders suggest artists to listeners. The Novel Artist recommender tries to broaden listener's music horizons by suggesting artists the listener haven't heard yet. Whereas the Artist Radio Recommender suggests artists to a listener no matter if he/she has already heard it. Such a recommender can be used for an internet radio.
        
        Each recommender has two interfaces: \emph{Adaptation Interface} and \emph{Runtime Interface}. The domain expert uses the Adaptation interface to adapt Unresyst to the music domain. The adaptation is done by defining basic recommender properties and a set of rules. The design and the usage of the Adaptation Interface is later described in the section \ref{adaptation_interface}.
        
        \fig{pics/unresyst_adaptation.png}{Adapting Unresyst to the music domain done by a domain expert.}{pic_unresyst_adaptation}
        
        In the figure \ref{pic_unresyst_runtime} there is a schema of how a system that is using Unresyst operates. The user accesses the system as usually through its graphical interface (GUI). The Unresyst GUI which is a part of Unresyst is plugged into the Tennis Server user interface and it presents recommendations to the user. The Unresyst GUI as well as the parent system uses the Runtime Interface of both recommenders to get recommendations and to provide information needed for making recommendations. Both recommenders transfer the calls to the Unresyst module. The design and usage of the Runtime Interface is later described in the section \ref{runtime_interface}.
        
        \fig[17]{pics/unresyst_runtime.png}{Unresyst common usage.}{pic_unresyst_runtime}
        
    \section{Unresyst Interfaces}
        \label{unresyst_interfaces}
        In order to make Unresyst independent of the parent system we have defined interfaces through which the parent system and Unresyst communicate. Unresyst has a set of two interfaces: the Adaptation interface and the Runtime interface. 

        \subsection{Adaptation Interface}
            \label{adaptation_interface}
            A well defined adaptation interface is critical for the success of the recommender. The interface has to be general enough to cover most domains and data sources they contain. At the same time it has to be clear and easy to use.
            
            The interface is used in the \emph{adaptation} phase of Unresyst setup. All initial data that is needed by Unresyst to provide recommendations are passed through this interface. Through the adaptation interface the following parts are given:
            \begin{description}
                \item[Subjects and Objects:] When adapting Unresyst to a domain, we have to define what and to whom we would like to recommend. In our implementation, this is done through an ORM Manager class covering the tables where subjects and objects respectively are stored. In our example we use managers pointing to the \emph{User} and \emph{Artist} table.
                
                \item[The Predicted Relationship:] We have to define which relationship in the parent system data model is the preference. This is done in the way described in \ref{representing_predicted_relationship}. In our example we use the relationship ``User played Artist's track'' as the predicted relationship.
                
                \item[Rules and Relationships that influence recommendations:] When we want to use business rules or relationships for making recommendations we have to define them through the adaptation interface. The way to define rules and relationships is described in sections \ref{representing_rules} and \ref{representing_relationships}. An example of a subject-object rule is the mentioned ``Music having the given tags shouldn't be recommended to female users''. An example of an object similarity rule influencing the prediction is ``Artists sharing tags are similar''. An example of a subject similarity relationship is the mentioned ``Users coming from the same country are similar''. The difference between a rule and a relationship is the following: For rules we'd like to give a specific strength for each covered pair, i.e. for artists sharing some tags we can give a percentage of how much tags they're sharing. Whereas in relationships, we only know there's some connection, that can't be weighted for the particular pair, i.e. if the users are coming from the same country, they are similar without any further strength differentiation for different pairs of users coming from the same country.
                
                \item[Biases:] Some objects are more likely to be liked than others, independently of the subject to whom we're recommending - these are called object biases. Subject biases indicate a higher tendency for a subject to like an object, independently of the particular object. Such facts can be included to recommendations by defining biases. More about representing biases can be found in section \ref{representing_biases}. An example of a positive object bias is the mentioned ``Artists that have released a new album recently''.
            \end{description}
            
            In our implementation, the adaptation interface is used by deriving a class from the predefined Unresyst \emph{Recommender} class. In the example we define an \emph{ArtistRecommender} class, that holds all domain specific data. The following piece of \emph{Python} code shows the definition of the music recommender from the example. Subjects of recommending are system users, recommended objects are artists. The definition of the rules, relationships and biases is discussed in the sections that follow.
            
            \begin{verbatim}
from unresyst import Recommender
from models import User, Artist

class ArtistRecommender(Recommender):
    """A recommender recommending artists (musicians) that 
    the user can like.
    """    

    name = " Artist Recommender"
    """The name"""    
    
    subjects = User.objects
    """The subjects to who the recommender will recommend."""
    
    objects = Artist.objects
    """The objects that will be recommended."""
                    
            \end{verbatim}

            \subsubsection{Representing Rules}
                \label{representing_rules}
                In the section we discuss the possibilities of implementing the rule representation, then we list the properties of the representing class. Finally we present a code of the rules of our example recommender for our prototype implementation 
                
                During the adaptation phase, the domain expert can introduce business rules that will be used for creating recommendations. As in \cite{racofi}, our rule consists of a \emph{condition} determining when the rule should be applied, and an \emph{action} defining what should be done if the condition is satisfied. The representation should use an easy human-editable notation, so that the rules can be easily added and later edited. Opposed to business relationships, for rules we have some kind of strength that is specific for each covered pair, i.e. for artists that share some tags we have a percentage of shared tags.
                
                The RACOFI framework \cite{racofi} uses two types of actions: \emph{Modify} that modifies the predicted subject's object rating by a given constant and \emph{Not Offered} that excludes an object from subject's recommendation.
                
                Our rules aren't modifying predictions, but they serve as an input for the predicting algorithm (see the section \ref{combining_knowledge_and_cf} for the reasons why this way of integrating rules to collaborative filtering was selected). Therefore we will use absolute values, not relative values as in RACOFI \emph{Modify} rules. The \emph{Not Offered} rule type can be represented by a rule giving minimal value, so we don't need to have a special rule type for it. 
                
                In our rules we would also like to represent inter-entity similarity. Hence we will use the following types of rules:
                \begin{enumerate}
                    \item \label{ex_s_o} \emph{Subject-object rules} defining subject-object interactions that can be used for recommending objects to subjects. An example of a negative subject-object rule is the mentioned ``Music having the given tags shouldn't be recommended to users of the given gender''.
                    \item \label{ex_s_s} \emph{Subject-subject rules} defining similarity between subjects. An example of a positive similarity rule is ``Users of similar age are similar''.
                    \item \label{ex_o_o} \emph{Object-object rules} defining similarity between objects. An example of a positive similarity rule is the mentioned ``Artists sharing some of their tags are similar''.
                \end{enumerate}
                
                There are several ways how to represent rules. The first studied one is \emph{RuleML (Rule Markup Language)} \cite{ruleml}, a XML-based markup language for representing rules. The language is very powerful, having the same expressiveness as declarative programming languages\footnote{There are several converters between the \emph{Prolog} programming language and RuleML, e.g. \cite{ruleml_prolog}}. RuleML was used for entering rules into the RACOFI recommender system \cite{racofi}.

                Creating and editing rules in RuleML isn't very convenient as creating and editing any other XML-based document. That is partially solved by a shortened notation \cite{ruleml_short}, but even that isn't very comfortable to a user that isn't experienced in declarative programing. Another drawback of using RuleML for our purpose is its generality. The set of conditions and actions we'd like to represent is very limited and therefore we don't need such a powerful language. 
                
                Another drawback of such a general notation is the efficiency of evaluating rules. The classical substitution of all possible pairs to the condition wouldn't be feasible for larger domains. See \ref{unresyst_details} for details on how evaluating rules was implemented in a more efficient way.
                
                Another option would be to directly use a logic programming language as \emph{Prolog}. This option has the same drawbacks in over-generality and user-unfriendliness as RuleML. Additionally we would have to incorporate a logic programming language interpreter to Unresyst. The following lines of code show our example rules written in the Prolog declarative language. The code is meant only as an and shows the possible actions without defining all necessary predicates. The predicates don't consider the strength of the rule conclusion.
                
                \begin{verbatim}
% don't recommend artists with male-specific tags to females
dont_recommend(U, A) :- 
    is_user(U),
    is_artist(A),
    female(U),
    artist_tagged(A, T),
    male_specific(T).

% users of similar age are similar
similar_subjects(U1, U2) :-
    is_user(U1),
    is_user(U2),
    similar_age(U1, U2).

# artists sharing some tags are similar
similar_objects(A1, A2) :-
    is_artist(A1),
    is_artist(A2),
    artist_tagged(A1, T),
    artist_tagged(A2, T).
                \end{verbatim}
                
                An option better fitting our needs is to implement our own \emph{Object-oriented rule representation}, where we represent rules as instances of a rule class. In the adaptation phase, the domain expert instantiates the pre-defined classes to create  business rules.
                
                The \emph{expectancy} concept (\ref{def_relationship_prediction}) is powerful but not very intuitive for defining the impact of the rules on predicting relationships. By defining a rule with expectancy we would be able to indicate positive as well as negative impact on predicting the given relationship because low values of expectancy have negative impact on preference and high values positive. Defining directly the expectancy of a rule would result in complicated functions and could lead to confusion and misinterpretation. Hence, for rule definition, we use a less general but more intuitive concept of \emph{confidence} and \emph{positiveness}.
                
                Each rule is either defined as \emph{positive} or \emph{negative}. Positive rules increase the prediction of the given relationship, negative rules decrease it. Each rule additionally has a confidence function defining how strong (positive resp. negative) the rule is for the given pair of entities. Events that can have both positive and negative impact should be represented by two rules.
                
                Another advantage of using confidence and positiveness is a more intuitive approach to defining positive and negative rules, as the recommender uses only the part (positive or negative) that we have defined. I.e. the negative rule of not recommending a specifically tagged artists to female listeners doesn't necessarily mean we would like to recommend these artists to all male listeners (positively). If we define the negative rule, only the negative part will be taken. If we wanted to incorporate the positive part too, we would define a new positive rule. 
                
                In the examples, we will be predicting the \emph{User listens to artist's tracks} relationship, representing the preference of the user to the given artist. 
                
                For our object-oriented rule representation we define a class which instances hold conditions, actions and some additional data. As we have showed, the only possible actions are determining the confidence of the subject-object relationship and determining inter-entity similarity. Therefore actions will be represented as functions giving a confidence of the preference or similarity. The rule objects contain:
                \begin{description}
                    \item[Condition:] A boolean function determining whether the rule can be applied to a given entity pair. The function is defined depending on the rule type:
                    \begin{description}
                        \item[Subject-object condition] $C_{so}:S \times O \to \{False, True\}$. A function takes a subject-object pair and determines whether the rule can be applied to the pair. In our example \ref{ex_s_o} the condition function is: If the user $s$ is a female and artist $o$ is tagged by one of the given tags, the condition evaluates to \emph{True}. Otherwise it's \emph{False}
                        \item[Subject-subject condition] $C_{ss}:S \times S \to \{False, True\}$. A function takes a subject-subject pair and determines whether the rule can be applied to the pair. In our example \ref{ex_s_s} the condition function is: If we know the age of both of the users, the condition is \emph{True}, otherwise it's \emph{False}.
                        \item[Object-object condition] $C_{oo}:O \times O \to \{False, True\}$. A function takes an object-object pair and determines whether the rule can be applied to the pair. In our example \ref{ex_o_o} the condition function is: If the artists share some tags, the condition is \emph{True}, otherwise it's \emph{False}. 
                    \end{description}
                    \item[Is Positive:] A  boolean constant (\emph{True} or \emph{False}) for determining whether the rule is positive for the predicted relationship or negative. I.e. the rules \ref{ex_s_s} and \ref{ex_o_o} are positive, the rule \ref{ex_s_o} is negative.
                    \item[Confidence:] A function determining the strength of the subject-object preference in means of the predicted relationship or subject-subject/object-object similarity in a positive or negative way.
                    \begin{description}
                        \item[Subject-object relationship confidence] $D_{so }:S \times O \to [0,1]$. A function takes a subject-object pair and gives a confidence, that the \emph{predicted relationship} appears (when positive) or doesn't appear (when negative). High values mean strong confidence. Low values mean that the rule is unsure about the impact (positive or negative) on the preference. This makes a similar effect as if the condition $C$ wasn't satisfied for the subject-object pair. In our example \ref{ex_s_o} we can use a linear confidence function. The more of the given tags the artist has, the higher is the resulting confidence. \item[Subject-subject similarity] $D_{ss}:S \times S \to [0,1]$. A function takes a subject-subject pair and determines similarity between the subjects. The higher the confidence, the more similar (or dissimilar if negative) the subjects are, according to the rule. In our example \ref{ex_s_s} we use a confidence function that returns a normalized difference between the age of the two users. 
                        \item[Object-object similarity] $D_{oo}:O \times O \to [0, 1]$ A function takes an object-object pair and determines similarity or dissimilarity between the objects. The higher the confidence, the more similar (or dissimilar when negative) the objects are, according to the rule. In our example \ref{ex_o_o} the confidence function returns the number of common tags normalized by the overall number of tags.
                    \end{description}
                    \item[Weight:] $w \in [0,1]$ A constant between $0$ and $1$ determining the strength of the rule. Weight, unlike confidence, is independent of the particular entities on which the rule is evaluated. The weight should be set so that the more significant rules get higher weight. The exact weight values should be checked experimentally.
                    \item[Description:] A text explaining the meaning of the rule. Descriptions can be used when presenting recommendations to users. In the text there can be gaps that that will be filled with a textual representation of entities. Our example rule \ref{ex_s_s} can have a description ``The users \{subject1\} and \{subject2\} are similar because their age is similar.''
                \end{description}
                
                The following lines of code show the rules written in our Python prototype recommender implementation.
                \begin{verbatim}
from unresyst import *
from models import *

AGE_DIFFERENCE = 38 - 17
"""The age difference between the oldest and the yongest user"""

class ArtistRecommender(Recommender):
    """A recommender recommending artists (musicians) that 
    the user can like.
    """    
    
    # ...
    
    # the class contains definitions for business rules
    rules = (
    
        # don't recommend artists with male-specific tags to females
        SubjectObjectRule(
            name="Don't recommend male music to female users.",

            # the user is a female and the artist was tagged by
            # a male-specific tag
            condition=lambda user, artist: user.gender == 'f' and \
                artist.artisttag_set.filter(tag__gender_specific='m').exists()
            
            # it's a negative rule
            is_positive=False,
            
            weight=0.5,
            
            # the more male-specific tags the artist has, the higher is 
            # the rule confidence. Normalized by the artist tag count
            confidence=lambda user, artist: float(
                artist.artisttag_set.filter(tag__gender_specific='m').count())/ \
                    artist.artisttag_set.count(),
                    
            description="Artist %(object)s isn't recommended to %(subject)s, " +
                "because the artist is considered male-specific."
        )
                
                
        # users of similar age are similar
        SubjectSimilarityRule(
            name="Users with similar age.",
            
            # both users have given their age and the difference 
            # is lower than five
            condition=lambda user1, user2: 
                user1.age and user2.age and abs(user1.age - user2.age) <= 5,
                
            is_positive=True,   
                
            weight=0.5,
            
            # a magic linear confidence function
            confidence=lambda user1, user2: 
                1 - float(abs(user1.age - user2.age))/AGE_DIFFERENCE,
            
            description="Users %(subject1)s and %(subject2)s are about " + 
                "the same age."
        ),        
        
        # artists sharing some tags are similar
        ObjectSimilarityRule(
            name="Artists sharing some tags.",

            # both artists have some tags and they share at least one tag
            condition=lambda artist1, artist2: \
                artist1.artisttag_set.exists() and \
                artist2.artisttag_set.exists() and \
                artist1.artisttag_set.filter(
                    tag__id__in=artist2.artisttag_set.values_list('tag__id')
                ).exists(),
            
            # it's a positive rule
            is_positive=True,
            
            weight=0.5,
            
            # The more tags the artists have in common, the higher is  
            # the similarity confidence
            condition=lambda artist1, artist2: \
                float(artist1.artisttag_set.filter(
                    tag__id__in=artist2.artisttag_set.values_list('tag__id')
                ).count()) / \
                min(artist1.artisttag_set.count(), artist2.artisttag_set.count()),
            
            description="Artists %(object1)s and %(object2)s are similar " +
             "because they share some tags."
        ),
    )
        \end{verbatim}

                Such rules can represent each of knowledge types described in \cite{knowledge_spain}, described in the section \ref{knowledge_based}. Catalog knowledge can be represented by rules accessing object properties in their Condition and Confidence functions. Functional and user knowledge can be representing by rules using the relationships between subjects and objects. 

            \subsubsection{Representing Relationships}
                \label{representing_relationships}
                
                Apart from defining business rules, the domain expert can define which relationships are relevant for performing the prediction. This is done when adapting a system to Unresyst.
                
                In relationships, unlike rules, we only know there's some connection, that can't be weighted for a particular entity pair, i.e. if the users are coming from the same country, they are similar without any further strength differentiation for a pair of users coming from the same country.
                
                We would like to represent relationships of the following types. The relationships don't have to be direct - on the path from subject/object to subject/object there can be an entity of any type. 
                
                As for the rules, there can be both positive and negative relationships. Positive relationships increase the subject-object preference or similarity for the relevant entity pairs, negative relationships decrease it.
                
                As for the rules, we have the following relationship types
                \begin{description}
                    \item[Subject-object relationships] indicate a subject's preference for the given object in means of the predicted relationship.
                    \item[Subject-subject relationships] indicate similarity among subjects. In our example, we have a relationship ``Users that are from the same country are similar''. The relationship is positive, as it increases the resulting similarity.
                    \item[Object-object relationships] indicate similarity among objects.
                \end{description}

                Obviously, the requirements on the relationship representation are very similar to the requirements we have set on rule representation. Hence, we can use the rule representation for relationships with some corrections:
                \begin{description}
                    \item[Condition:] The boolean function means whether the given subjects/objects are in the relationship. The forms of the function remain the same as described in the section \ref{representing_rules}. In our example, the condition function is \emph{True} if both users have filled the country they're from and they are from the same country, otherwise it returns \emph{False}.
                    \item[Is Positive: ] A  boolean constant for determining whether the relationship is positive for the predicted relationship or negative. Works analogously to the Is Positive value in rules.
                    \item[Confidence:] The function won't be needed for representing relationships. If the Condition function returns $True$ for a subject/object pair the pair surely is (when positive) or isn't (when negative) in a relationship. Hence, such a function would always return $1$ for relationships.
                    \item[Weight, Description:] The properties an analogous meaning to rule weight, see \ref{representing_rules}
                \end{description}
                
                The following lines of code show the relationships written in our Python prototype recommender implementation.
                \begin{verbatim}
from unresyst import *
from models import *

class ArtistRecommender(Recommender):
    """A recommender recommending artists (musicians) that 
    the user can like.
    """    
    
    # ...
    relationships = (
        # if two users are from the same country, they are similar
        SubjectSimilarityRelationship(
            name="Users living in the same country",
            
            # both users have given their country and it's the same
            condition=lambda user1, user2:
                user1.country and \
                user2.country and \
                user1.country == user2.country,
            
            # it's relationship positive to similarity
            is_positive=True,               
            
            weight=0.5,            
            
            description="Users %(subject1)s and %(subject2)s are from " + \
            " the same country.",
        ),
    )
                \end{verbatim}
                
                Such a representation can use semantics of a system independently of its data model. There doesn't have to be a direct link between subjects/objects in the data model to define a relationship. Even though there isn't a direct connection in the data model, we can represent such a relationship in our system. Moreover, the relationships can be taken from various sources, e.g. multiple databases, data stores, or log files. The only thing that has to be provided to Unresyst is an implementation of a function returning whether the given subjects/objects are in the relationship.
                
                This representation is a reduction of the full semantic representation used in \cite{white_paper}. The authors propose using all system entities and relationships for recommending. This approach has some significant drawbacks. Firstly, it's not clear how to assign weights for relationships between entities that are not subjects or objects. Such relationship can have a varied meaning in the context of different relationships. In our example, if we had to use the links from artists to tags, we would have to assign a weight to them. However, we're using these links in two contexts: similarity of artists and the rule deprecating artists marked by the given tag for female users. Evaluating such relationship once in a positive meaning and once in a negative would be much complicated. The second drawback of the \cite{white_paper} approach is that most of the main-stream recommender algorithms use only subjects, objects and relationships between them. Therefore the choice of a recommender algorithm is much more limited.
                
                The relationships between entities that are not subjects or objects can be used in our representation as well, but only as parts of the described rules. They do not have a particular representation in Unresyst. 
                
                To our relationship definition we can include a relationship of any type:
                \begin{description}
                    \item[One-to-one relationships] can be included by directly traversing the relationship. 
                    \item[One-to-many relationships] can be included for example by testing the equality of the connected entities. In our example a relationship user - country is a one-to-many relationship. A user can be from at most one country, while one country can be a home of many users.
                    \item[Many-to-many relationships] can be included too. In our example the artist tags are many-to-many relationships. One artist can be tagged by many tags and one tag can be assigned to many artists.
                \end{description}
                
                \subsubsection{Representing Predicted Relationship}
                    \label{representing_predicted_relationship}
                    During the adaptation phase, the domain expert has to define which relationship should be predicted. In our example, we  would like  Unresyst to recommend artists to users.
                    
                    The predicted relationship definition is is done in a way similar to defining relationships that are relevant for recommendations. The only attribute that is omitted is the \emph{weight}. The condition and the description remains as described in the section \ref{representing_relationships}. 

                \subsubsection{Representing Biases}
                    \label{representing_biases}
                    Apart from rules and relationships the domain expert can define the so-called biases. Object bias indicates a tendency of an object to be liked more or less than others, depending if the bias is positive or negative. Object bias is a property of an object and is independent of the subject to whom we're recommending. Subject bias is an analogous concept for subjects. They indicate a higher tendency for a subject to like any object. Subject biases are useful only when the absolute expectancy matters, as for predicting object rating (see \ref{rel_last_fm}).
                    
                    As for rules and relationships, we use an object-oriented representation of biases. Each bias instance contains the following attributes.
                    \begin{description}
                         \item[Condition:] A boolean function determining whether the bias can be applied to a given entity. The function is defined depending on the rule type:
                        \begin{description}
                            \item[Object bias condition:] $C_o:O \to \{False, True\}$. A function takes an object and determines whether the object is influenced by the bias. In our example  the condition function is: If the artist $o$ is played more than $N$ times in a given recent period, the condition evaluates to \emph{True}. Otherwise it's \emph{False}
                            \item[Subject bias condition:] $C_s:S \to \{False, True\}$. A function takes a subject and determines whether the subject is influenced by the bias.
                        \end{description}
                        \item[Is Positive:] A  boolean constant (\emph{True} or \emph{False}) for determining whether the bias is positive for the preference or negative. Our example bias is positive.
                        \item[Confidence:] A function determining the strength of the bias in a positive or a negative way.
                        \begin{description}
                            \item[Object bias confidence:] $D_s:S \to [0,1]$. A function takes an object  and gives a confidence, that the object will be preferred by any given subject (or not preferred when negative). High values mean strong confidence. Low values mean that the rule is unsure about the impact (positive or negative) on the preference. In our example we take a confidence function returning the artist play count divided by the maximum play count for an artist in the given period.\footnote{For the sake of simplicity we take an absolute play count and a fixed time period. For better results it would be better to take the number of plays relative to an average artist play count in a given period. Our example function would probably give high biases to a constant set of popular artists.}

                            \item[Subject bias confidence:] $D_s:S \to [0,1]$. A function takes a subject and gives a confidence, that the subject will prefer any given object (or not prefer when negative). 
                        \end{description}
                         \item[Weight, Description:] The properties has the same meaning as in rule definition (see \ref{representing_rules}).
                    \end{description}
                    The following lines of code show the example bias written in our Python prototype recommender implementation.
                    \begin{verbatim}
import datetime

from django.db.models import Count

from unresyst import *
from models import *

MAX_PLAY_COUNT = 542
"""The maximum play count for an artist in the period"""

N_MIN_PLAY_COUNT = 100
"""The minimum play count for an artist to apply the bias"""

PERIOD_START_DATE = datetime.date(2010, 9, 1)
PERIOD_END_DATE = datetime.date(2010, 12, 31)


class ArtistRecommender(Recommender):
    """A recommender recommending artists (musicians) that 
    the user can like.
    """    
    
    # ...
    biases = (
        ObjectBias(
            name="Artists whose tracks have been listened a lot recently.",
            
            description="%(object)s has been listened much recently.",
            
            # take only artists with more than the minimal play count
            # in the given period
            condition=lambda artist: \
                artist.track_set\
                    .filter(scrobble__timestamp__range=
                        (PERIOD_START_DATE, PERIOD_END_DATE))\
                    .aggregate(Count('scrobble')) > N_MIN_PLAY_COUNT
            
            weight=0.5,
            
            # it's a positive bias
            is_positive=True,
            
            # the number of scrobbles for the artist divided by the max.
            confidence=lambda artist: \
                float(artist.track_set\
                    .filter(scrobble__timestamp__range=
                        (PERIOD_START_DATE, PERIOD_END_DATE))\
                    .annotate(scrobble_count=Count('scrobble'))\
                    .aggregate(Sum('scrobble_count')))/MAX_PLAY_COUNT
        ),
    )
                    \end{verbatim}

                \subsection{Runtime Interface}            
                    \label{runtime_interface}
                    Unresyst runtime interface serves for performing common operations in the recommender. The interface is made easy to use, so that Unresyst can be incorporated directly in the parent system without needing to implement an adapter. 
                    
                    The runtime interface contains the following methods.
                    \begin{description}
                        \item[$build()$] The build method does all computations and prepares all necessary data structures of the recommender in order to start recommending. The state of the system database in the time of build is used for recommending. Changes made in the parent system database will take effect in recommending after either calling the update method or the build method. The build method can take an indispensable ammount of time and system resources and therefore it should be called only by an entrusted person. It shouldn't be accessible to a common system user in any way. Build must be called before using any other runtime interface method. 
                        \item[$predict\_relationship(subject, object)$] The function predicts the preference in the means of the predicted relationship, of the given subject to the given object. The return value is an instance of the $RelationshipPrediction$ class (see the next paragraph for details). The function is meant to be called very often. Therefore the execution should be pretty fast, independent of the number of entities in the parent system.
                        \item[$get\_recommendations(subject, count)$] The function returns the given number of recommendations for the given subject. The return value is a list of instances of the $RelationshipPrediction$ class (see the next paragraph for details). The function takes advantage of the structures precomputed during the execution of the build method. For reasonable values of the count parameter it should be executed in a constant time.
                        \item[$update(entity)$] A method that is called after an update in the parent system database in order to propage the change to recommendations and predictions. The entity parameter is either a subject or an object. The method recomputes all structures we have created during the build method for the given entity. For some of the algorithms the update method might be as complex as performing build. The update method isn't implemented in our recommender prototype.
                    \end{description}
                    
                    The $RelationshipPrediction$ class, which instances are returned by the $get\_recommendations$ and $predict\_relationship$ runtime methods, has the following attributes.
                    \begin{description}
                        \item[$subject$] The subject of the prediction, typically the system user. The attribute contains a parent system class instance, no conversion is needed.
                        \item[$object$]: The object of the prediction, analogously to the $subject$ attribute.
                        \item[$expectancy$]: The estimated probability of the predicted relationship
                        occuring between the subject and the object, which is a rate of subject-object preference. The attribute contains a float number between from the $[0, 1]$ interval.
                        \item[$explanation$]: A short textual explanation of the provided prediction. The attribute contains a short text that can be presented to the user. For some algorithms this attribute may be inavailable.
                    \end{description}
                    
                    In our prototype implementation, all runtime interface methods are placed directly on the Recommender base class. When using the interface, we work with our class defined in the adaptation phase. In all runtime methods we work directly with the parent system objects, no conversion is needed.
                    
                    The usage of the runtime interface of our Python prototype implementation can be seen on the following lines.
                    \begin{verbatim}
kod z konzole - build, recommend, predict
                    \end{verbatim}


    \section{Applying Rules}
        BFS with the given depth
        sumarni vzorecek
        \subsection{Matching Rule Conditions to Entities and Entity Pairs}
            \label{matching}
            traversing the pairs, testing condition, optimization - provide a generator function
            abstractor.
        \subsection{Aggregating Similarities and Biases}
            \label{aggregating}
            aggregator, jak se to kdyz se to sejde see \ref{combining}.
        
        \subsection{Compiling Rules to Preference Predictions}
            \label{compiling}
            compilator
            predicted relationship + similarity, subject-object rules, bias, 
            ukazat na prikladu
            
        \subsection{Combining}
            \label{combining}
            deje se na dvou mistech 
            combining: aggregating phase (biases, similarities) ->, compiling phase (preferences) -> combined preferences,. 
            \subsubsection{Twisted Average}???
                
                \begin{equation}
                    \label{eq_expectancy_combination}
                    f(x) = \left\{\begin{array}{ll}
                            2^{n-1}x^n & \textrm{if $x\in[0,\frac{1}{2}]$}\\
                            & \\
                            1-2^{n-1}(x-1)^n & \textrm{if $x\in(\frac{1}{2}, 1]$}\\
                        \end{array} \right.
                \end{equation}
            \subsubsection{Mycin}
                Confidence factor, bude se muset lehce ztransformovat.
            \subsubsection{Bayesian}
                $C_{so}$: event, $s$ chooses $o$\\
                $E_{Rso}$ event, rule $R$ covers $s$ - $o$ prediction
                \begin{equation}
                    \label{eq_bayes1}
                    P(C_{so} | E_{Rso}) = \frac{P(E_{Rso} | C_{so}) P(C_{so})}{P(E_{Rso})}
                \end{equation}
                hh\\
                $CPair$: a set of s-o pairs, s has chosen o\\
                $Pair_R$: a set of s-o pairs, $R$ predicts s-o expectancy\\
                $S$: a set of subjects\\
                $O$: a set of objects\\
                $P(C_{so}) \simeq$ expectancy given by $R$\\
                $P(E_{Rso}) \simeq \frac{|Pair_R|}{|S||O|}$\\
                $P(E_{Rso}|C_{so}) \simeq \frac{|CPair \cap Pair_R|}{CPair}$\\
                \begin{equation}
                    \label{eq_bayes2}
                    P(C_{so} | E_{R_1so} \cap E_{R_2so}) = \frac{P(C_{so}) P(E_{R_1so} | C_{so}) P(E_{R_2so} | C_{so} \cap E_{R_1so})}{P(E_{R_1so}) P(E_{R_2so}|E_{R_1so})}
                \end{equation}

        \section{Unresyst Application Layers}
            \label{unresyst_layers}
        \section{Unresyst Implementation Details}
            \label{unresyst_details}
            obrazek architecture:
            Specific Recommender holds the domain-specific data.
            Recommender provides a domain-independent interface for creating a recommender model, getting recommendations and updating the recommender model.
            Abstractor translates the domain-specific objects into universal ones, converts the given business rules into relationships among subjects and objects.
            Aggregator aggregates all relationships into a single one for subject-object, subject-subject and object-object pairs.
            Recommender Algorithm uses the known relationships among subjects and objects, exploits them to predict all subject-object relationships of the given type.
        
        obrazek build:
            During the build, domain data that have been entered by the domain expert are used for creating a recommender model. 
            Recommender just passes the call to other layers.
            Abstractor goes over the subjects and objects, evaluates the business rules on them, introduces a new relationship or bias for each rule. It converts subjects and objects to a universal representation that would be used in the rest of Unresyst.
            Aggregator aggregates all relationships int o a single one for subject-object, subject-subject and object-object pairs, using the given weights. It does the same for biases.
            Recommender Algorithm uses the aggregated relationships to learn a recommender model.
        
        obrazek class diagram:
        Classes are displayed as rectangles, objects as rectangles with round corners. All the classes are \emph{purely static} - there are no instances of the classes, the classes contain only class methods. They act as singleton objects.
        The diamond relationships mean that the given class/object can be accessed only from the containing class. 
        
        implementacni vychytavky:
            symetricke relace serazene podle idecka, zarucene bude s1 s2 a uz ne s2 s1
            
            pridani toho generatoru do pravidel

    \section{Layers}
        \subsection{Adaptation Interface}
        misto condition generator
        \subsection{Data Model}
        datovy model - subjekty, objekty v jednom, definice, indexy, agregator si to radi a pak to bere jak to jde
        Vychytavka se symmetric relations. Poradi: v s-o prvni subject, vsude jinde to co ma mensi id tak to prvni.
        \subsection{Runtime Interface}
            jak tam vracim uzasny miry a vysvetleni, jak je to diky buildu rychly. 
        \subsection{Recommendation Viewer}
            \label{viewer}
            The recommendations made by the Universal Recommender can be viewed in a web based application called \emph{Recommendation Viewer}. The application shows recommendations for a chosen subject. It is independent of the object and subject domain. The page for viewing the recommendations can be easily embedded to a webpage.
        
        ...
\chapter{Verifying the Universal Recommender on Real-World Data}
    \label{adapting_to_existing_systems}
    The process of adapting the Universal Recommender to some existing systems is described in the chapter. The chosen systems work on various domains. Each system has some API, so that the Universal Recommender can easily get data about the objects, subjects and their relationships. The way how to run the Universal Recommender in several instances for a system is described here. Some basic rules for the Universal Recommender configuration are given.
        \subsection{Flixster data set}
            z megamnozstvi jsem udelal min - podmnozina uzivatelu, z prvnich 105000 radku friendu, k nim nalezejici ratingy, uzivatele bez hodnoceni smazat, ponevadz nejsem schopen je nijak testovat - je to akorat spam
        \subsection{Last.fm}
            \label{verifying_last_fm}
            zpusob vyberu z megadatasetu
            musel jsem vyhazet tagy, ktere nejsou sharovane mezi vic artisty, byly jich dve tretiny.
        \subsection{Travel agency}
            byl smaznul jsem i ostatni implicitni feedback z train setu - feedback z budoucnosti neznam. 
        
       
        ...

\chapter{Evaluating Recommender Results}
    \label{evaluating_recommender_results}
    In the chapter we describe experience with running the Universal Recommender on various systems. The quality of the recommendations are evaluated for each system. The results are compared to the recommender contained in the system, where relevant. 
    
    metriky kde se porovnava poradi v listech nejsou uzitecne, jelikoz v test setu nemam poradi. 
    hh\\
    $p_{so}$: preference of $s$ to $o$ taken from the test set\\
    $\widetilde{p}_{so}$: prediction of the preference of $s$ to $o$
    \begin{equation}
        \label{rmse}
        RMSE = \sqrt{\frac{\sum_{(s,o)\in TestPairs}(p_{so} - \widetilde{p}_{so})^2}{|TestPairs|}}
    \end{equation}
    
    ndcg nemuzu pouzit, protoze nemam poradi v result listu
    korenuv hyperzpusob na par nahodne vybranych uzivatelu.
    hh\\
    $Prec_s$: precision for subject $s$.\\
    $Rec_s$: recall for subject $s$\\
    $R_s$: a set of objects recommended to $s$\\
    $T_s$: a set of objects in test set for $s$\\
    $N$: number of recommended objects\\
    
    \begin{equation}
        \label{precision}
        Prec_s = \frac{|R_s \cap T_s|}{N}
    \end{equation}
    
    \begin{equation}
        \label{recall}
        Rec_s = \frac{|R_s \cap T_s|}{|T_s|}
    \end{equation}
    
    zpusob vyberu test dat z datasetu - nakonec asi podle casu (where available)
    
    timestampy at si resi v pravidlech - to je business vec - jestli plati nejaky decay nebo tak neco, do toho algoritmus nema stourat. 
    
    \section{Metrics}
        je jich hafo, viz clanek. Kdyz nemam negativni hodnoceni, tak je mi RMSE uplne na pytel. Jak jsem dosel k tomu precision recall na urovni usera - je potreba to nejak omezit aby nevyhraval recommender konstantni 1. Rozumna operace pro omezeni je recommende - per user. 
    \section{Last.fm dataset}
        Ze mam dva recommendery - jeden novel - objevovani novych artistu
        druhy nenovel - napr. hrani v personalized radiu, nezalezi na tom jestli hral nebo ne. Tohle nesrovnam s Mahoutem, protoze ten vyrazuje zname dvojice z recommendations
        
        u novel test pairu beru distinct subj, obj. u nenovel beru jak mi to prijde. Pokud recommender trefi objekt, ktery je v test setu vickrat, tak do precision to pocitam jenom jednou (recommended item byla zahrana), do recall vickrat (trefil vic polozek z moznych). 
        
        Results:
        test set randomly chosen, 516 trivial hits
        - unresyst with age rule: prediction Success rate: 0.583559 (646/1107); recommendation: 4 hits recorded, precision, recall (0.0046511627906976744, 0.0042393410852713176)
        - mahout slope one: prediction Success rate: 0.708220 (784/1107), 7 hits recorded, precision/recall (0.0069767441860465115, 0.014426910808489757)
        
        test set taken as the latest scrobbles (non-novel): XXX trivial hits
        - unresyst with age rule and scrobble count rule:
            prediction: Success rate: 0.527125 (583/1106), RMSE: 0.475152
            recommendation: 65 hits recorded, (0.050724637681159424, 0.052776203958823528)
        - mahout slope one (binary):  
            prediction: 0.536166 (593/1106) RMSE: 0.340527
            recommendation: 3 hits recorded, (0.0043478260869565218, 0.0056051034311903883)

    \section{Improving the Recommender Results}
        \label{improving_the_results}
        \subsection{Learning Weights}

\chapter{Conclusion and Future Work}
\label{conclusion}

% zahrnul jsem knowledge-based recommender do matrix factorization (ale na to prijdu az v kapitole algorithms).
% navrhnul jsem expectancy - miru relevance rekomendace nezavislou na hodnoceni, navrhnul jsem jak ji zadavat aby to bylo user-friendly
% oddelil jsem business knowledge od recommender algorithm

\chapter{Software tools}
\label{tools}
 - gedit, http://www.timtim.com (obrazky), Kile (latex),  pdfTeXk version 1.40.3 (Web2C 7.5.6)
 - django 1.2, python 2.7
    
    
%%% Seznam literatury
%%%
%%% Literatura se øadí abecednì. Úvádí se pouze literatura, na kterou se v textu odkazuje.
%%% Pøi odkazu na knihu se v¾dy uvádìjí èísla stránek.

\begin{thebibliography}{99}
% seradit abecedne, u internetovych clanku dat datum pristupu
% jak davat neclanky (napr. last.fm?)

% druhy literatury:
%    o universal recommenders
%    o algoritmech a jejich implementaci
%    case studies
\addcontentsline{toc}{chapter}{Bibliography}
% \bibitem{abraham-marsden}Abraham R., Marsden J. E.: {\em Foundations of Mechanics}, Addison-Wesley, Reading, 1985.
    
    \bibitem{patent}Geoffrey J. Hueter, Steven C. Quandt, Noble H. Hueter: \emph{Universal system and method for representing and predicting human behavior} \#20090248599, United States Patent Application Publication, 2009. http://www.freshpatents.com/-dt20091001ptan20090248599.php, http://www.freepatentsonline.com/20090248599.pdf

    \bibitem{netflix_solution}http://www.netflixprize.com/assets/GrandPrize2009\_BPC\_BellKor.pdf
    \bibitem{netflix_wiki}http://en.wikipedia.org/wiki/Netflix\_Prize
    \bibitem{netflix_benefit}http://www.nytimes.com/2009/09/22/technology/internet/22netflix.html
    \bibitem{netflix_end}http://blog.netflix.com/2010/03/this-is-neil-hunt-chief-product-officer.html
        http://glaros.dtc.umn.edu/gkhome/suggest/overview
    hybrid vec na duinu
        http://wwwis.win.tue.nl/hacdais2010/paper4short.pdf 
    \bibitem{survey}Gediminas Adomavicius and Alexander Tuzhilin: \emph{Towards the Next Generation of Recommender Systems:
A Survey of the State-of-the-Art and Possible Extensions}, 2005
    \bibitem{wiki_genome}http://en.wikipedia.org/wiki/Music\_Genome\_Project
    \bibitem{wiki_collaborative}http://en.wikipedia.org/wiki/Collaborative\_filtering
    \bibitem{wiki_slope_one}http://en.wikipedia.org/wiki/Slope\_One
    \bibitem{amazon}Amazon.com Recommendations Item-to-Item Collaborative Filtering http://www.win.tue.nl/\~laroyo/2L340/resources/Amazon-Recommendations.pdf
    \bibitem{bellkor_ieee}Matrix factorization techniques for recommender systems http://research.yahoo4.akadns.net/files/ieeecomputer.pdf
    \bibitem{bellkor_2009}
Yehuda Koren: The BellKor Solution to the Netflix Grand Prize
http://www.netflixprize.com/assets/GrandPrize2009\_BPC\_BellKor.pdf
    \bibitem{google_news}Google News Personalization: Scalable Online Collaborative Filtering http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.80.4329\&rep=rep1\&type=pdf
    
    \bibitem{white_paper}The Universal Recommender http://adsabs.harvard.edu/abs/2009arXiv0909.3472K
    \bibitem{duine}The Duine Framework http://duineframework.org
    \bibitem{knowledge_burke}Knowledge-based recommender systems \verb!http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.3078&rep=rep1&type=pdf!
    \bibitem{integrating_burke}Integrating Knowledge-based and Collaborative-filtering
               Recommender Systems
\verb!http://www.aaai.org/Papers/Workshops/1999/WS-99-01/WS99-01-011.pdf!
\bibitem{racofi}RACOFI: A Rule-Applying Collaborative Filtering System
\verb!http://www.daniel-lemire.com/fr/documents/publications/racofi_nrc.pdf!
\bibitem{knowledge_spain}A Knowledge Based Recommender System Based on Consistent Preference Relations 
\verb!http://www.springerlink.com/content/m64g474m7p0t4r26/!
\verb!http://books.google.cz/books?id=LN4dVFPXBioC&lpg=PP1&ots=EwNO8Bpeyy&dq=Intelligent%20Decision%20and%20Policy%20Making%20Support%20Systems&pg=PP1#v=onepage&q&f=false!
\bibitem{order}Learning to order things
\verb!http://www.jair.org/media/587/live-587-1790-jair.pdf!
\bibitem{ruleml}\verb!http://ruleml.org/!
\bibitem{ruleml_short}\verb!http://ruleml.org/submission/ruleml-shortation.html!
\bibitem{ruleml_prolog}\verb!http://centria.di.fct.unl.pt/~cd/projectos/w4/ruleml/index.htm!
\bibitem{lastfm_festivals}\verb!http://www.last.fm/festivals!
\bibitem{mahout}\verb!http://mahout.apache.org/!
\bibitem{collaborative_filtering}Collaborative filtering recommender systems \verb!http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.4520&rep=rep1&type=pdf!
\bibitem{last_fm}Last.fm recommendation service \verb!http://www.last.fm/about!
\bibitem{yahoo_cup}KDD cup recommender competition \verb!http://kddcup.yahoo.com/index.php!
\bibitem{probabilistic_analysis}Recommendation systems: a probabilistic analysis \verb!http://www.tomkinshome.com/site_media/papers/papers/KRR+98.pdf!
\bibitem{yahoo} Seung-Taek Park, David M. Pennock: Applying collaborative filtering techniques to movie search for better ranking and browsing \verb!http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.8109&rep=rep1&type=pdf!
\bibitem{google_api}The Google Prediction API \verb!http://code.google.com/apis/predict/!

http://ids.csom.umn.edu/faculty/gedas/papers/recommender-systems-survey-2005.pdf
odkazy:
    http://en.wikipedia.org/wiki/Recommender\_system
    http://www.deitel.com/ResourceCenters/Web20/RecommenderSystems/RecommenderSystemsConferences/tabid/1323/Default.aspx
    http://lucene.apache.org/mahout/taste.html\#useful .. tam toho neni moc
    Univerzalni recommender, projekty:
        Aura (dead since 2009):
            \bibitem{aura}The Advanced Universal Recommendation Architecture (AURA) Project home page. http://labs.oracle.com/projects/dashboard.php?id=196
            \bibitem{music_explaura}The Music Explaura, an experimental music recommender based on AURA. Currently inactive. http://music.tastekeeper.com/
            \bibitem{aura_wiki}The AURA project wiki. http://kenai.com/projects/aura/pages/Home
        Loomia (komercni):
            http://www.loomia.com/
        SUGGEST (dead since 2000):
            http://glaros.dtc.umn.edu/gkhome/suggest/overview
            + http://pypi.python.org/pypi/pysuggest/1.0
        easyrec (opensource, vypada ze moc neumi, ale bezi jako service):
            http://easyrec.org/api-js
        duine (opensource):
            http://duineframework.org
    knihovny na recommendaci
        mahout
            http://lucene.apache.org/mahout/
            http://svn.apache.org/repos/asf/mahout/
    
    algoritmy
        http://tastecliq.posterous.com/comparing-state-of-the-art-collaborative-filt
        tagy:
            http://stackoverflow.com/questions/2794272/tag-keyword-based-recommendation
        
        
    python to Java
        http://www.slideshare.net/onyame/mixing-python-and-java
        http://wiki.cacr.caltech.edu/danse/index.php/Communication\_between\_Java\_and\_Python
        Pres generovane c++
            http://pypi.python.org/pypi/JCC/
        nejak jinak (asi obracene)
            http://jepp.sourceforge.net/
        primo pres masiny (dead since 2009)
            http://hustleplay.wordpress.com/2010/02/18/jpype-tutorial/
            http://jpype.sourceforge.net/
            
            
        
    
 
% \bibitem{derbes}Derbes D.: {\em Reinventing the wheel: Hodographic solutions to the Kepler problems}, Am. J. Phys. {\bf 69} (2001) 481--489.
% \bibitem{kvasnica}Kvasnica J.: {\em Teorie elektromagnetického pole}, Academia, Praha, 1985.
\end{thebibliography}

\end{document}
